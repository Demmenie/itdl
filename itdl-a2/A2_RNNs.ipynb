{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ7Xx__nJmj7"
   },
   "source": [
    "<div style=\"text-align: right\">   </div>\n",
    "\n",
    "\n",
    "Introduction to Deep Learning (2024) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp;\n",
    "-------|-------------------\n",
    "**Assignment 2 - Sequence processing using RNNs** | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/UniversiteitLeidenLogo.svg/1280px-UniversiteitLeidenLogo.svg.png\" width=\"300\">\n",
    "\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "The goal of this assignment is to learn how to use encoder-decoder recurrent neural networks (RNNs). Specifically we will be dealing with a sequence to sequence problem and try to build recurrent models that can learn the principles behind simple arithmetic operations (**integer addition, subtraction and multiplication.**).\n",
    "\n",
    "<img src=\"https://i.ibb.co/5Ky5pbk/Screenshot-2023-11-10-at-07-51-21.png\" alt=\"Screenshot-2023-11-10-at-07-51-21\" border=\"0\" width=\"500\"></a>\n",
    "\n",
    "In this assignment you will be working with three different kinds of models, based on input/output data modalities:\n",
    "1. **Text-to-text**: given a text query containing two integers and an operand between them (+ or -) the model's output should be a sequence of integers that match the actual arithmetic result of this operation\n",
    "2. **Image-to-text**: same as above, except the query is specified as a sequence of images containing individual digits and an operand.\n",
    "3. **Text-to-image**: the query is specified in text format as in the text-to-text model, however the model's output should be a sequence of images corresponding to the correct result.\n",
    "\n",
    "\n",
    "### Description**\n",
    "Let us suppose that we want to develop a neural network that learns how to add or subtract\n",
    "two integers that are at most two digits long. For example, given input strings of 5 characters: ‘81+24’ or\n",
    "’41-89’ that consist of 2 two-digit long integers and an operand between them, the network should return a\n",
    "sequence of 3 characters: ‘105 ’ or ’-48 ’ that represent the result of their respective queries. Additionally,\n",
    "we want to build a model that generalizes well - if the network can extract the underlying principles behind\n",
    "the ’+’ and ’-’ operands and associated operations, it should not need too many training examples to generate\n",
    "valid answers to unseen queries. To represent such queries we need 13 unique characters: 10 for digits (0-9),\n",
    "2 for the ’+’ and ’-’ operands and one for whitespaces ’ ’ used as padding.\n",
    "The example above describes a text-to-text sequence mapping scenario. However, we can also use different\n",
    "modalities of data to represent our queries or answers. For that purpose, the MNIST handwritten digit\n",
    "dataset is going to be used again, however in a slightly different format. The functions below will be used to create our datasets.\n",
    "\n",
    "---\n",
    "\n",
    "*To work on this notebook you should create a copy of it.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP__1utGJmj_"
   },
   "source": [
    "# Function definitions for creating the datasets\n",
    "\n",
    "First we need to create our datasets that are going to be used for training our models.\n",
    "\n",
    "In order to create image queries of simple arithmetic operations such as '15+13' or '42-10' we need to create images of '+' and '-' signs using ***open-cv*** library. We will use these operand signs together with the MNIST dataset to represent the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3nzYbXOJmj8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import rotate\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Dense, Reshape, LSTM, Dropout, TimeDistributed, RepeatVector, Input\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "# weet niet of dit bovenste stukje code nodig is, maar ik heb het er maar in gezet\n",
    "tf.config.list_physical_devices('GPU')\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "Z7RGPMxLJmkA",
    "outputId": "a6cf8be6-c32f-40b2-b8ae-517056fba1c8"
   },
   "outputs": [],
   "source": [
    "# Create plus/minus operand signs\n",
    "def generate_images(number_of_images=50, sign='-'):\n",
    "    blank_images = np.zeros([number_of_images, 28, 28])  # Dimensionality matches the size of MNIST images (28x28)\n",
    "    x = np.random.randint(12, 16, (number_of_images, 2)) # Randomized x coordinates\n",
    "    y1 = np.random.randint(6, 10, number_of_images)       # Randomized y coordinates\n",
    "    y2 = np.random.randint(18, 22, number_of_images)     # -||-\n",
    "\n",
    "    for i in range(number_of_images): # Generate n different images\n",
    "        cv2.line(blank_images[i], (y1[i], x[i,0]), (y2[i], x[i, 1]), (255,0,0), 2, cv2.LINE_AA)     # Draw lines with randomized coordinates\n",
    "        if sign == '+':\n",
    "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw lines with randomized coordinates\n",
    "        if sign == '*':\n",
    "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
    "            # Rotate 45 degrees\n",
    "            blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
    "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
    "            blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
    "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return blank_images\n",
    "\n",
    "def show_generated(images, n=5):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    for i in range(n**2):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "    plt.show()\n",
    "\n",
    "show_generated(generate_images(sign='-'))\n",
    "show_generated(generate_images(sign='+'))\n",
    "show_generated(generate_images(sign='*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Lx-Pt6ypJmkD"
   },
   "outputs": [],
   "source": [
    "def create_data(highest_integer, num_addends=2, operands=['+', '-']):\n",
    "    \"\"\"\n",
    "    Creates the following data for all pairs of integers up to [1:highest integer][+/-][1:highest_integer]:\n",
    "\n",
    "    @return:\n",
    "    X_text: '51+21' -> text query of an arithmetic operation (5)\n",
    "    X_img : Stack of MNIST images corresponding to the query (5 x 28 x 28) -> sequence of 5 images of size 28x28\n",
    "    y_text: '72' -> answer of the arithmetic text query\n",
    "    y_img :  Stack of MNIST images corresponding to the answer (3 x 28 x 28)\n",
    "\n",
    "    Images for digits are picked randomly from the whole MNIST dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    num_indices = [np.where(MNIST_labels==x) for x in range(10)]\n",
    "    num_data = [MNIST_data[inds] for inds in num_indices]\n",
    "    image_mapping = dict(zip(unique_characters[:10], num_data))\n",
    "    image_mapping['-'] = generate_images()\n",
    "    image_mapping['+'] = generate_images(sign='+')\n",
    "    image_mapping['*'] = generate_images(sign='*')\n",
    "    image_mapping[' '] = np.zeros([1, 28, 28])\n",
    "\n",
    "    X_text, X_img, y_text, y_img = [], [], [], []\n",
    "\n",
    "    for i in range(highest_integer + 1):      # First addend\n",
    "        for j in range(highest_integer + 1):  # Second addend\n",
    "            for sign in operands: # Create all possible combinations of operands\n",
    "                query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=True)\n",
    "                query_image = []\n",
    "                for n, char in enumerate(query_string):\n",
    "                    image_set = image_mapping[char]\n",
    "                    index = np.random.randint(0, len(image_set), 1)\n",
    "                    query_image.append(image_set[index].squeeze())\n",
    "\n",
    "                result = eval(query_string)\n",
    "                result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=True)\n",
    "                result_image = []\n",
    "                for n, char in enumerate(result_string):\n",
    "                    image_set = image_mapping[char]\n",
    "                    index = np.random.randint(0, len(image_set), 1)\n",
    "                    result_image.append(image_set[index].squeeze())\n",
    "\n",
    "                X_text.append(query_string)\n",
    "                X_img.append(np.stack(query_image))\n",
    "                y_text.append(result_string)\n",
    "                y_img.append(np.stack(result_image))\n",
    "\n",
    "    # Combine the two lists into a single list of tuples\n",
    "    combined_text = list(zip(X_text, y_text))\n",
    "    combined_img = list(zip(X_img, y_img))\n",
    "    combined = list(zip(combined_text, combined_img))\n",
    "    random.shuffle(combined)\n",
    "    # unpack combined\n",
    "    X_text, y_text = zip(*[x for x, _ in combined])\n",
    "    X_img, y_img = zip(*[x for _, x in combined])\n",
    "    return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.\n",
    "\n",
    "def to_padded_chars(integer, max_len=3, pad_right=False):\n",
    "    \"\"\"\n",
    "    Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side\n",
    "    \"\"\"\n",
    "    length = len(str(integer))\n",
    "    padding = (max_len - length) * ' '\n",
    "    if pad_right:\n",
    "        return str(integer) + padding\n",
    "    else:\n",
    "        return padding + str(integer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTMHYBf4baih"
   },
   "source": [
    "# Creating our data\n",
    "\n",
    "The dataset consists of 20000 samples that (additions and subtractions between all 2-digit integers) and they have two kinds of inputs and label modalities:\n",
    "\n",
    "  **X_text**: strings containing queries of length 5: ['  1+1  ', '11-18', ...]\n",
    "\n",
    "  **X_image**: a stack of images representing a single query, dimensions: [5, 28, 28]\n",
    "\n",
    "  **y_text**: strings containing answers of length 3: ['  2', '156']\n",
    "\n",
    "  **y_image**: a stack of images that represents the answer to a query, dimensions: [3, 28, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y0N1vtdLJmkG",
    "outputId": "9cdffe31-4f7c-4e56-902e-ac6acc221c67",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Illustrate the generated query/answer pairs\n",
    "\n",
    "unique_characters = '0123456789+- '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)\n",
    "highest_integer = 99                      # Highest value of integers contained in the queries\n",
    "\n",
    "max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
    "max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
    "max_answer_length = 3    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')\n",
    "\n",
    "# Create the data (might take around a minute)\n",
    "(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "X_text, X_img, y_text, y_img = create_data(highest_integer)\n",
    "## Display the samples that were created\n",
    "def display_sample(n):\n",
    "    labels = ['X_img:', 'y_img:']\n",
    "    for i, data in enumerate([X_img, y_img]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        # plt.set_figheight(15)\n",
    "        plt.axis('off')\n",
    "        plt.title(labels[i])\n",
    "        plt.imshow(np.hstack(data[n]), cmap='gray')\n",
    "    print('='*50, f'\\nQuery #{n}\\n\\nX_text: \"{X_text[n]}\" = y_text: \"{y_text[n]}\"')\n",
    "    plt.show()\n",
    "\n",
    "for _ in range(10):\n",
    "    display_sample(np.random.randint(0, 10000, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h06Gi5l63EvS"
   },
   "source": [
    "## Helper functions\n",
    "\n",
    "The functions below will help with input/output of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rePVm6duJmkJ",
    "outputId": "c48e6478-4c67-492e-975b-9fa6e4a2d669"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding/decoding the text queries/answers so that they can be processed using RNNs\n",
    "# You should use these functions to convert your strings and read out the output of your networks\n",
    "def encode_labels(labels, max_len=3):\n",
    "  n = len(labels)\n",
    "  length = len(labels[0])\n",
    "  char_map = dict(zip(unique_characters, range(len(unique_characters))))\n",
    "  one_hot = np.zeros([n, length, len(unique_characters)])\n",
    "  for i, label in enumerate(labels):\n",
    "      m = np.zeros([length, len(unique_characters)])\n",
    "      for j, char in enumerate(label):\n",
    "          m[j, char_map[char]] = 1\n",
    "      one_hot[i] = m\n",
    "\n",
    "  return one_hot\n",
    "\n",
    "\n",
    "def decode_labels(labels):\n",
    "    pred = np.argmax(labels, axis=1)\n",
    "    predicted = ''.join([unique_characters[i] for i in pred])\n",
    "    return predicted\n",
    "# TODO set unrandom but for debug its fine\n",
    "X_text_onehot = encode_labels(X_text)\n",
    "y_text_onehot = encode_labels(y_text)\n",
    "random_numbers = np.random.randint(0, len(X_text), 4)\n",
    "print(X_text_onehot.shape, y_text_onehot.shape)\n",
    "for i in range(4):\n",
    "    print(y_text_onehot[random_numbers[i]])\n",
    "    print(decode_labels(y_text_onehot[random_numbers[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_classification(y_pred, y_true):\n",
    "  bools = [y_pred[i] == y_true[i] for i in range(len(y_pred))]\n",
    "  correct = np.where(bools)[0]\n",
    "  incorrect = np.where(np.logical_not(bools))[0]\n",
    "  return len(correct), len(incorrect), np.array(correct), np.array(incorrect, dtype=int)\n",
    "\n",
    "def decode_all(predictions):\n",
    "    decoded_predictions = []\n",
    "    for i in range(len(predictions)):\n",
    "        decoded_predictions.append(decode_labels(predictions[i]))\n",
    "    return decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert our strings to integers. \n",
    "# Note that due to white spacing we must first subtract any white spacing, before converting to integers. \n",
    "# Furthermore, we should note exceptions such as '- ' which is basically just a black, we should completely remove these, but do count them up. \n",
    "# These are of course completely wrong as no number is present.\n",
    "\n",
    "def process_strings(input_list):\n",
    "    cleaned_list = []\n",
    "    invalid_count = 0\n",
    "\n",
    "    for item in input_list:\n",
    "        cleaned_item = item.replace(\" \", \"\")\n",
    "        # # check if there is only a + or - in the string\n",
    "        if re.search(r\"[+-]\", cleaned_item[1:]) or re.search(r\"[^0-9+-]\", cleaned_item) or not cleaned_item or cleaned_item == '-':\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        cleaned_item_int = int(cleaned_item)\n",
    "        cleaned_list.append(cleaned_item_int)\n",
    "    return cleaned_list, invalid_count\n",
    "\n",
    "# for debugging:\n",
    "input_strings = [\" 92 \", \"30\", \"-67\", \"  -  20 \", \"12 - 34\", \"49-\", '']\n",
    "cleaned_numbers, invalid_count = process_strings(input_strings)\n",
    "\n",
    "print(\"Cleaned Numbers:\", cleaned_numbers)\n",
    "print(\"Invalid Count:\", invalid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the wrongly classified instances (2.2)\n",
    "# Set the batch size\n",
    "\n",
    "def plot_wrong_classified(cleaned_wrong_classified, cleaned_true,batch_size=300):\n",
    "\n",
    "    # Get the total number of instances\n",
    "    total_instances = len(cleaned_wrong_classified)\n",
    "\n",
    "    # Calculate the number of subplots needed\n",
    "    num_subplots = int(np.ceil(total_instances / batch_size))\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplot grid\n",
    "    num_rows = int(np.sqrt(num_subplots))\n",
    "    num_cols = int(np.ceil(num_subplots / num_rows))\n",
    "\n",
    "    # Create a subplot grid\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 12))\n",
    "\n",
    "    # Flatten the axs array if it's a multi-dimensional array\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Plot instances in batches of 250\n",
    "    for i in range(num_subplots):\n",
    "        start_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, total_instances)\n",
    "\n",
    "        # Use the current subplot\n",
    "        ax = axs[i]\n",
    "\n",
    "        # Plot instances that were wrongly labeled\n",
    "        ax.scatter(range(start_index, end_index), cleaned_wrong_classified[start_index:end_index],\n",
    "                color='red', marker='x', label='Wrong predicted values', s=25)\n",
    "\n",
    "        # Plot true values of the wrongly classified instances\n",
    "        ax.scatter(range(start_index, end_index), cleaned_true[start_index:end_index],\n",
    "                color='blue', marker='o', label='True values', s=25, alpha=0.4)\n",
    "\n",
    "        # Customize the subplot\n",
    "        ax.set_xlabel('Instance index')\n",
    "        ax.set_ylabel('Instance value')\n",
    "        ax.set_title(f'Subplot {i+1}')\n",
    "        ax.grid()\n",
    "\n",
    "        # Create a legend with unique labels\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "    # Display the grid of subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-pNByj-JmkL"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## I. Text-to-text RNN model\n",
    "\n",
    "The following code showcases how Recurrent Neural Networks (RNNs) are built using Keras. Several new layers are going to be used:\n",
    "\n",
    "1. LSTM\n",
    "2. TimeDistributed\n",
    "3. RepeatVector\n",
    "\n",
    "The code cell below explains each of these new components.\n",
    "\n",
    "<img src=\"https://i.ibb.co/NY7FFTc/Screenshot-2023-11-10-at-09-27-25.png\" alt=\"Screenshot-2023-11-10-at-09-27-25\" border=\"0\" width=\"500\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tll54DIrZwbK"
   },
   "outputs": [],
   "source": [
    "def build_text2text_model(num_encode_layers=1,num_decode_layers=1,max_answer_length=3):\n",
    "    text2text = tf.keras.Sequential()\n",
    "    text2text.add(Input(shape=(max_query_length, len(unique_characters))))\n",
    "    hidden_units = 128\n",
    "    for i in range(num_encode_layers):\n",
    "        text2text.add(LSTM(hidden_units, return_sequences=(i < num_encode_layers - 1)))\n",
    "        text2text.add(Dropout(0.2))\n",
    "    # Repeat the context vector for decoding\n",
    "    text2text.add(RepeatVector(max_answer_length))\n",
    "\n",
    "    # Decoder: Add num_decode_layers LSTM layers\n",
    "    for _ in range(num_decode_layers):\n",
    "        text2text.add(LSTM(hidden_units, return_sequences=True))\n",
    "        text2text.add(Dropout(0.2))\n",
    "\n",
    "    # Output layer: TimeDistributed Dense with softmax activation\n",
    "    text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))\n",
    "\n",
    "\n",
    "    # Next we compile the model using categorical crossentropy as our loss function.\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    text2text.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return text2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_text2text_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = np.array([i/10 for i in range(1, 10)])\n",
    "training_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz6QkPAdzywk"
   },
   "outputs": [],
   "source": [
    "## Your code (look at the assignment description for your tasks for text-to-text model):\n",
    "## Your first task is to fit the text2text model using X_text and y_text)\n",
    "## dit is taak 1.2\n",
    "test_split = 0.1\n",
    "X_test = X_text_onehot[:int(len(X_text_onehot)*test_split)]\n",
    "y_test = y_text_onehot[:int(len(y_text_onehot)*test_split)]\n",
    "\n",
    "X_train = X_text_onehot[int(len(X_text_onehot)*test_split):]\n",
    "y_train = y_text_onehot[int(len(y_text_onehot)*test_split):]\n",
    "total_scores = {}\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "for train_size in training_sizes[:]:\n",
    "    print(f\"Training size: {train_size}, Test split: {test_split}, validation size: {1-train_size}\")\n",
    "\n",
    "    X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
    "    model = build_text2text_model()\n",
    "    history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch), epochs=epochs, batch_size=batch_size)\n",
    "    # history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=128)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    results = {'loss': results[0], 'accuracy': results[1], 'history': history}\n",
    "    print(f\"Test {results}\")\n",
    "    total_scores[train_size] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verslag table\n",
    "for key,value in total_scores.items():\n",
    "    sentence = f\"{round(1-key,2)} & {round(value['accuracy']*100,2)} & {round(value['loss'],4)} \\\\\\\\\"\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_key = max(total_scores, key=lambda x: total_scores[x]['accuracy'])\n",
    "best_config = total_scores[best_config_key]\n",
    "best_config_key,best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=best_config_key, random_state=42)\n",
    "model = build_text2text_model()\n",
    "history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('total_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(total_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history_plots(histories, sizes):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, history in enumerate(histories):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        # set title fontsize a bit lower\n",
    "        plt.title(f'Accuracy with {int(sizes[i]*100)}% training size', fontsize=8)\n",
    "        plt.grid()\n",
    "        plt.ylim(0,1)\n",
    "        plt.ylabel('accuracy', fontsize=8)\n",
    "        plt.xlabel('epoch', fontsize=8)\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        # set x and y values also to fontsize 8\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "histories = [total_scores[key]['history'] for key in total_scores.keys()]\n",
    "sizes = [key for key in total_scores.keys()]\n",
    "create_history_plots(histories, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "# put them into a readable format\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Predicted: {decode_labels(predictions[i])}, True: {decode_labels(y_test[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions = decode_all(predictions)\n",
    "decoded_y_test = decode_all(y_test)\n",
    "correct_num, incorrect_num, correct_indices, incorrect_indices = check_classification(decoded_predictions, decoded_y_test)\n",
    "print(f\"Correct: {correct_num}, Incorrect: {incorrect_num}\")\n",
    "print(f\"accuracy: {correct_num/(correct_num+incorrect_num)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_wrong_classified, invalid_count_wrong_classified = process_strings(np.array(decoded_predictions)[incorrect_indices])\n",
    "cleaned_true, invalid_count_true = process_strings(np.array(decoded_y_test)[incorrect_indices])\n",
    "print(invalid_count_wrong_classified, invalid_count_true)\n",
    "int_decoded_predictions = [int(x) for x in cleaned_wrong_classified]\n",
    "int_decoded_y_test = [int(x) for x in decoded_y_test]\n",
    "plt.hist(int_decoded_predictions, bins=range(-100,100), alpha=0.5, label='Predictions')\n",
    "plt.hist(int_decoded_y_test, bins=range(-100,100), alpha=0.5, label='True')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Distribution of correct and incorrect numbers')\n",
    "# logarithm y-axis\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wrong_classified(cleaned_wrong_classified, cleaned_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_key,best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_decode_encode(train_size,num_of_decodes = 1,\n",
    "                           num_of_encodes = 1):\n",
    "  # Create datasets\n",
    "  X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
    "  results_all = {}\n",
    "  # Iterate over encoder en decoder numbers\n",
    "  for i in range(1,num_of_decodes+1):\n",
    "      for j in range(1,num_of_encodes+1):\n",
    "        print(f\"Testing {i} decode, {j} encode layers\")\n",
    "        model = build_text2text_model(num_encode_layers=j, num_decode_layers=i)\n",
    "        history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "        results_all[(i,j)] = {'history': history}\n",
    "  return results_all\n",
    "results = test_num_decode_encode(num_of_decodes = 1,\n",
    "                       num_of_encodes = 5,train_size=best_config_key)\n",
    "\n",
    "results2 = test_num_decode_encode(num_of_decodes = 5,\n",
    "                        num_of_encodes = 1,train_size=best_config_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the results\n",
    "results_comb = {**results, **results2}\n",
    "results_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in results_comb.items():\n",
    "    print(key, value['history'].history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = max(results_comb, key=lambda k: results_comb[k]['history'].history['val_accuracy'][-1])\n",
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new cool model\n",
    "X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
    "model = build_text2text_model(num_encode_layers=best_config[1], num_decode_layers=best_config[0])\n",
    "history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions = decode_all(predictions)\n",
    "decoded_y_test = decode_all(y_test)\n",
    "cleaned_wrong_classified, invalid_count_wrong_classified = process_strings(np.array(decoded_predictions)[incorrect_indices])\n",
    "cleaned_true, invalid_count_true = process_strings(np.array(decoded_y_test)[incorrect_indices])\n",
    "print(f\"accuracy: {correct_num/(correct_num+incorrect_num)}\")\n",
    "plot_wrong_classified(cleaned_wrong_classified, cleaned_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTUqbQrbaKfB"
   },
   "source": [
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## II. Image to text RNN Model\n",
    "\n",
    "Hint: There are two ways of building the encoder for such a model - again by using the regular LSTM cells (with flattened images as input vectors) or recurrect convolutional layers [ConvLSTM2D](https://keras.io/api/layers/recurrent_layers/conv_lstm2d/).\n",
    "\n",
    "The goal here is to use **X_img** as inputs and **y_text** as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "5Kv1ZBYqHTG3"
   },
   "outputs": [],
   "source": [
    "def build_img2text_model(num_encode_layers: int = 1,num_decode_layers:int = 1, max_answer_length: int=3):\n",
    "    img2text = tf.keras.Sequential()\n",
    "    img2text.add(Input(shape=(5, 28*28)))\n",
    "\n",
    "    hidden_units = 256\n",
    "    # Encoder: Add num_encode_layers LSTM layers\n",
    "    for _ in range(num_encode_layers):\n",
    "        img2text.add(LSTM(hidden_units, return_sequences=False if _ == num_encode_layers - 1 else True))\n",
    "\n",
    "    # Repeat the context vector for decoding\n",
    "    img2text.add(RepeatVector(max_answer_length))\n",
    "\n",
    "    # Decoder: Add num_decode_layers LSTM layers\n",
    "    for i in range(num_decode_layers):\n",
    "        img2text.add(LSTM(hidden_units, return_sequences=True))\n",
    "\n",
    "    # Output layer: Dense layer with softmax activation for classification\n",
    "    img2text.add(Dense(len(unique_characters), activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    img2text.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "                     metrics=['accuracy'], steps_per_execution=25)\n",
    "    return img2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_reshaped = X_img.reshape(-1, 5, 28 * 28)\n",
    "test_size = 0.1\n",
    "X_train = X_img_reshaped[int(len(X_img_reshaped)*test_size):]\n",
    "y_train = y_text_onehot[int(len(y_text_onehot)*test_size):]\n",
    "X_test = X_img_reshaped[:int(len(X_img_reshaped)*test_size)]\n",
    "y_test = y_text_onehot[:int(len(y_text_onehot)*test_size)]\n",
    "\n",
    "\n",
    "X_train_batch, X_val_batch, y_train_batch, y_val_batch = train_test_split(X_train , y_train, train_size=best_config_key, random_state=42)\n",
    "epochs = 10\n",
    "model = build_img2text_model(num_encode_layers=best_config[1], num_decode_layers=best_config[0])\n",
    "history = model.fit(X_train,y_train,batch_size=32,validation_data= (X_val_batch, y_val_batch), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "print(\"Result:\")\n",
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "plt.plot(np.arange(1, epochs+1), acc, label='Training', color='blue')\n",
    "plt.grid()\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import recall, precision\n",
    "predictions = model.predict(X_test)\n",
    "decoded_predictions = decode_all(predictions)\n",
    "decoded_y_test = decode_all(y_test)\n",
    "correct_num, incorrect_num, correct_indices, incorrect_indices = check_classification(decoded_predictions, decoded_y_test)\n",
    "print(f\"Correct: {correct_num}, Incorrect: {incorrect_num}\")\n",
    "print(f\"accuracy: {correct_num/(correct_num+incorrect_num)}\")\n",
    "test_recall = recall_score(decoded_y_test, decoded_predictions,average='weighted')\n",
    "test_precision = precision_score(decoded_y_test, decoded_predictions,average='weighted')\n",
    "print(f\"Recall: {test_recall}, Precision: {test_precision}, Accuracy: {correct_num/(correct_num+incorrect_num)}\")\n",
    "\n",
    "cleaned_wrong_classified, invalid_count_wrong_classified = process_strings(np.array(decoded_predictions)[incorrect_indices])\n",
    "cleaned_true, invalid_count_true = process_strings(np.array(decoded_y_test)[incorrect_indices])\n",
    "print(invalid_count_wrong_classified, invalid_count_true)\n",
    "print(f\"accuracy: {correct_num/(correct_num+incorrect_num)}\")\n",
    "plot_wrong_classified(cleaned_wrong_classified, cleaned_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5\n",
    "def test_num_decode_encode_img2text(train_size,num_of_decodes = [1,2,3,4,5],\n",
    "                           num_of_encodes = [1,2,3,4,5]):\n",
    "  # Create datasets\n",
    "  X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
    "  results_all = {}\n",
    "  # Iterate over encoder en decoder numbers\n",
    "  for i in num_of_decodes:\n",
    "    for j in num_of_encodes:\n",
    "        print(f\"Testing {i} decode, {j} encode layers\")\n",
    "        model = build_img2text_model(num_encode_layers=j, num_decode_layers=i)\n",
    "        history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "        results_all[(i,j)] = {'history': history}\n",
    "  return results_all\n",
    "results_imgtext = test_num_decode_encode_img2text(num_of_decodes = [1,2,3,4,5],\n",
    "                       num_of_encodes = [1],train_size=0.9) # TODO change naar best config key\n",
    "results2_imgtext = test_num_decode_encode_img2text(num_of_decodes = [1],\n",
    "                       num_of_encodes = [1,2,3,4,5],train_size=0.9) # TODO change naar best config key\n",
    "results_comb_imgtext = {**results_imgtext, **results2_imgtext}\n",
    "best_config_imgtext = max(results_comb_imgtext, key=lambda k: results_comb_imgtext[k]['history'].history['val_accuracy'][-1])\n",
    "for key, value in results_comb_imgtext.items():\n",
    "    print(key, value['history'].history['val_accuracy'][-1])\n",
    "X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=0.9, random_state=42)\n",
    "model = build_img2text_model(num_encode_layers=best_config_imgtext[1], num_decode_layers=best_config_imgtext[0])\n",
    "history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "predictions = model.predict(X_test)\n",
    "decoded_predictions = decode_all(predictions)\n",
    "decoded_y_test = decode_all(y_test)\n",
    "cleaned_wrong_classified, invalid_count_wrong_classified = process_strings(np.array(decoded_predictions)[incorrect_indices])\n",
    "cleaned_true, invalid_count_true = process_strings(np.array(decoded_y_test)[incorrect_indices])\n",
    "print(f\"accuracy: {correct_num/(correct_num+incorrect_num)}\")\n",
    "plot_wrong_classified(cleaned_wrong_classified, cleaned_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnGyo_DIlymz"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## III. Text to image RNN Model\n",
    "\n",
    "Hint: to make this model work really well you could use deconvolutional layers in your decoder (you might need to look up ***Conv2DTranspose*** layer). However, regular vector-based decoder will work as well.\n",
    "\n",
    "The goal here is to use **X_text** as inputs and **y_img** as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwhT9fiW7p_t"
   },
   "outputs": [],
   "source": [
    "# Your code\n",
    "def build_text2img_model(num_encode_layers=1, num_decode_layers=1, max_answer_length=5):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder: Dynamically add LSTM layers\n",
    "    for i in range(num_encode_layers):\n",
    "        return_sequences = (i < num_encode_layers - 1)  # Only the last encoder layer doesn't return sequences\n",
    "        model.add(LSTM(512, return_sequences=return_sequences, input_shape=(3, 13), name=f\"encoder_lstm_{i + 1}\"))\n",
    "        model.add(Dropout(0.4, name=f\"encoder_dropout_{i + 1}\"))\n",
    "    \n",
    "    # Repeat vector to match the number of outputs (5 images in a sequence)\n",
    "    model.add(RepeatVector(max_answer_length, name=\"repeat_vector\"))  # (batch_size, max_answer_length, 512)\n",
    "    \n",
    "    # Decoder: Dynamically add LSTM layers\n",
    "    for i in range(num_decode_layers):\n",
    "        model.add(LSTM(256 if i == 0 else 128, return_sequences=True, name=f\"decoder_lstm_{i + 1}\"))\n",
    "        model.add(Dropout(0.4, name=f\"decoder_dropout_{i + 1}\"))\n",
    "    \n",
    "    # Generate the spatial features for each time step\n",
    "    model.add(TimeDistributed(Dense(7 * 7 * 128, activation='relu'), name=\"time_dense\"))\n",
    "    model.add(TimeDistributed(Reshape((7, 7, 128)), name=\"time_reshape\"))\n",
    "    \n",
    "    # Transpose convolutions to upscale to (28, 28)\n",
    "    model.add(TimeDistributed(Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu'), name=\"conv2d_transpose_1\"))\n",
    "    model.add(TimeDistributed(Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu'), name=\"conv2d_transpose_2\"))\n",
    "    model.add(TimeDistributed(Conv2DTranspose(32, (3, 3), padding='same', activation='relu'), name=\"conv2d_transpose_3\"))\n",
    "    model.add(TimeDistributed(Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid'), name=\"output\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_text2img_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_reshaped = X_img.reshape(-1, 5, 28,28)\n",
    "test_size = 0.1\n",
    "y_train = X_img_reshaped[int(len(X_img_reshaped)*test_size):]\n",
    "X_train = y_text_onehot[int(len(y_text_onehot)*test_size):]\n",
    "y_test = X_img_reshaped[:int(len(X_img_reshaped)*test_size)]\n",
    "X_test = y_text_onehot[:int(len(y_text_onehot)*test_size)]\n",
    "best_config_key = 0.9\n",
    "X_train_batch, X_val_batch, y_train_batch, y_val_batch = train_test_split(X_train , y_train, train_size=best_config_key, random_state=42)\n",
    "epochs = 10\n",
    "model = build_text2img_model(max_answer_length=5)\n",
    "history = model.fit(X_train,y_train,batch_size=128,validation_data= (X_val_batch, y_val_batch), epochs=epochs)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_prediction(n):\n",
    "    labels = ['y_pred:', 'y_test:']\n",
    "    for j, data in enumerate([predictions, y_test]):\n",
    "        plt.subplot(1,2,j+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(labels[j])\n",
    "        plt.imshow(np.hstack(data[n]), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "print(predictions.shape)\n",
    "for i in np.random.randint(0,predictions.shape[0],5):\n",
    "  display_sample_prediction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_decode_encode_text2img(train_size,num_of_decodes = [1,2,3,4,5],\n",
    "                           num_of_encodes = [1,2,3,4,5]):\n",
    "  # Create datasets\n",
    "  X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
    "  results_all = {}\n",
    "  # Iterate over encoder en decoder numbers\n",
    "  for i in num_of_decodes:\n",
    "    for j in num_of_encodes:\n",
    "        print(f\"Testing {i} decode, {j} encode layers\")\n",
    "        model = build_text2img_model(num_encode_layers=j, num_decode_layers=i,max_answer_length=5)\n",
    "        history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "        results_all[(i,j)] = {'history': history}\n",
    "  return results_all\n",
    "\n",
    "results_text2img= test_num_decode_encode_text2img(num_of_decodes = [1,2,3,4,5],\n",
    "                       num_of_encodes = [1],train_size=0.9) # TODO change naar best config key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2_text2img = test_num_decode_encode_text2img(num_of_decodes = [1],\n",
    "                       num_of_encodes = [1,2,3,4,5],train_size=0.9) # TODO change naar best config key\n",
    "results_comb_text2img = {**results_text2img, **results2_text2img}\n",
    "best_config_text2img = max(results_comb_text2img, key=lambda k: results_comb_text2img[k]['history'].history['val_mse'][-1])\n",
    "for key, value in results_comb_text2img.items():\n",
    "    print(key, value['history'].history['val_mse'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batch, X_val_batch,y_train_batch, y_val_batch = train_test_split(X_train, y_train, train_size=0.9, random_state=42)\n",
    "model = build_text2img_model(num_encode_layers=best_config_text2img[1], num_decode_layers=best_config_text2img[0])\n",
    "history = model.fit(X_train_batch, y_train_batch, validation_data=(X_val_batch, y_val_batch),epochs=10, batch_size=128)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_prediction(n):\n",
    "    labels = ['y_pred:', 'y_test:']\n",
    "    for j, data in enumerate([predictions, y_test]):\n",
    "        plt.subplot(1,2,j+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(labels[j])\n",
    "        plt.imshow(np.hstack(data[n]), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "print(predictions.shape)\n",
    "for i in np.random.randint(0,predictions.shape[0],5):\n",
    "  display_sample_prediction(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = model.evaluate(X_test,y_test)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FZ7Xx__nJmj7"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
