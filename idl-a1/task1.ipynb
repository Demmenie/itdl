{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 14:56:10.433783: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 14:56:10.448084: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 14:56:10.452141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 14:56:10.462885: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 14:56:11.215247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730901372.499691  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.518845  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.518891  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,Input,Dense, Dropout\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training - Loss Function')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Train - Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist_data(X_train, y_train, X_test, y_test):\n",
    "    num_classes = np.unique(y_train).__len__()\n",
    "    lenght = X_train.shape[1]\n",
    "    width = X_train.shape[2]\n",
    "    print(f\"num_classes: {num_classes}, lenght: {lenght}, width: {width}\")  \n",
    "    X_train = X_train.reshape(X_train.shape[0], lenght*width).astype('float32') / 255\n",
    "    X_test = X_test.reshape(X_test.shape[0], lenght*width).astype('float32') / 255\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    return X_train, y_train, X_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 10, lenght: 28, width: 28\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, y_train, X_test, y_test,num_classes = preprocess_mnist_data(X_train, y_train, X_test, y_test)\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "input_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730901372.794562  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.794695  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.794721  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.907400  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730901372.907515  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 14:56:12.907545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730901372.907597  141146 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 14:56:12.907621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730901374.986267  141244 service.cc:146] XLA service 0x7f829400c8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730901374.986349  141244 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-11-06 14:56:15.018958: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-06 14:56:15.162041: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/469\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.8061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730901376.994056  141244 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.4409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 14:56:21.140183: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_47', 336 bytes spill stores, 288 bytes spill loads\n",
      "\n",
      "2024-11-06 14:56:21.451854: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_47', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8665 - loss: 0.4405 - val_accuracy: 0.9691 - val_loss: 0.1028\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1030 - val_accuracy: 0.9743 - val_loss: 0.0793\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0708 - val_accuracy: 0.9774 - val_loss: 0.0710\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0539 - val_accuracy: 0.9818 - val_loss: 0.0622\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0435 - val_accuracy: 0.9797 - val_loss: 0.0719\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0389 - val_accuracy: 0.9813 - val_loss: 0.0695\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0329 - val_accuracy: 0.9802 - val_loss: 0.0683\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0288 - val_accuracy: 0.9826 - val_loss: 0.0635\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0243 - val_accuracy: 0.9826 - val_loss: 0.0634\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0230 - val_accuracy: 0.9815 - val_loss: 0.0744\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0960\n"
     ]
    }
   ],
   "source": [
    "mlp_mnist_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "mlp_mnist_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = mlp_mnist_model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "score = mlp_mnist_model.evaluate(X_test, y_test, verbose=1)\n",
    "# mlp_mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 10, lenght: 28, width: 28\n"
     ]
    }
   ],
   "source": [
    "def load_fashion_mnist_data(validation_percentage=0.1):\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    X_train, y_train, X_test, y_test,num_classes = preprocess_mnist_data(X_train, y_train, X_test, y_test)\n",
    "    # split X_train and y_train into training and validation sets\n",
    "    X_val = X_train[int(X_train.shape[0]*(1-validation_percentage)):]\n",
    "    y_val = y_train[int(y_train.shape[0]*(1-validation_percentage)):]\n",
    "    X_train = X_train[:int(X_train.shape[0]*(1-validation_percentage))]\n",
    "    y_train = y_train[:int(y_train.shape[0]*(1-validation_percentage))]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_fashion_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "# adapted from https://www.kaggle.com/code/pavansanagapati/a-simple-cnn-model-beginner-guide#Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAMtCAYAAAAYPwdHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd5wU9f3GP9v3+h1wd3BwHHCAFFEUERQUEPQExIogVqwExWhiYkxMoibG/DRGTSygJnYMoqJYKELEAhaQYkHpvd/B9bL1+/uDsHvPZ7ndW9ijPu/Xy5f7MLMzczPf+c7MzvN8PxZjjBFCCCGEEEIISSDWw70BhBBCCCGEkGMPPmgQQgghhBBCEg4fNAghhBBCCCEJhw8ahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISTh8EGDEEIIIYQQknD4oEEIIYQQQghJOPbGzBQMBmXbtm2SlpYmFoulqbeJJAhjjFRWVkpeXp5YrYl9pmSbODphmyAatgmiaao2wfZwdMI+gmjiaRONetDYtm2b5OfnJ2TjyKFn8+bN0qZNm4Quk23i6IZtgmjYJogm0W2C7eHohn0E0TSmTTTqQSMtLU1ERPrLMLGL4+C3jBwS/OKT+TIjdPwSSZO0Cf1rhjEHvqxe3UBm/t920D/O7Aw6+1svaJsngJvmDYLe3SMZ5z9/D+g9GzNBd35kI+jAruL9bHTTc9S1iYPA3rY16LXXoy58GduEf8PmhK4/2P8k0Hu6uEFnv/otaOPxJHT9jeVYbhPWbniebx+UBTrzXGwDO8twH7R4Owl02hfrQNf1LAC9cQT+sjeq90LQuzy4/IXv9wCd9/jXciTQVG3icLeHIw1bB2w/gXUbG5jz8HLE9xEJvHfQ140d56HuOHo16C2VGaB3rm0B2urFbQuk473F8JO/A/3h99gndL4H1xesrNrfZu+fRN5TKeJpE4160Nj3OssuDrFb2DkcNfyvTTXF68gmaRMR23kQJ4Udb+ocKU7QNhdOt9vxBsEWUA8aQXzQsDnx+7ZkF2hrklq+FddvOVzn0dHWJg4Cu1UdE7c+JjhdErzNQdUGdZvR+8hYsI0dMo7hNmG14TGOOO9TVBvxqumO6OexXR1jaxL2I65U/Judjhj90BFw3ohIk7WJw90ejjRsqn0etutCLI70PiKB9w76uqD7bX0vYQ9Gv/ZbrbhtJgnvLZyqj4i4d7Dg+oLx7KNE3lNp4mgTDIMTQgghhBBCEk6j3mgQkhBivcaL8lovMPBU0GtHY9N9YNA00HVmF+h2DrQq5YybCbqnS/26HSf/Lm8J2tfBBvrmS9CWs8ATfsYfv/QqmNb6MfzFwrJg2UFt2/GCLQttMZtGoe/31otmgC4dngL6+/I80NU+l9L4y1LLlArQGY460OdmvQv6t59fBtoSwDbd4rkvhcRPxZV9Q59bj18D00o9NaALHGX4XQ/+enhKmy2gb//7XND93Pjb3NtV6aCrg9hGPi8/AfSmKmyjXS5YBXrAtaWgH180JPS509jFQg6O5gtw/5+QuhP08spWoKvGoQ0msHxlXOuzdWwP+rL38Rxv6VgB+sPSnqA3nIt9UKCsPK71H7PEaQmytwnbn366G/MEF/bD8yrLvhb0Ti/eO6TZsZ//a5v3QLc/KTXqtlQF8fszanJB+0/Ce4fs+ZWgf6rCe41vvgrbQ0/423pc1g5s34cLvtEghBBCCCGEJBw+aBBCCCGEEEISDh80CCGEEEIIIQmHGQ1y6Ijho7S1aA669j9hr+P4grdhmtOCIzds8KKXdpcXvdM/VOMQdX6DPsgkKw5v2ykJvY1bvM1A+9T3gyb6yAv31OWAbuEID1H36+5zYFrmS+grv2/5CNAtL/4p6rqOVwKl6G93lmN7+8//DQV9xp2LQI9ttQD0We4S0Fk2HNJ4ubcW9AY/+r/vWnI56LzZ2Ga80a28pAGsJ3cFXT0q7Ftf/BN64q3JftAWK7YJE8TzdpMf+6B7qy+Nui3+IP5WF1D9wJ4KzAEFAjh/0I966eKOoB2twn3Bqud6w7TOt2D7JbFx2bA99ElBP/7QdBxyuuVMHHJ6nQ+vKzfMHwv6wwFPgXZb5oMuViMU/ejB61KBezfotWXYfkjj0H3EsP+Ej0Pzcsw8rKvCe4daP2YkfQHst6u9mMN6a/kpoJNTsM3oc97rxdtuhwPvZdo2w+vYJjteV1LtuPzBZ4XbbHFvvKjsfPkM0M3/fXhygHyjQQghhBBCCEk4fNAghBBCCCGEJBw+aBBCCCGEEEISzvGR0YhzzGVbc/TjlxZ1Bp3++ldxrc9iD3v+jM+r546PWFUYE1hi/lCTPh23/YrmYc/815WFME1nJJJsPtC1AVVt04LLdlr8Uad/V401GOwqE6JxxJiu2eVNC30u8aGvUuc9/tx9OuinT8d6DLLw+7jWfbwQdOJ+tJdh5e1PXzwdtOMGPIZ7AnhcmtmqQP9U1wn0Syv6gs59NQl0eXvVZosPUyXwo5xVv8baF8ESWwNzRmYyXC7sJ/x+/K5PZSY2bkL/trUCL5lBNx5Di8p8GGeMY6zmFztub2BzOBeU3RX9++VXY3vLeC3GdYnI6rJs0N7mePyX1LYD3dO9CfRZbrxudLpuCejHvj4X9K9bfgT6+zq8rqRY0W//fSVmNkTKhOyHGPc5pX/F8/zLsvD9w/oKvL9z2/GY6uuvR2U0LOpeQWcyPB7sI/wqk2FXmYy0ZKyroTMingB+X9f+sVnD9xIpDry/7HgD1n2pmIZ5D51rbCr4RoMQQgghhBCScPigQQghhBBCCEk4fNAghBBCCCGEJJzjIqNhsaHHzviVP79nN9A/jUNvthWHyxdHNXq77bXow3V89A2uL1ouQ+c51LaKBZ8FY2U8LPbwIbUYI+KPMvNhxn9OL9DDmmMWYUl1u9DnZFXnwqX+sBxnBehzU7DWRJ4NfZUOtV8rg7i8ZCseB4/BY6yf0NOsOLZ2TRA9ouv8eKrNrDwpPG8AvyvKtl1n0LO56ib0aHZeKGQ/OKrwmNe0wKOWvhGP+aI/nAb6v/noga9rgQcmfQO2iZYl6L2tyVa1VnRvGyNuRfZPwSu4X8tvD5/7pbvTYJrZhedKTao6CP7ov7VZvCpz0QL7oYhDWIHnqqUuvt/yrGp9gfRwmyremgnTOjOTETdbN2KdlJRO6K/Xfe3uINaxsFnQT6/5alsB6M75+P3Zqo5GS0cZ6FwXXseKo66N7MPeoR3oHs23g95cnRn6nOzAa7NHXZububGOVXYSXifsFuz3/UbVyVCZCm8Q+6tMJ95QtnKXg/YEsQ3qvKlHXUh21ob7PJ3fyHVjzZCVV54MOufpL+RQwDcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThHB8ZDTv+mTqjsbkoE/RVZ3wOekFxB9AbXS1xeThcvtiHnAG68zNbQ5/9G3Bcbj0etN42jS0Lx0GWAPrCAxVhj6cxR3BAQ0S2nIPZhOZ2rFOQZQ97JXXdDLcVfZYlPvRmX/HMXaBTtqGvMm0jenOr8tE7m7oVpxsreqetXlxewKXG409HvesUbIN/GjM59HlxdXuYpvMoPoPffXzQf0BPlI5CIrH69VjreAxrWjRcf0FEJLkEj3HqDlyeL1nlfNrgcdKlVSx6c47ekjeHFZ2Bq+l7Zujz6UUrYNrCpVjrxKLqVFiT8VwL7sF+QGcmTAn2WTaPylQkqf5crc9eiW3G11yN4a9++7Mmh6efcCdeO+Kr3ENERNJWod/dfS5eR4LKb7/Zi5mOcvcanL9/T7UGbE+7AtWgrcrfn2LB+TfWYI0HkRIhsfHnpIPul4HZg4+DXUKf0+14bc9zlYGuCeI53syOx1Dfi+hjqmtq6TblUvcuNsHv6+u9Xr7OcEi9P31ZZRucZMc8SN1AzGzI03JI4BsNQgghhBBCSMLhgwYhhBBCCCEk4fBBgxBCCCGEEJJwjouMRrAu+tjX3lMwGzAyAz3AOg/wqRU9c1s/zgcdOAmXt/GxcH4guPRMmNb8B/TzpS/F8Z9Lzm4NurgXen5z1VDqWXPXhj6boPeItnheMPRr0NVqjPH6+12Pdd3Cjl7D1bW5oPMeQY9m5WisibDzdAzWtPo7zr/1HjxOLb7HNuBrgT5JY0OvdvIO9N4W3IfFLupGh7+vMxktHPi3bfNlgh6fuRz0pF4X4bYsxunHKzpXY1F5KKsyuavhzqUu8yB/h9FFFlQmI2hnIY1E0PZP4XP34qs2wrRvc7H/rNuN532gBg+6vQaPub0q+jGKyGBUq7pH6gobdKg2WKVqraRjZiP7o/C4+IGS3VG3hcQmdQteu/U1R/vr02x47zCvNhv0B288D3qdD68Ts6qxrobbgtO1/35rVQbo9CP5An4EUXwK1ivR+/nMjPB9kT7GDguecyV+zHvM31MI+ttNmIOwbcLaFfZq7DNsGAkRR7XqA3BTJeDC75d1x+27Y8BHoHd5w9vbOWUXTGvrxPbzeTL+LYcKvtEghBBCCCGEJBw+aBBCCCGEEEISzrFpnbKo193KMlE1Cm0013b7BPRaH74ebePcA/ryvMW4/KtRP7VyAOjqdeHXodYU3JYdffFZb+tFuG7jw9dmWUvU0GfX7QRd4Q0Pxev31YlMlyOW3+bgMMIfqGFe6w8Dl+XAV8yaDknFoH8QHJbw88eeAb01UAN6QOdfgF4/Auc/+/tLQM/p/gboZCsOiXdfcXfQX52MVquaeq/sdfuqMzivL4jHfHo12kG2n4Wv21uq5nm84k3FfkC5JMRWp4YiVdYp5WqImG5iOJ/UqIYROoBv3EkjsTjwXDO+sPXw1aHY98rD0ZdlU1YpPSSxHq7WVquGu1VtQs9vVcPf6jYQgZqe+cqXMb5A4iF1C1qhyoLJoLWVSQ9lukvZav5ZipbdNCsuX9t0VtXh0Ph6SHdrxBjYpDFkT8Tz5JW5g0CvuT58nFxdy2Fa64fwGJtF36ul471FR6Vt6dgmLGmpuLwUtGsG05V9Mwmv9/ZK9FrlPP0j6JmSCbrX0nCb7Z+yCqZt9WM5hCF5K0EvPkTvGvhGgxBCCCGEEJJw+KBBCCGEEEIISTh80CCEEEIIIYQknKMzo6EzGHHS9zc41Oig1B8bmHMvrdW4lNUGPcJlARxa7b5uH4Iu7hwe3laXl//XahxGtWod+u1tfvxb+96wFPRlzRaBfuTtHqHPfqPGTTvMmH49QX/tWQE62lCDeri6lg70WS6twWEENcMuGwvaWovLa5uP+3nYH88DnWbBTMdITxGuQA2lWjakM35fcBziz0rD0wc2Q9+k9gVrXexPA113Bvp85QkhEjm0aESmQke59M8uenqc81sxXhUxvx5OlzSO+pkMjX/dBtTrzwDtLKjG6XXo0bfp4WxVTkcPVanPezsuXuqaRx9SWf/U59riENJ0OLaVgr4sBfWkcvTb677Wpu4F9NDkmsogBrFsqkHVBfF41/mw00K3P2mIVZNOx39QUZdWn4b/wbIMj7E3CzvqK37CIWL1MVtblwP6xwrMXGytxKPm8asMiMHlWSyY68lNw+v5jW1wyO63dvUCveSmcP5kWTkOX2u2YYY3WIP3MYcKvtEghBBCCCGEJBw+aBBCCCGEEEISDh80CCGEEEIIIQnn6MxomIMba3p1FXrsdqejp26HPxN0cxt65tKstaDbObDMe3FA+Trr1YDwKr/9A93fB13XFT2behzuM93bQF/+47WgU2SdHKns/DUanFvaKkBvEKwh4qnnX81VmQw9nnlNAHMz/sGngq7Nxv1a2wyfsZVVVqpbotfRquIudlWDIeBEr7YnE3Xdz9Arfmbqp6HPu3z4t3R2bwetfcEZNjSCX9f1a9CfCnpGj1d0JsJeE71uRkTdC2XX1zUWIlcYfXKEv580Ocaqzp1U7Lt3qzoKARfO76hUtVhUP2FVxzSGZT9mG0radXD5QxId//qNUafr622suhiagPrtNtmCDcKlglvJqgGVlWPes0XUtZF9tJ6L5802LKMhJReFz/tHTnsbpt314dWgX/n9CNCeDDymFXhrIH5VG01fB4xdXXccqC1e3PbqIOZ0/zb1CtDOSvx+6W/C9wN+XyZMC5bhve495+D95vRzTgLt375DmgK+0SCEEEIIIYQkHD5oEEIIIYQQQhIOHzQIIYQQQgghCefozGgcJNkuzFzoGg1OC/oot/myQK+uPQH0qgr0wZ2fuxx0/ToI2m+vPZ95DhzXu86gKVhXxuiXi5mMZXLk4l+I+/HhFkNBj87BmiCdnOHxrPNtOPb0i+UngvYEsSnPeGUSaJ8JKK3GM1fabVFeWyseB6t6RveomiUOCwYA1vlw+gt7+oU+t3bhMdft0aHa46dlXUAvmI0+ywL5Qsh+6lwodB0Li6qZECvDEQvVJMXmwXO/Npt+/IRgrXeggnieJ2/Hg2brrg6yOqY2jy6WgjLoxH+w1eH8ASybIHY1XWc6vM1we1K3NpwBsDgwhxatnghpHKXB2qjTdebCIYGo02PVQNLXKZvqdIKVrKNyIJx975egqwJYk2txSX7o8wvb+sO0awd9Bvq+UdHrqlUFMbezJ4jX5zoV7gsoXaMKPLnVPWCGKrbTxo4Z4uVebLP3brw49Hl1CaZ63N9hh/TUuotBt9p+aO4V+EaDEEIIIYQQknD4oEEIIYQQQghJOHzQIIQQQgghhCScozOjYUHPm8WGPkjjR8+cLQuzAQMyvwddHMA6BmUBHFs901YDutKPvrc9tTh/FxfWQVhS0y70OduJfny97A1e9Nh1cuG4xo/sHAw6370HtH/w2eHP/jqRT6bLkUKbh9APWP4QTn+hJdaaqD0p7KvccQv6Iu8/CceDXl6VB/rvuzHDsboGczQpNj2+uU6/xIfVEj17s9uH46N3TA7nT15e0xem5Vy0IsbaMGPETMZe7C1zQeuMhehIhB7v/CB/dtEZj6AdV+hQtVf0+OvWlHAbCVZjrRRyYKRvUJkHdZ4GnXjQvJk4e8pmbBRWv6qX0wyX5yxT1ya8FInqdiLqfBxkN0TixBdnTS6dybCJylioTsajMpb6OhFQnY6tmr/9HghvftQPdK/+K0H/uvCj0OdfLbwcpq2d1QH0K9lng07ZgsdEX1d0Fi+QFL1ek8ai+hS7ig3pPsGHkQ2pyw93KmuGPgfTrs8bCPqVAsyjDFl8A2jbJ0uib+wBwlZNCCGEEEIISTh80CCEEEIIIYQkHD5oEEIIIYQQQhLO0ZnRUL5Kix3/DJ3R2HxjV9DnJKO//4u61qCz7ZWg9VjYrVzloNNyMT+gMx7N7GFPfWUgCaYlq4HV9bpPdZaA/sXcU3HdJ+4Gne4IPzsGj7LnSP+OnaAd9XTr2lNgmvsFNC5qb2yGHbMv+pi5rNhG9DHW6PHOrcrgr7/fwoHHscKPx73+cfYsbBZ13aRxmBo0t9o8eoZ4Fxhjui65EGfdDmcFLoC5jMTjqNb1cmLULtG1VNQxVcPzR+RyXKXYaOpa4PpUVCuCgIu1VQ4lDkt8+1tnMtzaQK/ag87qBVX703WygtmsjXIgJJ1QBrq0Du/BPq/oHPqcsgivxbV9sN8d3gnraARVJxArz6nvBfT3rfpeQuV29L2JP4jfX7InH3TFW+F86oO9MZu6cHMB6B47rgSdv2QN6Iar+BwcR9edKCGEEEIIIeSogA8ahBBCCCGEkITDBw1CCCGEEEJIwjkqMxoWhxN0sK6ugTn30uJ79D2WBNAXmWlFP79T+Sq9ynN3ZrP1oItV7mJJbXvQabawdzzbit79fAdmLL6vQ//djOqOoG+8YC7o/zx3Lm77rHBNBas5wgdlV/5YqwsN0HBcVS5nnRfrYjhjZC70+OcancHQ45sfLNF8nSo+EkFEBimgnJRxjgV/rGJMfOOXNzUWtT3a308SRLBhZ7HVh+f1rt1YM8nqxfPcWRb9vHeVofb5sA9TUSxJ2oVtoDZbjZlfpRupMvmTJsUWUVxHT8fjoa8TDlUopVrwJNd+/GRVSKUmiPN3arNLSPyc3Xod6CS1n8/P+C70+csdp8O0ilq8H6wN4P3l1poM0HYrHlOPH6/PDhv2RzpjYVROx6IyGi3cmBmp8eP2dc/E2mqLasIZjfYubD/dWuK8hamY+f2h3Qmg5bsKaQr4RoMQQgghhBCScPigQQghhBBCCEk4fNAghBBCCCGEJJzEZTSU395iR1+Zxaaeaayog3X1Br2P4rkVETG++Maa/sezT4He7M8EvcOHOtOGmY2A8nF+VYuePT2WdrYdfW4VQWXcrUdl0A1aZwv0sn/TfDXoaeVDGlz2EY/ysAc9uvBBGMcPmItZU5MLOsmG+6nUH33Ael13Q9fFiDWetPbq6uOm159qb/hvc1bEyFjYlI9b1Ykhe9FZlojpMWokxFz+QX7fWFUfqRuZtd5xjtEHknpE2W+eTGwTmRmloPfU4HRPM7y26LPWUqLygcnKw5+O3w96YwSFrHjuV7bF60H9XiTe6x6JjTVGHQ1dB8MaI0OjMx0+weOvs3p1QbxPKsrFGg6zBTNFZP/YrXic9njx+lu/XomzAud1JOEx8auO3amW7bTh9VffO+ht8VuwDejcjl/dOzjU91MdOL9uQ8nFDd8PdEnD2mQRGaG22L7c30mTwDcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThHHBGI2Jsf+Ub137SRJZ0qL0Ix0HefDF62q46ZSHoHf400Etr2oHOqFfnQkQkxYrO3Pr+PhGRbd4s0DpH0cxeBTqnXmZD12fY6sNlaXReZIsfl115IdblyHwl6uKOaCwqi1C/TQUq8O+uUBmITAcewxo1Frb2Jmpfpc5s6AyGnl97dwMWPK6l/mTQrZxYLKO+19cSYB2MRGBJwX2uDpmo4cpFDWcekZnQGYx463IYnVvT9U7UBliTwv78YDWOpU6iECXPkrwD+/KdPzUHnb5V1cFIxr7erko01ebgMbSqDIZzE7ZBmwp5+PBSJEk7cHk1eewLmhJLr+6gM6zLQOusna7PpNE1t/R1w2aUVp2SrqNxWjLWg5gtPaOun+wlIkujOnufCd+vukrwpHYnqRpcQWwDOnMR1BcOhZ4emQdFalWdDJ8D16/zp7qOh3tL+B6wxI+ZC08Q79Ndqj1703FrMCGWOPhGgxBCCCGEEJJw+KBBCCGEEEIISTh80CCEEEIIIYQknAPOaOhMRswVtWoJ2tce6yDs6Rr2tta0RE9bz2E/gR6b+yLo4gD60hwW3LbNPvTlnpK8AfTH5d1Al9hTQesMx5kpWMuiLIi+3Dw7jtX+mzUjQ59zkzFT8a+CGaB9ytO50oceznLlH/x5t3mg35FsOVoxwSj+ZOXD9irvYVAZ6rVPUns4NT41nrnO3Wj0WNh6+Xr9Ed7fevPr+gwRRNsvJIweE1/JCGttrN0a3YobNzqzEbE6XS+FHDRbB2DfnLoBp2dsUP7nWjyP7WUYsvBnYn9c1wz7DUe18uR7cHlVrTE7pinNwe/bC/LD6964GWe2qvbC2isx2dMD7xVm1eDxrAqgSz3Nitd+jduC7SdWnQ19ndijsob9XPh9z7DeoF0zFkVdPtlLRBah3vXXvmkXTEtzR6+5pdH5D113w60yHXZVlUtnLHSuxxvUtVei32tb6tWg0/clel06sxG0Jfgi1wB8o0EIIYQQQghJOHzQIIQQQgghhCQcPmgQQgghhBBCEs4BZzQ8Q9E7mHMvjv/cM30L6G5J80HXRfHE/1jbGqbVBNHXutqLeY9yVbNAe952eXHw8r+vHwL6v6dPAv37beeDtiahJ293ADMcl6VWCIJ/27i2n4U+d3CiP/CD6lagt6m6GrkOrL/QzlEM+tK0VaCP5oxGPAzMWgn6x5o80NrXqOuXaK+sbjMHi15+pfL+1vdSxlufgTSAPcE7Umc4YthZY9XNMMoPG3HcnQ4hjSBKNsF2QkeYVNsFx8wPbEBPvjcT97mnGS47bR2et8pSL9UFeJ47yvGS6kvTv+VFDwbZqnD+ddeHMxpt71cZDWYy4qZkINZTCkj0LJ9N+fEDuvaNymQEY/x261LZP11jYXJlDug9t2D9qFYY6ST/I1Zti/r1S/w7dsI0t71t1GX5VWZC5yA8ATzn7RbdJlRdjUD0NlIXULV8dG0W1eZMSriPWlWD98aZdqzDpgk0VeEMBd9oEEIIIYQQQhIOHzQIIYQQQgghCYcPGoQQQgghhJCEE1dGw2K3i8Wy9yt9HsLxnAenLQddY9R44yqTobMI9clQvjKPDzdzlw/HwtZ0du0AfUn6MtCfPdUHdP+620GvPQfrdPy3Fj16xX5c/xXrzwG9ZFM+6L7t1oc+90jbCtN0viTNhp5iXROkOoj79as6zIsc1ZjG5yTqTHQ/e4Ydxz/X7U9nMqzKT29VXmrts7Sp6TXKcJ9qx/H3S314nOvX/Qg4Ypn/E5sfOWbRGQllYVd264i6GibWzy4x6m5EZDKsMY6rnty8Xp9YsjvGxhzHRMkmbL4QPe5JK3B6wI3HyKnidTVt8VxL24p6Txd1yVSnZvJWPKhlJ+L63Lvw+55m+Lc4y7AR1uaF+3/LKd1hmlmK11wSm8tPXgy6MpAEWmcotB8+INjPx6q3pHGq63kLO2Yw9qj852+6fgT6FcF7C3LwZDjxXkHXxYhVmyJWvjMiP6Kkzo8G1fW+yo/3fA5VpyOQEs4wf7IRM2pXdv4GdLkf23uMaEvC4BsNQgghhBBCSMLhgwYhhBBCCCEk4fBBgxBCCCGEEJJw4spobB/fS2yuvQPv3p/xJEx7fU9f0PnuPaALnCWgT07a2OB60qyYUzghHX2NH1S3Af1JWRfQrRxloD+vKQQ95f6/gR77i7tAnzHjZ6Ar2uHzmD8FfbfpJ6Of+venfAjaWc8sXhZAr34zVzXoTFv0cY919iXNiv7C+uPIm4BHZHXUxR21lPiwNoqum6Frr7iUN9anMhU6g6G9t+XKy6vHX0+2YSYjqHyXO4IN54q8mYfIKHmMY1yYw9GZi5h+VD09RiYjXiyB6CGRYDKe2yR+qrvjeZiyHPepzs0E9C53ar81NqJYNW8sQaO0qruAmydJrdGj76/EfsJeEV5hZUf076cujb4tJJLLMjFb+n0dZh50HY1AjN9i3Ra8Tmi/fSx0JqS5DdvDgKTtoF9LPiH0OVgT/V7heGJzLWZ+W7oxfKWzrvVp7sL9WKkyEfpa7o8RmdT3ElZL9PynzlzoTEetH69r+vv1+zTPFuwjkrtg3ZhSg/efh6qGF99oEEIIIYQQQhIOHzQIIYQQQgghCYcPGoQQQgghhJCEE1dGI3lXUGz/87B+UNETpnVIKgatPfSzq3qAbpNUCjrDFs4adFR1MJbVZYKeVYzjiecloR9vpy8D9G5fCugaVYvi348/BvrvO4eAvqTZEtAnOzGTURbE57UfvS1BVwbdoc+6/kN5QNfRwMyFz+AhsqkxljOt6C+s6NE89NnvqztmMxo6YxELPdZ1MMb3tVdX+yI12sepx97W0+vXQ/G7JSommOCwwDGKcahjqutk6EPexLvV6o++gogh+PmzzwFhPTGc0bPtwGyWzmA4MBInQX0F9GOj8SdFPygWNb8eUt9EZD6wEdbV4vYGs9FL7toR3sCabFWrJ+qWERERe8tc0L2cuA+/qMHOt5nKSASUX96m/Pa6X9fX98jriLp+27BB3vPNpaDfPXMi6NqB4Xsf1wzMmxxPWN143HSuQe/3NR68J6tPiqp5Ve13NjDnvnXhMU+2Yw7CqzoVndHQuG14IdDfD6j7S50BMY7w9JRNOG+qqsvmUfXEgrFqeCUIXtoIIYQQQgghCYcPGoQQQgghhJCEE5d1KnWrR+z2va9a9Kuqj0twiNlcdyXonmmbQa+swVdZ39fmhT4vsbeFaUnq1VKGE18H6VdfLRy47vauXaCd6rXaojpc3/jsT0Bv8uPQae9Xdwb9Y00e6Cw72pm+rwhPr1Gv5TwBPAR1frSYZbjwb+3dDIcFXimtQBefHH52DNZZRd6VYxL9ajRiaFJFvMMO6uHwtPUq1vL19unzpb59z59Ma1Qi0MPbRs6AMsLm0sQ/u+g36No65U8Lt4lDNOrgMUF1YXhIWL2PlfNUAsoVETG8rRqONsJapWfPxH7CqoaiFLsailIdWPtGtICYDnjtMMXhDfCiI1jsrfAa6t+OlmMiUt6vHWibBU/yGtUAsu1476CtU/q6kK2sznp4+shh1NX6lY27f4e1oJPVdWR3t3D7ypshxy3GaAsbHid9z/jZ7k711E6YpofG19Ykf4wLgzXO4Wz18vzqHtBu1bZrXH6dsj95M8Lfb7YS/+4UNZ52hO3qEI2szzcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThxJXRsM7/TqyWvf6wNz/qB9P+cNGboD8tw8zGBzswe1DhVd7I5PAwb+kqY9FMjUmYoTIQbuWbLPXjcLYeK3raAsqntsOD5tcFwU6gfUH0WXqU1n7APd4WoPOSykOfK9VYphsqm4EuKcdBC+uS8RDNDxSCPr/lctyWXeG/LeA5RAa8RGEOPKvgjhgrNDo6UxFr+FpXjOVr76Me3tZuRa9tXT3zeJwj9ZIGCLjUjtSZCOwmIoe/TfD2aGuvjhVZfbjGsk7hPrH5JwnemGOYoD18ILXnWFnoJZCkvuvAY2DxRh+uVjcSZwoObRmR0fBiI6jNw0bYfAm22eZ9cej0NTvDG6wuOxLMweygMKMRwdaheNIt9uDxqlIZDZ2p8KqQTzt7CWj9S22aFRtcjg3vZVZ5cbjdyiA2yDMyMKNRo7anqhtuP9mLHnJWZyRX7MwJfS5QGY1YeUo9fK1ddQouG57T+n5RE2voe6/6fqzhcesywvM3X1YG03SmKOI+hxkNQgghhBBCyNEKHzQIIYQQQgghCYcPGoQQQgghhJCEE1dGoz4dfvMl6Ge+G4nTb10JemjLH0AvqcDaFZvqZRW+rcW6FA41rnCyAz1zuoS704aeO+1L0376FBsuT9flaObCjEiaKuuuPXcaW731LyxvB9Nyk9HD2TEdPaB6zGXt4Xxh/Zm4vCe/qPddn/wYdcuOMCzaNN+wN7FCZV2SnfF5V7UXV2c86gx6rbWPU39fo32XNuWz9NQbCztm/QYTvX2RvVTlu6NOj8hMxKqroQ9xjBCHsWp/v6qhoJq3zowkl6gQB2kUtc3r1Q5y4j5PKsZ5S7upa4Ebtb0SG4muu6GPWUYqevIDTswHWutwefndMEdhZuSA3l6ZhtvnDDdKk4ntwzgY7opFh3ZYQ6uDHQ/g2Wl4n6I97d/WFuD8qovp85tfg858Fe+LJm9eADrPvgH0Ol+6RKONukPr3Xl96HO5kH3oe7qI6/UWPC/rU+ZLBr1mD2ZsK6swRxMMRA82mIC60FhVDiziwqOk0g4ntslMp6rVklrvC2s2wTSbumj51EUwVp2gRME3GoQQQgghhJCEwwcNQgghhBBCSMLhgwYhhBBCCCEk4cTn0LLaRCz/84UG0QOXMfkr0Lsn41ffuqwIdJ/fLQJ9QbtvQ5+7ONU4x4LmabcyU6cob3Sd8vbrp6n5tfmgA2qOj0u7gi7zoUdvZw36Kh226N7q+uMy16px1str0fRpU36+uk/QL7j+R6xPkjED9+PxikOZp+tnIEQiczraw6m19jbq2it6ukbPH61OB+toJAZ7nfLfq5IG2hobMdy59sqq0zrWcbKpuhh6+ToDAt5aEbFvYEbjQKhrUW8/qv4zaTfu05J01QjsKqOxAw9aQGU+XKWoK2tUVizOn+6clZgNqypDv7glWK9GSA1uW3U++s6Tv4lv3ccDuz5qA3pPJzwJrereQtdXynVET0I4q6Ln52rUvUhZDFO8zgaWBLD9LlrRPvS5s2DNleMJi6Xx11cREUdVw7mKTAdmHpKdeE563XjM2mSWgfYEcLo3gOdprFIVuk6GTWWSS6rwPG/lrgD9dcvw94PVmCfOtKHWNd/0NbKp4BsNQgghhBBCSMLhgwYhhBBCCCEk4fBBgxBCCCGEEJJw4stoBAMilgN7Nkl5+2vQP7yN03+QsPfQ0vtCmFbbEjMSrt1Y56KyAKenr0VfmtWD/v3gtz/F2NqqGNPRI+drYK79oYZll+yY31gVx9KPcqLUzdAsLsGcTX6bPaBr1AD4uu6F1qk2T9TpWmsvr0d5b5Nt0Q399b9vbLEKNDR+vxzPpP0Xz+vSzieC9mSqTASWQIggsu6FGg89zsNS01LX2cDp7mUbQp+Z1mg8/pTwgbDVqrxelj4P8Vpgc6O2+rDfCNrV8jAyJ3W78drjTFGNpgXWXOqWhXU0FnZqBdoE1dWkXuakfl5DRMSbhn0QpjuIiEjeI1+ALrwzFbRVSkEv8rQGHatekq6Vo1lUhzXBdP60IogZn0LHbqVxe7s+Fr73OK77CAeGC6r9eN7WBFHrvrw+b8zqD9qfjnvWVYJtYL0NM7o6y6fRTShiW3Q2UF0XLH6c4c2KU0G3WdzwBlQHXaC96j4lZg2vBME3GoQQQgghhJCEwwcNQgghhBBCSMLhgwYhhBBCCCEk4cSX0ThEmEXfg3Y3MN8+0r+IPj36SNfkaCQ/rQy1AzMayVYv6N5J60A7VatwKGNkhjU+B2yNMl66lYH//SqszdLaEfYGJ7fHzE8EVmXyDB7X7twGCVTgfsx/6lvQZRf1AF3bAn9n8eFw5RH+VWsg+ojoen7t3U3fgG2s2Xs/gtbbTxqH6RAeB99sxKSCP8bFQ49hH8DIhdgwYiF5CzDLtW4MtgldJiHrE9yAj6yqDpJqM8kZGByqrQl79FM2Yj/Q/H3MJLFXiM15l48F/dGbL6k5toLaE9SpSpUFyMFjopqPnJW0HXSOTdU+sewC3V5lMs78xc9Ap/2I9cqOV6ypuB9tFn09x7PBl9HwXWCHe75M3IYdYQTVuwRdb8SXcWjyn3yjQQghhBBCCEk4fNAghBBCCCGEJBw+aBBCCCGEEEISzhGZ0SDHKRblgY9SP+LrHwpBL3S1xxnKcZxt44iR1FGP3LYq9Q968Gvl7dZjXesaC1Y1PL63njcy+5vo3n9mMhqJaj/Baqynk/46+ptxNHQRe6uWoP0FOaA9WTgmuT7GSZsxY2E2bIm6PRFHtf72s3ZKo+lwbTirYHyYzdL5pmx1LllPxuyU+RFzD5YTOoAO/rACdOf/xrWp0vxfMWZ4rvHLYq8QP5YFy0AX5fUEXTfidNC7u+EtUtJZJaBz/4sZDKzKItJnxp2gU7JrQKe+nQY6YzL2UWnCTMb+8G/HejSr1vYGvWY79t3Zi6L8pq7vOzRHcV/8y9lXgc4qwLoxLZYxo0EIIYQQQgg5SuGDBiGEEEIIISThNMo6Zf736sgvPpGj9y3ScYdf9vp1TBO8+muaNtF461SwFsedtASVNaoWjQXGH591ylKXWOuUUdapoDM8Q8CL3/XrmRPI0dcm4qHx7We/BNF24/djG/P71DFXi/cHcOhTY3B5wZjH9fBYp472NmGpd24avY+NOu+Nsk5FHDP8vkVNj30Mjw2aqk0c/j4iOn4fnvMBD94iBWqwPfh1n6Hah75O6e8HvGjxbcq+/2A40vuIiPsBZWIL1DtMkfv42LVOxWx/qr3H0/7iaRMW04i5tmzZIvn5+Y3eAHJksXnzZmnTpk1Cl8k2cXTDNkE0bBNEk+g2wfZwdMM+gmga0yYa9aARDAZl27ZtkpaWJpZYwRlyxGCMkcrKSsnLyxOrNbEuObaJoxO2CaJhmyCapmoTbA9HJ+wjiCaeNtGoBw1CCCGEEEIIiQeGwQkhhBBCCCEJhw8ahBBCCCGEkIRz1D1ojB07VlJTU2PON3DgQBk4cGDC1jtw4EA58cQTE7Y80jRs2LBBLBaLPProozHnvf/+++kJPcZheyCExIL9BIkHi8Ui999/f0i/9NJLYrFYZMOGDYdtm45kDsmDxjPPPCMWi0X69OlzKFZ3zPHQQw/Ju+++e7g3IyFYLJZG/ffJJ58c7k0Fampq5P7774+6XaWlpWK322Xq1Kkicmwdt6aC7YEcCvbdCOz7z+12S15enhQVFck///lPqaysPNybSKLAfoIcDPs7/zt37iwTJkyQnTt3Hu7NO+ZpVB2Ng2Xy5MnSrl07WbhwoaxZs0Y6dux4KFZ7zPDQQw/JyJEj5eKLLz7cm3LQvPrqq6BfeeUVmTNnTsS/d+3atcm35fe//73cc889jZq3pqZGHnjgARGRBt+UzZ49WywWi5x33nkicmwdt6aC7YEcSv70pz9J+/btxefzyY4dO+STTz6RO++8Ux577DF577335KSTTjrcm0j2A/sJkgj2nf91dXUyf/58mThxosyYMUN++OEHSU5OPtybd8zS5A8a69evly+++EKmTZsm48aNk8mTJ8t9993X1KslRyhXX3016K+++krmzJkT8e+HArvdLnZ79FMgGAyK1+uNOs8+ZsyYIf369ZPMzMwEbN3xAdsDOZQMHTpUTjvttJD+7W9/Kx9//LFccMEFcuGFF8pPP/0kSUlJ+/1udXW1pKSkHKpNJfVgP0ESQf3z/6abbpLmzZvLY489JtOnT5cxY8Yc5q1rOg5339Xk1qnJkydLVlaWDB8+XEaOHCmTJ0+OmKe+P/K5556TwsJCcblc0rt3b1m0aFHMdSxbtkyys7Nl4MCBUlVV1eB8Ho9H7rvvPunYsaO4XC7Jz8+Xu+++WzweT4Pf0SxevFjOPPNMSUpKkvbt28ukSZMi5tm1a5fceOONkpubK263W04++WR5+eWXI+arrq6Wu+66S/Lz88XlcskJJ5wgjz76KFRatFgsUl1dLS+//HLotd/YsWMbvb3HGt98840UFRVJixYtQsfghhtu2O+8sdrS/ry2FotFJkyYIJMnT5bu3buLy+WSSZMmSXZ2toiIPPDAA6HjUN+jGQwGZdasWTJ8+PDQcqIdt6VLl8rQoUMlPT1dUlNTZfDgwfLVV1/Btux73fvZZ5/JuHHjpHnz5pKeni7XXnutlJaWHuguPKZge2B7OFjOOecc+cMf/iAbN26U1157TUTCWcC1a9fKsGHDJC0tTa666ioR2Xtsn3jiCenevbu43W7Jzc2VcePGRRyDxrTNKVOmSK9evSQtLU3S09OlR48e8o9//OPQ/OHHEewn2E/sj3POOUdE9v4g3lCud+zYsdKuXbsDWv4zzzwTag95eXly2223SVlZWWj6hAkTJDU1VWpqaiK+O2bMGGnZsqUEAoHQv82cOVPOOussSUlJkbS0NBk+fLgsX748Ynsb6rsOF03+RmPy5Mly6aWXitPplDFjxsjEiRNl0aJF0rt374h5X3/9damsrJRx48aJxWKRRx55RC699FJZt26dOByO/S5/0aJFUlRUJKeddppMnz69wV+jgsGgXHjhhTJ//ny55ZZbpGvXrvL999/L448/LqtWrWqUJ7K0tFSGDRsmo0aNkjFjxsjUqVNl/Pjx4nQ6Q51WbW2tDBw4UNasWSMTJkyQ9u3by5tvviljx46VsrIyueOOO0Rkb7GTCy+8UObNmyc33nij9OzZU2bPni2//vWvZevWrfL444+LyN5XxjfddJOcfvrpcsstt4iISGFhYcxtPRbZtWuXnHfeeZKdnS333HOPZGZmyoYNG2TatGkR8x5IW9rHxx9/LFOnTpUJEyZIixYt5OSTT5aJEyfK+PHj5ZJLLpFLL71URARsFosWLZLi4mIZNmyYiEQ/bsuXL5ezzjpL0tPT5e677xaHwyHPPvusDBw4UD799NOILNOECRMkMzNT7r//flm5cqVMnDhRNm7cKJ988slxHUpke2B7SBTXXHON/O53v5OPPvpIbr75ZhER8fv9UlRUJP3795dHH300ZK0YN26cvPTSS3L99dfLz3/+c1m/fr089dRTsnTpUlmwYIE4HI5Gtc05c+bImDFjZPDgwfLwww+LiMhPP/0kCxYsCF0nyMHDfoL9REOsXbtWRESaN2+e8GXff//98sADD8iQIUNk/PjxoWOwaNGiUD8xevRoefrpp+XDDz+Uyy+/PPTdmpoaef/992Xs2LFis9lEZG/buO6666SoqEgefvhhqampkYkTJ0r//v1l6dKl8DDUUN912DBNyDfffGNExMyZM8cYY0wwGDRt2rQxd9xxB8y3fv16IyKmefPmZs+ePaF/nz59uhER8/7774f+7brrrjMpKSnGGGPmz59v0tPTzfDhw01dXR0sc8CAAWbAgAEh/eqrrxqr1Wo+//xzmG/SpElGRMyCBQui/i0DBgwwImL+/ve/h/7N4/GYnj17mpycHOP1eo0xxjzxxBNGRMxrr70Wms/r9ZozzjjDpKammoqKCmOMMe+++64REfPggw/CekaOHGksFotZs2ZN6N9SUlLMddddF3X7jlZuu+0209hm+M477xgRMYsWLWpwnnja0n333RexbhExVqvVLF++HP69uLjYiIi577779rveP/zhD6agoAD+raHjdvHFFxun02nWrl0b+rdt27aZtLQ0c/bZZ4f+7cUXXzQiYnr16hVqX8YY88gjjxgRMdOnT29wPxytsD3she0hsezbd9HaSkZGhjnllFOMMXuvMyJi7rnnHpjn888/NyJiJk+eDP8+a9Ys+PfGtM077rjDpKenG7/ff6B/1nEL+4m9sJ9oHPv2ydy5c01xcbHZvHmzmTJlimnevLlJSkoyW7Zsibhn3Md1110XcYz0Md23/PXr1xtjjNm1a5dxOp3mvPPOM4FAIDTfU089ZUTEvPDCC8aYvffErVu3Npdddhksf+rUqUZEzGeffWaMMaaystJkZmaam2++GebbsWOHycjIgH9vqO86nDSpdWry5MmSm5srgwYNEpG9rwVHjx4tU6ZMgddB+xg9erRkZWWF9FlnnSUiIuvWrYuYd968eVJUVCSDBw+WadOmicvlirotb775pnTt2lW6dOkiJSUlof/2vTqbN29ezL/HbrfLuHHjQtrpdMq4ceNk165dsnjxYhHZ67ds2bIl+P0cDof8/Oc/l6qqKvn0009D89lsNvn5z38O67jrrrvEGCMzZ86MuT3HG/s8rB988IH4fL6o88bTljQDBgyQbt26xbVtM2bMCL3+jkYgEJCPPvpILr74YunQoUPo31u1aiVXXnmlzJ8/XyoqKuA7t9xyC/yaNn78eLHb7TJjxoy4tvFYg+1hL2wPiSE1NTVi9Knx48eDfvPNNyUjI0POPfdcuI706tVLUlNTQ9eRxrTNzMxMqa6uljlz5iT+jyEh2E/shf2EyJAhQyQ7O1vy8/PliiuukNTUVHnnnXekdevWCV3P3Llzxev1yp133ilWa/g2++abb5b09HT58MMPRWTvPfHll18uM2bMANv/G2+8Ia1bt5b+/fuLyN63n2VlZTJmzBjod2w2m/Tp02e/96+67zqcNNmDRiAQkClTpsigQYNk/fr1smbNGlmzZo306dNHdu7cKf/9738jvtO2bVvQ+0547Susq6uT4cOHyymnnCJTp04Vp9MZc3tWr14ty5cvl+zsbPivc+fOIrL39Wos8vLyIgI1+76/b/zkjRs3SqdOnaBxiYRHw9i4cWPo/3l5eZKWlhZ1vuORqqoq2bFjR+i/4uJiEdnbkV922WXywAMPSIsWLeSiiy6SF198cb8Zm8a2pf3Rvn37uLZ3x44dsmTJkkZdMIqLi6WmpkZOOOGEiGldu3aVYDAomzdvhn/v1KkT6NTUVGnVqtVxM2Y32wPbw6GgqqoK+mO73S5t2rSBeVavXi3l5eWSk5MTcS2pqqoKXUca0zZvvfVW6dy5swwdOlTatGkjN9xwg8yaNevQ/LHHIOwn2E/E4umnn5Y5c+bIvHnz5Mcff5R169ZJUVFRwtez7/5NHy+n0ykdOnSA+7vRo0dLbW2tvPfeeyKytx3PmDFDLr/88pDFbfXq1SKyN1Oi+52PPvoo4v51f33X4aTJMhoff/yxbN++XaZMmSJTpkyJmD558uTQcG772OdF05h64WgREZfLJcOGDZPp06fLrFmz5IILLoi5PcFgUHr06CGPPfbYfqfn5+fHXAY5NDz66KOhIQFFRAoKCkIDBrz11lvy1Vdfyfvvvy+zZ8+WG264Qf7+97/LV199BYUcG9uW9kdDOZ+GmDlzprjd7tCbO5JY2B5IU7NlyxYpLy+HodddLlfED0bBYFBycnL2O6iJiITCv41pmzk5ObJs2TKZPXu2zJw5U2bOnCkvvviiXHvttfsdPIREh/0EicXpp58Oo87Vx2Kx7Pc47899k0j69u0r7dq1k6lTp8qVV14p77//vtTW1sro0aND8wSDQRHZm9No2bJlxDL0KGj767sOJ032oDF58mTJycmRp59+OmLatGnT5J133pFJkybFfXKK7G0QkydPlosuukguv/xymTlzZswq4IWFhfLtt9/K4MGDDzgItW3btohhwlatWiUiEgriFBQUyHfffSfBYBAO9IoVK0LT9/1/7ty5UllZCb+i6fn2/b3HE9dee23olaFIZAfet29f6du3r/zlL3+R119/Xa666iqZMmWK3HTTTU22TdGOwYcffiiDBg2K2M79fSc7O1uSk5Nl5cqVEdNWrFghVqs14qF39erVcDGqqqqS7du3hwKExzpsD2wPTc2+egyxft0sLCyUuXPnSr9+/Rp17YrVNp1Op4wYMUJGjBghwWBQbr31Vnn22WflD3/4A+tNxQn7CfYTB0NWVtZ+LXIH4i7Zd/+2cuVKsLp5vV5Zv369DBkyBOYfNWqU/OMf/5CKigp54403pF27dtK3b9/Q9H0DAuTk5ER892igSR55amtrZdq0aXLBBRfIyJEjI/6bMGGCVFZWhl4VHQhOp1OmTZsmvXv3lhEjRsjChQujzj9q1CjZunWrPP/88/vd3urq6pjr9Pv98uyzz4a01+uVZ599VrKzs6VXr14iIjJs2DDZsWOHvPHGG/C9J598UlJTU2XAgAGh+QKBgDz11FOwjscff1wsFosMHTo09G8pKSkwJNqxTocOHWTIkCGh//r16ycie19f618cevbsKSIS1xDFB8K+URv0cfD5fDJnzpz9vv7e33Gz2Wxy3nnnyfTp0+EV9s6dO+X111+X/v37S3p6OnznueeeA2/xxIkTxe/3Qxs5lmF7YHtoSj7++GP585//LO3bt485DOSoUaMkEAjIn//854hpfr8/dHwb0zZ3794N061Wa2hEoqZuv8ci7CfYTxwMhYWFsmLFipDlTkTk22+/lQULFsS9rCFDhojT6ZR//vOf0Pb+/e9/S3l5ecRxHz16tHg8Hnn55Zdl1qxZMmrUKJheVFQk6enp8tBDD+03Z1R/m49EmuSNxnvvvSeVlZVy4YUX7nd63759JTs7WyZPngyvh+IlKSlJPvjgAznnnHNk6NCh8umnn8qJJ56433mvueYamTp1qvzsZz+TefPmSb9+/SQQCMiKFStk6tSpMnv27AZfqe0jLy9PHn74YdmwYYN07txZ3njjDVm2bJk899xzodDVLbfcIs8++6yMHTtWFi9eLO3atZO33npLFixYIE888UTo7cWIESNk0KBBcu+998qGDRvk5JNPlo8++kimT58ud955Jwxh26tXL5k7d6489thjkpeXJ+3bt48Yyu544OWXX5ZnnnlGLrnkEiksLJTKykp5/vnnJT09vcl/pUlKSpJu3brJG2+8IZ07d5ZmzZrJiSeeKMXFxVJRUbHfC0ZDx+3BBx+UOXPmSP/+/eXWW28Vu90uzz77rHg8HnnkkUciluP1emXw4MEyatQoWblypTzzzDPSv3//Bs+v4wW2B7aHeJk5c6asWLFC/H6/7Ny5Uz7++GOZM2eOFBQUyHvvvSdutzvq9wcMGCDjxo2Tv/71r7Js2TI577zzxOFwyOrVq+XNN9+Uf/zjHzJy5MhGtc2bbrpJ9uzZI+ecc460adNGNm7cKE8++aT07NnzkFS4Pl5gP8F+ojHccMMN8thjj0lRUZHceOONsmvXLpk0aZJ07949Imgfi+zsbPntb38rDzzwgJx//vly4YUXho5B7969IwpNnnrqqdKxY0e59957xePxRNwXp6eny8SJE+Waa66RU089Va644grJzs6WTZs2yYcffij9+vWL+NH6iKIphrIaMWKEcbvdprq6usF5xo4daxwOhykpKQkNLfe3v/0tYj5Rw4jVH952HyUlJaZbt26mZcuWZvXq1caYyOFtjdk7zOzDDz9sunfvblwul8nKyjK9evUyDzzwgCkvL4/6Nw0YMMB0797dfPPNN+aMM84wbrfbFBQUmKeeeipi3p07d5rrr7/etGjRwjidTtOjRw/z4osvRsxXWVlpfvGLX5i8vDzjcDhMp06dzN/+9jcTDAZhvhUrVpizzz7bJCUlGRE5poa6jWeYwiVLlpgxY8aYtm3bGpfLZXJycswFF1xgvvnmm9A88bSlhoYpvO222/a7/i+++ML06tXLOJ3O0LJ+9atfmW7duu13/mjHbcmSJaaoqMikpqaa5ORkM2jQIPPFF1/A9/cNmffpp5+aW265xWRlZZnU1FRz1VVXmd27d8faXUclbA9sD03Bvn237z+n02latmxpzj33XPOPf/wjNOz4PvZ3nanPc889Z3r16mWSkpJMWlqa6dGjh7n77rvNtm3bjDGNa5tvvfWWOe+880xOTo5xOp2mbdu2Zty4cWb79u1NsxOOIdhPsJ+Ih8YMb22MMa+99prp0KGDcTqdpmfPnmb27NkHNLztPp566inTpUsX43A4TG5urhk/frwpLS3d77rvvfdeIyKmY8eODW7fvHnzTFFRkcnIyDBut9sUFhaasWPHQluO1XcdDizGNCLlRAjZL926dZMLLrhgv78oHSz7ioItWrQo5ts2cmTA9kAIiQX7CXI80eSVwQk5VvF6vTJ69OgIPyU5PmF7IITEgv0EOd5o1INGMBiUbdu2SVpa2nE3AtLRjDFGKisrJS8vL+FDnbFN7OUXv/iFiEjcHs7GUFtbKyJ7RwtJ1PLZJpqWo609iLBNkEiaqk2wPezlaOsn2EcQTTxtolHWqS1btrDOxFHM5s2bE168hW3i6IZtgmjYJogm0W2C7eHohn0E0TSmTTTqjca+kZL6yzCxiyPG3ORIwS8+mS8zIqqPJ4ImaRPRfs04yChR7QW9QKeu2AM6sGZ9XMuzdusMurhPJujmL0YfbvlwcdS1CdLksE0QTVO1iUPdHmyZOOTrygcLQY846VvQc9/rDbr1o183zYY1wO7rTwedPxrrOqz8NLz9+X89dNvGPuLAsZyKI8htOg/bpKsM57d58F4n5zOs+h1YuyFRmxZ5zxXHfVY8baJRDxr7XmfZxSF2y7HXEI5Z/tdmmuJ1ZJO0iajbeXAPGnYHDltpt7nUquP7G6zq+zanWv6Rep4cbW2CND1sE0TTRG3iULcHm8UJ2pqE/bQrFbfB5jq8/bi+jjhScPtt9YZfPqTbxj7igLHY8Jja1BDa6lZCbOpm/2DvVaJvnD6ecdxnxdEmjpwa5YQQQgghhJBjBo46RY4cLOq5NxhocFZbZ3wFvmpcNujZIx8FXehYdlCbFgkuz2OwWmfNH1Cf+a9fgW77wBeNX5XVhjrKfiGEkOOZta/3DH3+Rc//wrTLLCtBf1WB15HJNz8OeuE17UHP3Y02mMXr24IOVuKvzfZML+jxJ30GOsNWA7qTayLo/1Z2Bz189Pehz3PO7QbTysfn4LZ8t0JIExCn3ajFP7eA/lebD0CnqPueLFsyLuB+lJ0/uxb0JSd8F/rcylkG055cOgi/O34N6GBlJWiLHR8JjN8viYBvNAghhBBCCCEJhw8ahBBCCCGEkITDBw1CCCGEEEJIwmFGgxw+4sgenPktel1vzHoZdDMrjs6xXS3qk1p8ps62VYP+3pMH+qc61INSfwKdZ0dv4zY/DvGWa8OMxuKbnwD93XXhv33891fBtJyLlLdW7xdmNpoG5b212HA/m4Daz7GGAow1GsdBDNnsGYbDcLpmLMJVn3Yirmrx8oSt+7imCY9pvOx4F/MC2f9IAm2btwS0NRm938EazAccrVRf1gf0SW3CQ8L+e82ZMC0ntQq01YLH69HtRaBPTd8E+tJs3Kc5LlzejOV43g3tjOddZQBHHFpWifUHJu0+G/QJzXBo07nbTwh9zk8rg2m1j9aBdp0npCnQWVIT/frbJwOHzv/B2xx0phXPwzIPjjLVzbkb9Px+mOPJsaWEPlcFsQ3cec4G0B2evBF0p7GLQVuSsA8xKsNxoPCNBiGEEEIIISTh8EGDEEIIIYQQknD4oEEIIYQQQghJOMxokEOH9jfHyBZ0XRxunr9uvhCmza/LAp2pxiMPGvQaZlprQdcZ9N8PSNoMekgyjn29LYDzlwUxE5JrQ6/uzkCq0iAlzRr2Ui7tPQWmDZpzEWjnuRvxy3q/xTmuNzlA4t2vB3Ecai5B3/nuE7H91RV6QA/4I2aErLIB9LZz8Hw4Vvz5MYn33Ig1v9Z6/jjXZ3GhH9t48Liafj1Dn0f/axZMuzFjGehBv8N+wzZPrSwYjLotRytbB+M+3rmldeiz04VZuTo/1rlw23H6mrIWOH8Ab5F0psNpxb749E7ox9/jTQG9oy4ddTXqU3PwOlRch9cRW731/7CzFUxrkYq5Q89wleP6EHNc5MCIyO6p67FVVf6+JA1zOlv82Be7LVir4kSVydjox2zVsroC0FemhWvDlKlz3CqYbT3hUWwjET2CziEmCL7RIIQQQgghhCQcPmgQQgghhBBCEg4fNAghhBBCCCEJhxkNcuiI4Vfec8MZoP/e8unQ51m16GV1CHoJ0yzotfWpsa6DBr3TAUG9TvkgbYLb6rAEok73qMyHzmz41DN9TTDsFX6vGtf9RpfXQV905V2g01//CjQzGQ0Qrz9fTTd+fwMz7p8dd+CY/a3ml4PeOigD9NXXzQG9YE9h6PPdbf4F014rxmV/8sMJoLf8piNo66dLG7HFxwGxMhUx5rfYY1wilV/b4sTsVlCPQ69q4OhMRu1Fp4P+5xNPhj5XGMxzTCprDTrpVly2dlsH1bqOFVJaou+8prLefsJdJnV+PJ4OG+6lFCd62qt8uIDdNZi5cNmxj9AZDl8Q+/1WKRWgm7kxK6UzGTtrMHtV/zpmswYbnCYisuMs/FvbfyjkQIior4TH1OCth5Rd0hN0Gzter9epy0qGJfp5mWbFNtnOWQw6yxa+f0i24sb8bXcP0IF0bM+O9pj38K9XedAE1eziGw1CCCGEEEJIwuGDBiGEEEIIISTh8EGDEEIIIYQQknCY0SBNhvY3x/K8L3pwIujFnvD8Hex7YNqP3pagKw16XVPU2NRBlclwq8yFU40orTMcsdDz68yGnm61hNeXXq+mhojICh/6gL98dBLo4V/iePnaV2lxoE/c+NDjSQ6Q09Hvahx4jL390Y+/6hQcTz0tsxT0i+8MAd36k/BxemTeSTDNN7gz6OTeeIytHswEWXt2Ax1c9qMQiTvPFDOno6brzEUEyuNsOwGzNa8/+Rjodf6wZ9+tcmgv/WUE6IzVKrt1rNbXUb5xXT9iU0X4vKupwHMwWdXV0LhseDzdNjU/xunEreav9uN5maSyfHaVq3DbsL04LDg9WdX52ONRG1CPgMpo2AqrGpiTxIU6b4J1dQ3MuJfiXqg/U7P/WIfZqhszNuHy1b3INhWL6O3COhuBejXD1vmwvbz434GgHedjG8lZgpmNJH0vYcX5zQGW4uEbDUIIIYQQQkjC4YMGIYQQQgghJOHwQYMQQgghhBCScJjRIE1GLH+zf25b0D95vwC9wRfOYVycUgbTflSxA5/KRKBrNxLngZoNG4nOZGhdZ8J1NLT3epO/GehdgW2gt5+fBzp7IvoqjT+6D/m4IU5Pui0da7WUF3UFnbIVzbb2PdjKcl/KBO27Hb2023dkge70xy9xeQX5oc9+te3upetBW07rAnpTEY6/r6zf0nqZEJGDHhfe3g77LH8O1kbxZGMmYOdpDpyeg+szNjzO33pbgP6sMnycO7t3wLTm87fitjS00ccY1h6YV7JZ8Ty0u8P9n68CPeil5Zh/c6o6GIUZWPumLoDHL9WBJ5aum2G3BqJOr1EZDp0B0fP7TcP1oCprsa1puuZie4l1TSQNEGfW6fQzVoIOqmP4Yw1ev0eXYJ7u4hysgRRU7wNOd+0C/UBx+Pv3ZWMWzzhwWztMwaxr4MdVEo14a0k1BN9oEEIIIYQQQhIOHzQIIYQQQgghCYfWKXLY+Gvh21GnZ9rCL3ttFnwmrm892h/6dWXEcLVK2iSxQz/q9entsdUbwk7/LZlWHKq3uTUJdOkp+DozW6/8WBnG8iCJGF45oGwyaj9ZstAGY6/D6SUn49CSFWfhMV4z8HnQZ/7yZ6A7TVHDjyr8Gzc3OM20yQXt2qMsGXm4LUNHoS3r289OBm354tuo23KsYnGoNuFRVpeT0S4XfAyHLG6TVgx6aw1aX25r/SnoueXdQd+RPQ/0LauvBD2n/ETQGfba0Oc9AbT9GEdiL9/1zxeLMUesF6u2DdoE67x4DEywXl+r+nnrZrQbFavhZsuqsa/VrpmM5FrQXj8eg0DQEnW6w4btrdSF6wsE8TpR68VrQ8XO8N9uTcYDlJyKtq4NZWjBbZWPNjL/5i1CYmOx4zGINVz8qJxFoPPtFaD/mYfTl3mi2/FWe3NAX7vxbNBDssJ2qVO/GQ3TOk34GnSEUfQQDYHNNxqEEEIIIYSQhMMHDUIIIYQQQkjC4YMGIYQQQgghJOEcnRkN7SvTaO91vF5tBw5BF8uTF8FBDqEI2+JCX6Xxqm05iv34O/zoic90ov8Zswu4D+tnHEREKoPodU2zope2Ooj70W1FX6/OUHjVcLk2C67PYcHtifV9TYo17MvcHUDPcf1siojI9gBmNl4eglmAv0jPqOs6Xol1nkfMX4X7XR1SqTobj0PeFGxTRVf2BJ0m0TMZ8eDJRX++Nx37wJzF6Nee4T0DdEs3+oDdresNsRj0iOAIyscsRvmhNcFvfwJtvxaHotywFfsVEdRPS2c1HfuZW6U/6EfWvwU624b9+6O7BoU+/2cGerPbr8EcTqzrnJ4uKvdW/zpnzBEa0BCRmmz8O4p34nUkOT08DPWdPf8L05744ALQwR143TC5OIS104XHr6oOz3mvT+1z1cUEA+q6YMHrgsuB+9mjlldRjNeG8075IfTZH8RlfbquI2hHKrbNqp7Ylt3MaDSKWMPF1404HXQf13zQT+zGc/6kZMzi9XDhMNXfe1qDPtONw9d/7sQ+5tr0ktDnV1PwGnWkwDcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThHJ0ZjXhzCcqLKjH8p/FmMrb87kzQ/7zxWdCPFPaIa3mwLTE8xUcTwbNOAd1beRlX+9GPmm0Lj2FfHlS1I+zoTy32p4N2WHB+XavCZjBz4TNqPPQYdTACSgfVM7tVZUh0xqN+ZkRP6+HEcbfL1NjsNSpvQhogzn4isHsP6KTpC0G3nx79+9a0NNDBqqr4tqd+9kzNW5WH7ddVitOdZegjbvsetqHatrhtns4tQ5/9/rrjJqMRL/6taseo/F1kXY74+uvbfsI6Gp+e/B/QayrDVXI6n7EBpmnnuPHHuK7FmG4/SnI7tdnYH7pS8Hr915PeCX3u7doF097s2Qv0ji8xt5DTrRx0cQVek7yqzoVV1eHw+bB9OJy4z+02nD/Nhe2lXQb2QV9vxetacV14e/6v4F2Y1syJGbMvdrXH756MbTX/fSGNIUa/vW0Mtj+HyhDrPOh3Nfmgi/3YN1cFsNaLzpuWeLBNwrKm47LLn28JuvPNWMMj4m9roroafKNBCCGEEEIISTh80CCEEEIIIYQkHD5oEEIIIYQQQhLO0ZnR0MTwlcWbudh1G2Yuynqgz/LRc6aA3uHfDfqbmg6gS94Pj3vcYsSquLbF6ka/3uo/Y86h8Nc4lvqRTNCBz7VulZ3ROYh8e9i/6jF4jG2CxzjNVht1utOi63BobyIeY6vaFp2j0N/3xrAy6rob9TMabotPTcOF1an8yPnJ6Ot9PPqqyQESsy6BLXqtFD09lkc+GtqX7qhSDU7/ZGTD+b1puC1Wf/j7QZ1hI2Eiri3YD8TKZMSqyWT+kw3a1ROzOPZ6GYCRud/AtP+kdQUdrKyUqPQ9CWTu4xtAf1uvHkWgxiMyJvriDhd5f/sCtK0b1hV49PGi0OfU27FtbxmH+9vSCesOVHnweEVkLhyqfpLKbOjpuvl4vNinlNViHY9WyZgR6XPyGtCVI8Pbd/7vfgnT3K0wo1Fw7TrQqTWoyf6J6Pdj9Nt/Oe0d0Es8maCHpn0HOs+O9yppqv8tC2Ifo/kpbWuD03L/ieeGRd3L+ue2BW0fsgkX0ER12XiFIYQQQgghhCQcPmgQQgghhBBCEg4fNAghhBBCCCEJ5+jIaMQa2zeGr8xySnfQa6/Asak7nLYZ9Ccn/B30axXoAf2oDJe3uToL9NCc5aCnnvRC6POt0j/qtmq2jTsVdOGpmxqY88hn12lY/yHVilrXrqg/HnW5yi3s8GeAbucoAV0RxGyLRq8rVl0MHemwqcyFnl/nLrSuj675kWtDn/A6D/p4N/nRx+stOg20czZ6ucmBEW9dAqM88trrG0EcY5b7k1Gfefky0PP+2xN0x5dwW5yV2F7t1fW2/SCyI8c8B+lZ1rkeTearmLH77s91oNulhPN/q+pawbTSi/A6lLYR8yI3/utdtbaNoHq4sFDG3VeFQxn+oEd+anCrjywCP2LuMamo3jQ1b+aPOaA79MFr/w87cB+rMzRm2QGrFWewWlDbnOi/L6/Evr0uEzM6Tiv+Bf7tO0KfO92+Q6IR3elPGsIEo5/zwf49QY9KXQZ6SiXeDza3YXamOIDX9+k1nUBfnY5n3gxVd6MuiG2kPretxnNh0vBCXNa974Eukp4NLiuR8I0GIYQQQgghJOHwQYMQQgghhBCScPigQQghhBBCCEk4TZfRsKox5oPoNdT1IYJ16E0FYvhkbbnou1z5aGvQb/efBHprAP39n1TgeOR3bzsHdKoNva/ZzirQ89ahx66mBXrwhr3669DndoKeXHsB+u/WX4v6m3FPgL5s+HWgvef0wuV9vFiOVFQpDHFYsI34VL2IyhheyfpYVZ2LyiB6X5vb8Jh5Da7bbcUMhU9N13UwIlCbqjMgza3YhlYEwqb7tvZSmOayoAezfs0NEZFmVtxPFRMqQLeYHX1TjxniyDgcDnSGI1ZmI1omxI2lemTOj91A5/bchTOUYUajrCP2ka0+DZ8PJhBfnaFjmnjblJ5f1yQx8TnlZ1b2AN0hqTj0uYcb8wQPPvI96IBa11eqxIfuE8evvBJ00rr1oc9+03Cm7LCj9nlEPZt6Wtc5abEE+8pdo9NAG3WRslhxn+o6GX4/rjsY1KENlHa1PL2+3XUpoPtnrwVdLA378w+mfyH1CEa/1m86H8+jqiDeu5YFMFBXHMA2lqzuBTq4doLOsuH3PyvHjHCvNMxa1V//hdh85J6HcFs1W97GnFeby5Y3MOfBwTcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThJC6joX2TVtTaqho1k6GoHtkH9PaL0VM886ynQC+pawP66V2YuagNoM+xXTIaoE9K3QJ6lw/rbuzwoL6220LQX5e2A33liE9Dn4uuRF/tjsAa0BM3DQR9SdszQNtSt4J2l2He5Eh2YTqqYkxX9STK640XXWEwp6AzGc4Yo4br+W0RI6QfHFaJnhFJtmDti/p1N5rZ0A+9yoceUacFl1UWxP2U5jpOPfZHWCYjFvF4pIMDTgGdvbQGdO6kH0Dvubo36B2XYCZDDd0usjLsxxdznLaf/XGwbSqGvzsWH/dAk/WQH8JZm8FJuOxT/zQetC8d+7Qnx2E2Md9eBnr3J1gzoo2sl6MCdYwizqsotUts5dUNThMR8fkwc+FyYd+sMxk2m85c4PJ0HY2gymS43Lj80hrl//fjdS9adYyImi1HWf94uNDZFt2erMmYmXjsihdB/7m4L+hbms0HnaHuhXVNsLVR6mKIiKwsywU9qjneb9bPuq714U3Wj2e+Bvrd6lTQfzlpOui/XnMNaF3n50DhGw1CCCGEEEJIwuGDBiGEEEIIISTh8EGDEEIIIYQQknASl9GI5ZuMwaY/nhn6POGK92HaWcn/AK3HGn9i12DQOoPRJ31d1HXr+g1Bg89fuoaCP4g+zWXlmAlpm4J1Eepzz5rLQLvO26DmwHzI2r9hRuNflz4L+v2ynqB/vDE8vr414BH5Dj14h5Prbp0BWo8/XR1sBrq5NexLP9lZC9N0nQvthT3UOFUb2aPaoB6Vvlm9uh5pauz9dQH0Uba04djv2wLo2/3kxHdBF1nQ30+v7uEhlvdXs/6v4XPdl4XtqctTqg3cfjpo9248xi3fXAna36Ut6PoZueCRXDPhSCNGnQ2LA8Mwxq/2rT4X1fLe3oye6DW+8PSiPMwqZkt0/3TZzegtd1twW9q9iuPxH8n5vniw2MN9r/Fh/si4sF/2BDDzEPRhX2xPxum1KsPhduJ56gtEvy75g7j8VDfWVKj14vZ9tKkL6Dz5URokoobLweWFjhdi9csr/w/vN4cnfwH6xzqsWfR+1Ymgb8lYBTrNjuf8Bn98tXb0/apdwm3Oq+5dt/sxs5Fpxem71b1GyXl4T+ZNPxN0ztP4tzcWvtEghBBCCCGEJBw+aBBCCCGEEEISDh80CCGEEEIIIQnngDMagUGngt50HvrGbR3RG5akxvo/OWcb6N7uz0OfV9a0hGmf7ukMun0K1r3ItOMY8x2TcN0B9Ty13ZsJOs2GvjRdc6FOjXOcpOoe+JQvrsSDvrc93rBX9g+FmD+xrUUPZ4EdvdgzqvFvfbUYPXO5Lpx/xc/C6w7W2kXulCOG0Wlq7H9lTWxuw+NWv77EO1UdYFqeHXMwNsH9GEhwnYx40W2oLIinWjvHntDnZCu2L73tLpX/SFb1Rt6uao4rZybjiEB7f23dTwC98U/YJpJsZaHPvhKsp7DuiizQGWtUe1dDsQfb54G2enBbjuoWoms22er54rVPXRFRa+Ag617EXH6Mc7H3Ujwu164bAbr67OJGr9vqdoPWmYx3ynuB9m/BmkzHAzXtMkF7fHj9tLui+/VTkzFT4fVHv4XSdTOcdly+x4ffj1V3w9a5MPQ5sGotTItVu4z8DyvmaGL1Ac8Mewn0ci/mRYel4n3NWh9ejx/ejZnJsZlfg+7hxHvjt6uwvk1OMmZAygKYvRIJb09Q3Tu0suO96EaVGfvd0otBd7xmqTQFfKNBCCGEEEIISTh80CCEEEIIIYQkHD5oEEIIIYQQQhJOXBmNLXf3EZtrrw/01GE4nvOJLvTX2wQNghX+JNApdvQ67vSkhz5rf3teUjloPRb15jr0L68x2aDdKlOh62A0c2LGQ68/y4HTXVZcXrYTdXNHNej6GZDVHsyf1Bk0V3+v3NM1QRyXvYXaz+3cJXKkYuuEuYpW9mWgF3vQm5hnw/1cP9fgVWNH67oVOicTOd2mNC4vxYLbor+v0cfNq5YfWVcDfZUnOMLe4ErlES3254Du5MD2X63a/wUqs/Sc4H4/moi39kRTordF+/+tSeiJD1Sg31tOx/HXg/+3B3TNOvTitmwdzh21vHkFLiuG1z84AH3A5Z3Rm5v1X6wldFhH2I9RiyLm9IOs2dSkxPB7V8/Cc3PaGuwX8kei3xuI4S23OPFakWfHfmPaTz1Bd5BlDa/raCZKOGHHGaoGgcpYOFVdDJtV5TVVnYsUN143dB2MQIy6GRW12IfY1fr0/N7WGeFtw/IMIjbVPo6k8+JQE60PiXGOll2LtcvOT14G+ievqlmkdntHdb1u51gM+v92ngs63Y4Z4YszcX6nFbf3pzrM3/lTd4U+16n7EM2UUqzF0270d1HnTxR8o0EIIYQQQghJOHzQIIQQQgghhCQcPmgQQgghhBBCEk5cGY2CF9aK3brXB7p1UUeY9k0/NZB7F8wS9GyNY3YXJKGvvFtyuK5GihV9ibqOhUPVEeidih62Pu7NoH1qbGG3Gqs6Q3lfky3odXVYovveNvnxb93sR99tWTCsq4NYbySosgXF/nTQGSq3sNWTCbrUj+Pt588Mf/b7RLY0vNlNzo4huVGn16mcRKYVj2u5P3zcSnxpMK2neyPoCoP7NaD2q85kxKqzkeg6HPXbgIjItkDYl6nzIx2cu0AnK79psfpbXBZ17h3FxPTba+8tfDmx1SH0tujMhs5k6EzSml/itlrntwWd3QvzVelDcVz8uFC29KBNjalfrvIjh5N4MxlxYOmNuZiVN2I2sNtfsH6Tf3OMHjJGLsKagv1vsBrzeaufRE/0uc3QE73hfByTPyoxvOW6hodb5cQsG3BfRADHwXLUFluJqGVSD1979MOLH68TKUl47+F2YB+gMxq6LobXj+1FZzQ0Kaq+WGUtXsfcKv+5u2s405EzTy0seJQesKbgIPqQEb/CHft2Fd6T/WfnENBDmv8EOtuOdS8uS8W+99k2X4L+d3n03O7LBR+D9hhsc8WBcBtKs+rro8r4OqrUdLdEJUF9M99oEEIIIYQQQhIOHzQIIYQQQgghCYcPGoQQQgghhJCEE1dGQ6yWvf+JSNLXq2FSwezy/X0jRHkyetTnd+8NurRLeNz3ygL0hdW1Qs+lcSkPpralWZWPLIgz2HejB85ejdNdONy9uMpwee4yXL9rD/osbVXo87RWNuzDNW700EX1oIuIbEP//soy9OslmYWhz36D/s5DjTXG6ncHcKx/hxP3o7VelqZbEmZ8nMqUXqlyDjrHE6vOhUPp6mBS1Okavbyg4B9fpupoFAfSGpx2sgv/VrfKCFUb1WaOJxKcwwBi+FFj5UfW/Bnbc2AHHldHd/TqZg3HPvRgsCh/dl0L/FuCdcqbfoixuFxi+V+WyKL2swnguWx82A/onMOrwyeC/rSqaz21EKY9nYFj0n8yALOFU7uiPzoCnYtQ264zGbYTcPn3DpkO+q0rBqkVoL/bmoZZtGBlPb93rLxILtaP0rWF8ubHyj/Vn9969GQ0ouwXiwP7ypwWeA7WeHC6MXh8YyX1Uh3R62j4A3gMbCofWqemW9W9i8eHt2gVncLnClZbip5NOe6p30bUeeMb0gv0b5s/D3qxF+f/c/57oL/3Yj2kd0pOBf3GLmyf+UmloB/I/QL0OnWa3roV+4zH8z4FnWkNt5E96rs+g9u+tgb7CJFKiUqCrrd8o0EIIYQQQghJOHzQIIQQQgghhCQcPmgQQgghhBBCEk5cGY3AruKQz9aWmYEL6tAOtIkYzxex7ioD3XxNeDzzFinobTYe9EFqLHbl0dS+MhtON8lq7GD1feNCn2XQqcbGTsbp3nTly2yJY2F70zLDy1IlD3SOIaiOiD8Z96Ojshlomw//1vT1YS+28deJfIUe4UNJ7qxN+A9/QhkUXesCvdr1x5PWmYtqNda0znu4Lbhj9bqSrVifRI85r8eytinDcqzMh16/pv7fk6zqxqRZcT/UqPasa69EFFE4momRk7Dlhp3JwXx0KVfnY02D5He+jm/dcfpR1zzRF7QlgMcxv9sO0K7zNjR62dpbrtE5BmNXubbmR5bB3ng8Yix722m8W9blRKyL1M+N7T8gK0OfnYLn4YLadqD7Jq0H/dy1l4DOfAXHuI8gRhtp9xrW5Xjwq+GgO3+LmRENZDLixNMWrw1bVU0m14xFB7zsIxmLuteofxmxtcB9UlyKGZiWzTCzUVqN2bzsFMzg7FL1nGzW6H2v3YbTrSqj4VDTjfLUO+2oU9tHycLGyBM1ab7tUKNyORZ9j6fzKlFq0OT9CesXlQYxUxs0eL9YbPD+dFjyTtCXqboXennPlWKG4597TgbdP3Ul6AubLQX92J6TQN+SFe5TfOq+pSqI16T1Fc1Bu2JlNBIE32gQQgghhBBCEg4fNAghhBBCCCEJhw8ahBBCCCGEkIQTXx2NegTKlFdQ6xjo8cItrnqeZD1efSbOa5LQvxx0Rv8zjB2fp3R+xOKP7rM0Nvy+RXkdnWXol07egP7/+l5J41BeQr3telvUtuvp1kpcV2BN2INsOcx1NLaMLIg6XdePKAvi33Z6vazMgroaNS9+V2ckUlTuIaByDXUqLFOmcg4O5fUOqBHV3Spco73hev40G/o0i+v5p/Wy3MpbW2ei50OOqYxGDB9xTa9wm6poi+eOq0LlOdLRox6oQD92vNg6dQDd6zSsg5HlxDa64fSG6+fEROWVYo6Rr5qAr030XNuhpnZ4L7E79nqd9XFr9cK3oHVtijObr4u67BWevNDnH6pbw7QSD2a3tqShR/kX904B/eIr0fssjX9uW9C3Z+PyNv4eMwIxKlkcFJ4s7NO2+bPi+n79rIPFWI6ebsXS8O+l3o5Y4yAtBc9J3du4ndgXpzjwOqLrbKSq6clO9PNXqzodQfX9DBfWtyn2Y87M68e+3luvrobFhVlQ48FticgtxKgDdEShroFW9bfqukAmSgZDs+EvZ4B+qc3fQN+07jLQj7d7G3SNuv6u9KF2W/A4ZKjaKOek/gi6r1tfz5Eej90A2nNaFejfn70i9HmdD/dDsrrX3bYbs9Xto645cfCNBiGEEEIIISTh8EGDEEIIIYQQknAO2Dp1sEQM4xdtlK0dUaYdANEH3o09f6zvN/4l3sFzKNcVL/bBJVGnVwZwKME9QXzNXP+13p0P3gbT3rsfX3dmWPG76/24Z3zKOlUWxHXr4Wy1FUtbofQQs17VKJpb8RV9trJOdU4OvyK/ftNZMO3itp+D/smrrHgxsLdDO4d/w6YG5mwiLJbwq+94h1SMMSRj/SE6s2MsKuHnxnP4uv7qXBwK9amxo0BbZNkBryrC5qD3i8ISxP10auFG0IdmEMOGqWhnF5tr7+Xms7v+DtPm3p4LeqO3BeghymqwSe2bqkDYrnJB5jKYdl4yWmE8yk7qsuB5/9tJl4M+4Xm0cdX9FfWLnV4Dfc1P14JO2Rrd9pVIqlqhBWNNXW4Dc+4fU68NmWNkKNTd3dHKlJu2C/TWcrSS5KWjvbLah5Ydmxpu1m3D9pTpxn5eW6dqfdje2qaVqvXh/Pr7Sa6wJdKWjeeJf8tW0NEsZUc8ekh3ZZXSWOx4K2vp0hH0ijvC9vv1wyfCtAlbB4M+PWsD6F9sQCvV79p+ALqdHW2qZcpyqB2IXolulepzz3jQea98AbpqFlp4oy1btwBfRfRh05tqSOSjuCUSQgghhBBCjlT4oEEIIYQQQghJOHzQIIQQQgghhCScw5bRIMc+SQ70Uq/34bBs+c7doH0Rw7aGafYC+uHP7P1L0E+d+wroDvY9oHuq4fH+W4texObW6DkIr3om1xmNiiB6gds70bfpUV7Hu7afGvr8w3Mn4soexIyGT61b50lE0Ce8aVQb0HmPHOKMhjESOXBkPN+NQj0PqesT9KCf1RyHm319YhHonKfR6xqLtX/vC/qnzk+D7jxzHOoF38S1/ERi7NieO6eiF33xYf5NKffpr8X+vzzEvVcOhGk/z/kYdA/XdtB1ql/4pKYd6Db1+pFuTvS8L1Ye92wbnpdWwaEo11/4HG74hSgXevBc26lyZsl/xiGVI7CqPi6OYTlj4cW4gayp1immPRKV+ttijuT0X+PxZOF5ke5Er/8GHw4/3DYV28/qctyHdjs67vV1wG7B6S51DSyvxvZSmFIMensNth+PH2/R7LbwcfG1xYyGRWc0jiF234xD0k77A2Y09ZDwOTbsiwP1hgtf5cMczS9y/gv6vq0XgL69zVzQr+0+E/SvcuaBTlYxh/IgnvNn462C9L4XMxnNXsF7HY3T1vhzM6gSIq4d+t4BaaohkflGgxBCCCGEEJJw+KBBCCGEEEIISTh80CCEEEIIIYQkHGY0SJOh3fbtHamgf/QduP+v8/iFoP8pXeL6vjUlBXWzLDWDMlqqOgU6S2DUON9/L8H8SSRh72QzUZ7MB1Ha1J5MsaKvfFcAx/ZvWbQZF/BIjE1JMDUjThO7Y68R1eZBj6izHD3u9l04br1UYI7H1KCfNlgVnl7hQbPr1enfgi6/ORn00g/agfZvxP1UORozGW9d+g/Q12/EzEeXCT/gtkkTEiO7YlR7LfMnqzmij0N/KFmwrT3ox/PwOH5Yg2GDNFWT5qykDaAd9f70jervbmbFvzugd6M6zb/z4vx7Ano/YtZrfnVnXNyCZRIVc+CtxJqC26JrUfky8I9bWZIDOkdlNHQfGKzGfuSoQffV9agpUDVXVF0MXTYgz10G+ost7UC7ndh/adqm4D7eXIFt2edDD3x7F2Y0lrtaga72YsbIagkfY28GTsO/TKLulyMde4d2oH/768mgq4P4G/m6AN5brLDo8yw8v9uC+625up4+kf8h6F9uGQp6ZAvMf6zzYa7mDDcur40dcxH9v7sUdLMXo2cyNLoWS33qgjgtYDCT5iyPsfAmqr3CNxqEEEIIIYSQhMMHDUIIIYQQQkjC4YMGIYQQQgghJOEwo0GajIzr0G8vS1G2tqFh0KF8lR7TdM1T+5GPJH/y1Cr09Z7pxv243It+1OZW9A1vXIh1NNqLymw0MZVtbWJz7fUiV7VVPuEW6JlOSUNnsc+HvvG6UjXoeDC8PMs2HE98wO7bQNuX47JcODy6lPfBMfIHdcbMxV1rLwft/BXu92Ddj6CtycpDXxO9NksisVVjG/jo056gC+WrQ7Ytsch+BI+p4030rQ9NxloGVvV72CYV7VrpC58vZQE85j4bnjtpKrORps4dh0rauC04vcCOeZE/3D8AdLJ8jRuXwLoZFh0oUARcmNEoK8H2iomNyDHzj0mUVb/Ki/1NsvLTl/uxzoXOVOi6GK3ceA3rkYx97efBQtAOR/Tjb7fiBvsC2Pbd9vD6LbFKDumaCNFnP6LYOCoPdE/XNtCf1HQEne/ATCSmMESybeHru9uCx0DX6Wmm9tRDrWeAnqFyWQ9vxGzfLztg3Y3LUjGHmHL+OolGrOtIRY26JtYj0xb9mpO8s0mThA3CNxqEEEIIIYSQhMMHDUIIIYQQQkjC4YMGIYQQQgghJOEwo0GajMDOXaCHDUbP+53vvwu6kwO92b0X3RD63Ep+OriNUV5p7V+12PCZ28SoWxBRV0NhAsqLq73Z9f3Wal2/W4TjbH834FnQhQ4ce334yktAt/9tfONyJ5rcp78Wu6Xhsb6jYW+N3lxvh1zQddlh921lG/RbGwvq6nzltz8d21fnVPTvfz6vB+iOL+F+DqzETIbmUGYyNLZqHC99+sjnQP/yV2ccys2Jiq41UZTXE3TFGPQ8n3035ksezsXvF4LvXdVliUC7t7WOzs2bsZZK8rSvG5gz8UT0KYpTTlsD+qdduQ3M+b/lxerjjgGsXuzXfar+gltlLr4vxf7HqPnrvNivpdow41FnsD2Vl6Pf3ulWeTpPC9B2lVMMBhv+LdheG70OVaz2ciST//T3oO8dcSHom1t+CrqDHbMyOolQv9ZOncGsk8/gPt4W0DktXNbVaRtA9+2CmYuuDmwjZ912K+iIHJfCeL1Rp/t9DWerKoOY30i2YhtwVkXPaFgc+EhgfNG3pbHwjQYhhBBCCCEk4fBBgxBCCCGEEJJw+KBBCCGEEEIISTjMaJBDRuCn1aD1mM/tHTjue8/craHPO9WybJlYayJQVi5RURkJozVaZ5sciz3s49Q+SPf3OJZ71dl6LH9cVvnz+aDTZascrfi34njpVqWTG/h8IGiHenu1344mh3Ng+UrQI967E3SnGL7gI4n0/2AmY9l/cHqR9ARt6dU99HlnH+wXyk5EH3tqK8zltM7AfsMo//baneihL7xy2X63ObwxytB9EHUzNLEyQNv/iTUbCr7D2gJ6S0xtrRzrZBbuAZ2fVga6xo+Zig6pJajTcB+mqzoqp6WgP7+TqucwowBzX6dkYp2N+7Ix9zXBmwa6RSrWd7LW77U8R1MPFR/BykrQpf1w+t87Xwx69U1YJWb44EWgH8j9PPS5rRWvrwdLthX7lLN/dSfo9HcSW8PIsk5d+eqV8unmwP5scmUB6LRvtoDWKR/ji577OVD4RoMQQgghhBCScPigQQghhBBCCEk4fNAghBBCCCGEJBxmNMihQ/mXb/7HHaDde9A1n7o1nF2wy2KYFqw+yv3FpuHxrN3FuB92BHDc7DI1VrYl+tDY5Dik08+PnkzGwWIWLw99zsFuQnIkOrEqSRTKlhhz6AU2YW2KGMtOfROPeSwHv/E3jR/7kBOlXkTVsuagFzXPBO0qxlug9Z72oN0luM8talUzW2HNl7qWOEOzZfhb7kYX5mheyx8AWiV8xFaj/qVHOLvQYSPWqYo4mkdxHY1YBFatBd3hbtS66tYoCdcRqp/pEhEp74y5mLosPGZJe/ACm74S8yNm6XKcLonNZGja3Yt1ss76Zlzoc/J2vC+y78TMhn/rxqjLTlTdDA3faBBCCCGEEEISDh80CCGEEEIIIQmnUdYp879Xtn7xxX7XTI4Y/LJ3WFTTBK/zD6xN4GvggKcOtRcX5PfXe42nxp+1qGEozaEen/YgsdQ7JsbgS++AF/dLVSW+uq0Oovb7cH5/lH1x5LUJcrhhmyCapmoTTdEeLGob6/enwTrsG4O1aCcK1KlbIOUc0dckbZ0KePA6FLF8L/6WG1D24WCdWr4o1PKlJvz3+IO4sbrfj7Zf4uVY6iMsAQ/ogM+BWh0zv09db9X3E33vEe9xq3/99/uxvUsQtzXavUG8xNMmLKYRc23ZskXy8/NjzUaOUDZv3ixt2rRJ6DLZJo5u2CaIhm2CaBLdJtgejm7YRxBNY9pEox40gsGgbNu2TdLS0sSiCxKRIxZjjFRWVkpeXp5YrYl1ybFNHJ2wTRAN2wTRNFWbYHs4OmEfQTTxtIlGPWgQQgghhBBCSDwwDE4IIYQQQghJOHzQIIQQQgghhCQcPmjEYMOGDWKxWOTRRx893JtCDgKLxSL3339/SL/00ktisVhkw4YNh22byLHHwbSrsWPHSrt27RK+TeTwwjZx5BPPdf7+++9nluAYZezYsZKamhpzvoEDB8rAgQMTtt6BAwfKiSeemLDlHWkcEQ8a33//vYwcOVIKCgrE7XZL69at5dxzz5Unn3zycG8aOUzsuzjv+8/tdkvnzp1lwoQJsnPnzsO9eeQIgv0H0bBNHFvUvxZE+++TTz453JsK1NTUyP333x91u0pLS8Vut8vUqVNFROShhx6Sd99999Bs4DHAM888IxaLRfr06XO4N+Wo5FC0t0bV0WhKvvjiCxk0aJC0bdtWbr75ZmnZsqVs3rxZvvrqK/nHP/4ht99+++HeRHIY+dOf/iTt27eXuro6mT9/vkycOFFmzJghP/zwgyQnJx/uzSOHGfYfRMM2cezx6quvgn7llVdkzpw5Ef/etWvXJt+W3//+93LPPfc0at6amhp54IEHREQa/AV89uzZYrFY5LzzzhORvTd+I0eOlIsvvjgRm3vMM3nyZGnXrp0sXLhQ1qxZIx07djzcm3RUcSja22F/0PjLX/4iGRkZsmjRIsnMzIRpu3btOjwbdYipqanhTXMDDB06VE477TQREbnpppukefPm8thjj8n06dNlzJgxh3nrmo7q6mpJSUk53JtxxMP+g2jYJo49rr76atBfffWVzJkzJ+LfDwV2u13s9ui3TsFgULxeb9R59jFjxgzp169fRFslsVm/fr188cUXMm3aNBk3bpxMnjxZ7rvvvsO9WURx2K1Ta9eule7du+/3JMvJyQl9tlgsMmHCBHn33XflxBNPFJfLJd27d5dZs2ZFfG/r1q1yww03SG5ubmi+F154Aebxer3yxz/+UXr16iUZGRmSkpIiZ511lsybNy/mNhtj5JZbbhGn0ynTpk0L/ftrr70mvXr1kqSkJGnWrJlcccUVsnnzZvjuPi/e4sWL5eyzz5bk5GT53e9+F3OdZC/nnHOOiOztYBrySR6Mr/mZZ56R7t27i8vlkry8PLntttukrKwsNH3ChAmSmpoqNTU1Ed8dM2aMtGzZUgKBcHXYmTNnyllnnSUpKSmSlpYmw4cPl+XLl0dsb2pqqqxdu1aGDRsmaWlpctVVVx3Q9h9vNLb/ePHFF+Wcc86RnJwccblc0q1bN5k4cWLEd9q1aycXXHCBzJ8/X04//XRxu93SoUMHeeWVVyLmXb58uZxzzjmSlJQkbdq0kQcffFCCqmq7iMj06dNl+PDhkpeXJy6XSwoLC+XPf/4ztBOSONgmiOabb76RoqIiadGihSQlJUn79u3lhhtu2O+8zz33nBQWForL5ZLevXvLokWLYPr+Mhr77k8mT54cun5MmjRJsrOzRUTkgQceCNm76mcFg8GgzJo1S4YPHx5aTnV1tbz88suh+ceOHRuaf+nSpTJ06FBJT0+X1NRUGTx4sHz11VewLftsx5999pmMGzdOmjdvLunp6XLttddKaWnpge7CI5LJkydLVlaWDB8+XEaOHCmTJ0+OmKd+/ibWsd0fy5Ytk+zsbBk4cKBUVVU1OJ/H45H77rtPOnbsKC6XS/Lz8+Xuu+8Wj8fT4Hc0ixcvljPPPDPURidNmhQxz65du+TGG2+U3NxccbvdcvLJJ8vLL78cMV91dbXcddddkp+fLy6XS0444QR59NFHoZJ3rPaWKA77G42CggL58ssv5YcffogZhpk/f75MmzZNbr31VklLS5N//vOfctlll8mmTZukefPmIiKyc+dO6du3b+jEz87OlpkzZ8qNN94oFRUVcuedd4qISEVFhfzrX/+SMWPGyM033yyVlZXy73//W4qKimThwoXSs2fP/W5DIBCQG264Qd544w155513Qh3EX/7yF/nDH/4go0aNkptuukmKi4vlySeflLPPPluWLl0KF73du3fL0KFD5YorrpCrr75acnNzD3o/Hi+sXbtWRCR0vBPJ/fffLw888IAMGTJExo8fLytXrpSJEyfKokWLZMGCBeJwOGT06NHy9NNPy4cffiiXX3556Ls1NTXy/vvvy9ixY8Vms4nI3tf91113nRQVFcnDDz8sNTU1MnHiROnfv78sXboUHob8fr8UFRVJ//795dFHH+UbrkbS2P5j4sSJ0r17d7nwwgvFbrfL+++/L7feeqsEg0G57bbbYN41a9bIyJEj5cYbb5TrrrtOXnjhBRk7dqz06tVLunfvLiIiO3bskEGDBonf75d77rlHUlJS5LnnnpOkpKSIdb/00kuSmpoqv/zlLyU1NVU+/vhj+eMf/ygVFRXyt7/9LbE7hLBNEGDXrl1y3nnnSXZ2ttxzzz2SmZkpGzZsgB8J9/H6669LZWWljBs3TiwWizzyyCNy6aWXyrp168ThcERdz8cffyxTp06VCRMmSIsWLeTkk0+WiRMnyvjx4+WSSy6RSy+9VERETjrppNB3Fi1aJMXFxTJs2DAR2XvNuOmmm+T000+XW265RURECgsLRWTvQ+xZZ50l6enpcvfdd4vD4ZBnn31WBg4cKJ9++mlERmHChAmSmZkp999/f+hatnHjRvnkk0+OmTD75MmT5dJLLxWn0yljxowJXa979+4dMe+BHNtFixZJUVGRnHbaaTJ9+vT9nssiex8YL7zwQpk/f77ccsst0rVrV/n+++/l8ccfl1WrVjUqA1FaWirDhg2TUaNGyZgxY2Tq1Kkyfvx4cTqdoYfi2tpaGThwoKxZs0YmTJgg7du3lzfffFPGjh0rZWVlcscdd4jI3h/DL7zwQpk3b57ceOON0rNnT5k9e7b8+te/lq1bt8rjjz8uItHbW0Ixh5mPPvrI2Gw2Y7PZzBlnnGHuvvtuM3v2bOP1emE+ETFOp9OsWbMm9G/ffvutERHz5JNPhv7txhtvNK1atTIlJSXw/SuuuMJkZGSYmpoaY4wxfr/feDwemKe0tNTk5uaaG264IfRv69evNyJi/va3vxmfz2dGjx5tkpKSzOzZs0PzbNiwwdhsNvOXv/wFlvf9998bu90O/z5gwAAjImbSpEnx7qrjihdffNGIiJk7d64pLi42mzdvNlOmTDHNmzc3SUlJZsuWLWbAgAFmwIABEd+97rrrTEFBAfybiJj77rsvYvnr1683xhiza9cu43Q6zXnnnWcCgUBovqeeesqIiHnhhReMMcYEg0HTunVrc9lll8Hyp06dakTEfPbZZ8YYYyorK01mZqa5+eabYb4dO3aYjIwM+PfrrrvOiIi555574t1Nxz2N7T/2nff1KSoqMh06dIB/KygogONozN624XK5zF133RX6tzvvvNOIiPn6669hvoyMDGhXDa173LhxJjk52dTV1YX+bX/tlsQP28Sxz2233WYae/vyzjvvGBExixYtanCefdf55s2bmz179oT+ffr06UZEzPvvvx/6t/vuuy9i3SJirFarWb58Ofx7cXFxxLWnPn/4wx8ijm9KSoq57rrrIua9+OKLjdPpNGvXrg3927Zt20xaWpo5++yzQ/+279rWq1cvaPOPPPKIEREzffr0BvfD0cQ333xjRMTMmTPHGLP32tymTRtzxx13wHzxHNvrrrvOpKSkGGOMmT9/vklPTzfDhw+Hc9IYE3Hv8eqrrxqr1Wo+//xzmG/SpElGRMyCBQui/i377gv//ve/h/7N4/GYnj17mpycnNBxfOKJJ4yImNdeey00n9frNWeccYZJTU01FRUVxhhj3n33XSMi5sEHH4T1jBw50lgsFriPbqi9JZLDbp0699xz5csvv5QLL7xQvv32W3nkkUekqKhIWrduLe+99x7MO2TIEHjaOumkkyQ9PV3WrVsnInuf4t5++20ZMWKEGGOkpKQk9F9RUZGUl5fLkiVLRETEZrOJ0+kUkb1Po3v27BG/3y+nnXZaaJ76eL1eufzyy+WDDz6QGTNmhIJbIiLTpk2TYDAoo0aNgnW2bNlSOnXqFGHHcrlccv311ydmBx7jDBkyRLKzsyU/P1+uuOIKSU1NlXfeeUdat26d0PXMnTtXvF6v3HnnnWK1hk+Lm2++WdLT0+XDDz8Ukb2vGi+//HKZMWMGvEZ94403pHXr1tK/f38REZkzZ46UlZXJmDFjoE3YbDbp06fPfi1648ePT+jfdDzQ2P6j/i9R5eXlUlJSIgMGDJB169ZJeXk5LLNbt25y1llnhXR2draccMIJoX5GZK+vum/fvnL66afDfPuzvNVfd2VlpZSUlMhZZ50lNTU1smLFioPbASQCtglSn31ugg8++EB8Pl/UeUePHi1ZWVkhve+Y1z/ODTFgwADp1q1bXNs2Y8aMkCsiGoFAQD766CO5+OKLpUOHDqF/b9WqlVx55ZUyf/58qaiogO/ccsst8Ev9+PHjxW63y4wZM+LaxiOVyZMnS25urgwaNEhE9l6bR48eLVOmTNmvBTGeYztv3jwpKiqSwYMHy7Rp08TlckXdljfffFO6du0qXbp0gev9Pqt3Yyz5drtdxo0bF9JOp1PGjRsnu3btksWLF4vI3vbSsmVLyKc6HA75+c9/LlVVVfLpp5+G5rPZbPLzn/8c1nHXXXeJMUZmzpwZc3sSyWF/0BAR6d27t0ybNk1KS0tl4cKF8tvf/lYqKytl5MiR8uOPP4bma9u2bcR3s7KyQr7D4uJiKSsrk+eee06ys7Phv3039vXDgC+//LKcdNJJ4na7pXnz5pKdnS0ffvhhxEVGROSvf/2rvPvuu/LWW29F5AJWr14txhjp1KlTxHp/+umniABi69atQw85JDpPP/20zJkzR+bNmyc//vijrFu3ToqKihK+no0bN4qIyAknnAD/7nQ6pUOHDqHpIns7rNra2tBNS1VVlcyYMUMuv/zy0Cvp1atXi8jeTIluEx999FFEm7Db7dKmTZuE/13HA43pPxYsWCBDhgyRlJQUyczMlOzs7FA2Sp/vsfoZkb3tpVOnThHz6fYjstfycMkll0hGRoakp6dLdnZ2KMS6v76GHDxsE8cfVVVVsmPHjtB/xcXFIrL3AeCyyy6TBx54QFq0aCEXXXSRvPjii/v1zuvjvO/GtDHZhvbt28e1vTt27JAlS5Y06kGjuLhYampq9tuWunbtKsFgMCIPqttiamqqtGrV6pioHRUIBGTKlCkyaNAgWb9+vaxZs0bWrFkjffr0kZ07d8p///vfiO809tjW1dXJ8OHD5ZRTTpGpU6c26l5t9erVsnz58ohrfefOnUWkcYNQ5OXlRQwAs+/7+47Zvj6m/o+hIuHR1vbdp2zcuFHy8vIkLS0t6nyHisOe0aiP0+mU3r17S+/evaVz585y/fXXy5tvvhkaRWCf911j/hdu2Re6u/rqq+W6667b77z7/JGvvfaajB07Vi6++GL59a9/LTk5OWKz2eSvf/1rKAdQn6KiIpk1a5Y88sgjMnDgQHG73aFpwWBQLBaLzJw5c7/bqAvANOTzI5GcfvrpoVGnNBaLBYJN+2jqQGXfvn2lXbt2MnXqVLnyyivl/fffl9raWhk9enRonn1t8dVXX5WWLVtGLEOPWuJyuSI6DxIfDfUfV199tQwePFi6dOkijz32mOTn54vT6ZQZM2bI448/HhHWjdXPxENZWZkMGDBA0tPT5U9/+pMUFhaK2+2WJUuWyG9+85v9BoVJ4mCbOH549NFHQ0PJiuzN6uwLAr/11lvy1Vdfyfvvvy+zZ8+WG264Qf7+97/LV199BdfngznO8V7XZ86cKW63O/SLPGk8H3/8sWzfvl2mTJkiU6ZMiZg+efJkcJ2INP7YulwuGTZsmEyfPl1mzZolF1xwQcztCQaD0qNHD3nsscf2Oz0/Pz/mMo5ljqgHjfrsu7ncvn17o7+TnZ0taWlpEggEZMiQIVHnfeutt6RDhw4ybdo0CEY1NDRa37595Wc/+5lccMEFcvnll8s777wTulksLCwUY4y0b98+9ARKmp6srKz9vvY8kKf1goICERFZuXIlvJr2er2yfv36iPY0atQo+cc//iEVFRXyxhtvSLt27aRv376h6fssfjk5OTHbIkk89fuP999/Xzwej7z33nvwq1ZjXmc3REFBQeitVX1WrlwJ+pNPPpHdu3fLtGnT5Oyzzw79+/r16w943eTAYJs4trn22mtD1lWRyBv/vn37St++feUvf/mLvP7663LVVVfJlClT5KabbmqybYoWuv7www9l0KBBEdu5v+9kZ2dLcnJyRFsSEVmxYoVYrdaIm9nVq1fDQ0xVVZVs3749FDw/mpk8ebLk5OTI008/HTFt2rRp8s4778ikSZMO6Eddi8UikydPlosuukguv/xymTlzZswq4IWFhfLtt9/K4MGDDzhov23btohh7VetWiUiEho4pqCgQL777jsJBoPww+Q+u+W++5iCggKZO3euVFZWwlsNPd++v7epOew/oc6bN2+/vxbs8xHu71VhQ9hsNrnsssvk7bfflh9++CFi+r5XqfvmFcGn2a+//lq+/PLLBpc/ZMgQmTJlisyaNUuuueaa0C9Pl156qdhsNnnggQci/hZjjOzevbvRfwNpPIWFhbJixQo4rt9++60sWLAg7mUNGTJEnE6n/POf/4Rj+O9//1vKy8sjXm+PHj1aPB6PvPzyyzJr1iwZNWoUTC8qKpL09HR56KGH9usLrr/N5MBpTP+xv3O9vLxcXnzxxQNe77Bhw+Srr76ShQsXhv6tuLg4YnjF/a3b6/XKM888c8DrJtFhmzg+6dChgwwZMiT0X79+/URkrzVGt4d9o0rGM/TogbBv9MD6Q6SLiPh8PpkzZ85+bVMpKSkR89tsNjnvvPNk+vTpYH3auXOnvP7669K/f39JT0+H7zz33HNw7Zk4caL4/X4ZOnTowf1Rh5na2lqZNm2aXHDBBTJy5MiI/yZMmCCVlZURGd942Fe6oHfv3jJixAg4p/fHqFGjZOvWrfL888/vd3urq6tjrtPv98uzzz4b0l6vV5599lnJzs6WXr16icjePmbHjh3yxhtvwPeefPJJSU1NlQEDBoTmCwQC8tRTT8E6Hn/8cbFYLNAG9tfeEs1hf6Nx++23S01NjVxyySXSpUsX8Xq98sUXX4R+JY43NP1///d/Mm/ePOnTp4/cfPPN0q1bN9mzZ48sWbJE5s6dK3v27BERkQsuuECmTZsml1xyiQwfPlzWr18vkyZNkm7dukUdK/niiy+WF198Ua699lpJT0+XZ599VgoLC+XBBx+U3/72t7Jhwwa5+OKLJS0tTdavXy/vvPOO3HLLLfKrX/3qoPYTieSGG26Qxx57TIqKiuTGG2+UXbt2yaRJk6R79+4RwbhYZGdny29/+1t54IEH5Pzzz5cLL7xQVq5cKc8884z07t07ojDUqaeeKh07dpR7771XPB4P2KZERNLT02XixIlyzTXXyKmnnipXXHGFZGdny6ZNm+TDDz+Ufv36RXQCJH4a03/s3LlTnE6njBgxQsaNGydVVVXy/PPPS05OTlxvTOtz9913y6uvvirnn3++3HHHHaGhTPf94rSPM888U7KysuS6666Tn//852KxWOTVV189IMsNaRxsE6Q+L7/8sjzzzDNyySWXSGFhoVRWVsrzzz8v6enpTf7rflJSknTr1k3eeOMN6dy5szRr1kxOPPFEKS4uloqKiv0+aPTq1Uvmzp0rjz32mOTl5Un79u2lT58+8uCDD8qcOXOkf//+cuutt4rdbpdnn31WPB6PPPLIIxHL8Xq9MnjwYBk1alToWta/f3+58MILm/Rvbmree+89qaysbPDv6Nu3r2RnZ8vkyZMjrsvxkJSUJB988IGcc845MnToUPn0008bHC77mmuukalTp8rPfvYzmTdvnvTr108CgYCsWLFCpk6dKrNnz27QAr6PvLw8efjhh2XDhg3SuXNneeONN2TZsmXy3HPPhUL9t9xyizz77LMyduxYWbx4sbRr107eeustWbBggTzxxBOhtxcjRoyQQYMGyb333isbNmyQk08+WT766COZPn263HnnnTCoUkPtLaE06ZhWjWDmzJnmhhtuMF26dDGpqanG6XSajh07mttvv93s3LkzNJ+ImNtuuy3i+wUFBRFDc+3cudPcdtttJj8/3zgcDtOyZUszePBg89xzz4XmCQaD5qGHHjIFBQXG5XKZU045xXzwwQcRwwnWH962Ps8884wREfOrX/0q9G9vv/226d+/v0lJSTEpKSmmS5cu5rbbbjMrV64MzTNgwADTvXv3A91dxw37huiLNiShMca89tprpkOHDsbpdJqePXua2bNnH9Dwtvt46qmnTJcuXYzD4TC5ublm/PjxprS0dL/rvvfee42ImI4dOza4ffPmzTNFRUUmIyPDuN1uU1hYaMaOHWu++eab0Dz1h9Qj8dHY/uO9994zJ510knG73aZdu3bm4YcfNi+88EJEGygoKDDDhw+PWM/+hlL+7rvvzIABA4zb7TatW7c2f/7zn82///3viGUuWLDA9O3b1yQlJZm8vLzQcKsiYubNmxeaj0OZJga2iWOfeIa3XbJkiRkzZoxp27atcblcJicnx1xwwQXQBzd0nTcm8trR0PC2+7s/McaYL774wvTq1cs4nc7Qsn71q1+Zbt267Xf+FStWmLPPPtskJSUZEYH7myVLlpiioiKTmppqkpOTzaBBg8wXX3wB3993bfv000/NLbfcYrKyskxqaqq56qqrzO7du2PtriOeESNGGLfbbaqrqxucZ+zYscbhcJiSkpK4ju3+rsUlJSWmW7dupmXLlmb16tXGmP2f+16v1zz88MOme/fuxuVymaysLNOrVy/zwAMPmPLy8qh/0777wm+++cacccYZxu12m4KCAvPUU09FzLtz505z/fXXmxYtWhin02l69OhhXnzxxYj5KisrzS9+8QuTl5dnHA6H6dSpk/nb3/5mgsEgzBetvSUKizH8GYUQQggh5FDQrVs3ueCCC/b7JuJgeemll+T666+XRYsWxfwVnZBDwWG3ThFCCCGEHA94vV4ZPXp0RK6PkGOVRj1oBINB2bZtm6SlpR0zpeuPB4wxUllZKXl5eQkfOpVt4uiEbYJo2CaIpqnaBNvDXn7xi1+IiMSdJWwMtbW1IrJ3lKlELZ99BNHE0yYaZZ3asmXLcT8O8NHM5s2bE14Mjm3i6IZtgmjYJogm0W2C7eHohn0E0TSmTTTqjca+JHt/GSZ2ccSYmxwp+MUn82VGRHXIRMA2cXTCNkE0bBNE01Rt4khrD75BPUFvugJ/d7WUYlVoexX+4m7xo/Y2U8ViDU5P3oa//NZ0rwOd3awSdMcsHAZ912CcfqhgHxHGnocFeAPFe0Abn/dQbg6i3whZ1JuGYOKKGcfTJhr1oLHvdZZdHGK3HPkNgfyP//WZTfE6km3iKIVtgmjYJoimidrEkdYejN0N2pqkHjRq8UHDqh4sInRS9AcNmwtv/KyqnpwtBW9SHSnqQedw7TP2ESHsVhdoi9pmYzmM4yvFetDQ+mCIo00c9oJ9hBBCCCGEkGMPjjpFCCGEkOOOrYPwjUH/zstB+4M20BdnLwFd6EBrUy8XLu87L1qjVnhzQf9U2xr08spWoC9qvgz0c9JBSIJRv8hXXIHF6souxareD548HfSZ7m2gW9jwNVWXj28CPaLb96AdFnwLdmvzz0FP2tMf9JLbe4K2zl8WFjpybdQbNv324RBVt+AbDUIIIYQQQkjC4YMGIYQQQgghJOHwQYMQQgghhBCScJjRIIQQQshxhz8ZPeoLNxeAbpWFBe/mlJ4I+hMreuD/rZafaa8BbVUjEq2pzga9obwZfr8V5gNs3U8IfQ4sXymkcdi6dQ597v7aapjW2lUKuovrRdBegzmdpTXtQG/24TG7NO0H0Hee+jHoMek/gg6qbf3D9nNBF7hx+NwLn50HOtsebqN/fOcKmNb+ni9x4TqTcYgyG3yjQQghhBBCCEk4fNAghBBCCCGEJBw+aBBCCCGEEEISDjMahBBCCDnuyChEf37HZiWg85LKQWs/f56jDPSiqvagXVY/rk9lNnzJ6P+3W9Cxn2bFOhxbhzQPfW6JJT9IFFr8e0foc/fkrTBteQ3WMtnqyQLtUxkNXVtldXUO6Jk7MMfTNXMH6Kt3jgK9szINdG5aJejttRmgrYI5iqCEcxYDBn0H01yLsIr56t4e0KyjQQghhBBCCDlq4YMGIYQQQgghJOHwQYMQQgghhBCScJjRIIQQQshxR4es3aDzkzCD0dpVBvoE9zbQ39Zg3Q2dyXBYsM5GngOXHzT4W28zO9bNcKvvezOFNIJtd58J+oL0D0Ofv6nEHE2SzQtaZzI0VpWjSbFj7sHvxmNa4kkFnZOEGYx0J+ZwnKo2i1dlQrwBvG2v8LhDn9fvwZoeLVKxPVXelAe6+b9UnY0mgm80CCGEEEIIIQmHDxqEEEIIIYSQhMMHDUIIIYQQQkjCYUaDEEIIOQBKbjkDdKfrVoJeuBr94C0+cYLOeunQeKTJ/mmfghmNb3a3Bf11oB3oawvQT39i0mbQxf70qOtzqsyFZrsXaybYVM0E/wlYh4Psn5FXfQK6fq5CZzI01X6sPaEzGRqds9G1UDR1AQdoncmo8uH661Qmo9KL0932cC7IasH24g1gviNtNGaM5F9RNzVh8I0GIYQQQgghJOHwQYMQQgghhBCScPigQQghhBBCCEk4zGjsB1v3E0BXt0ffpPuDhYdycwghhByB7DkN6yYUJO8B3bJHBegnzvsGdPuzbwLd+QacHg+2TLxO/fQQXsdcLWpBt7tmFWjjwXoAxyLW5GTQ7dyYsXi/9ETQfj963F+WvqDz08pAn9NsBS7fUQx6pQfrGOhMxk9lLUEvSC7E5eVipoQ0DrfFF/qcasN2rmuX7PSkgbZZ8Pd4XzB6nQ2/ymwEjSWq1hmMoOB0tw37GKsLcxj162jU1mH+Q2c2TslbD3pdR8yQBdbg9ETBNxqEEEIIIYSQhMMHDUIIIYQQQkjCoXVKIocoHPeL6aD/+uUw0J12nwza8uW3TbNh+2HXhDNBZ63CodocHx34q3dCCDmesdjxkmj8/gbm3MulvRaDXl/dHHR+UinoazeejfOfj+NLDj7nRtD2j3H59bHl5oDuP2cj6J8nfwW6pQ1tXD8fejvopHePfUuwtSXus00eHC7WsycJtKsZ2s1SHXi9benGfeozaKvJsVWB/v2G00EHgmiT8avhSEt8aOOxquFuyV42vdkD9GXO/4Ju7Qifh8NS1sC0dX60031djnaiCjWcbKoDrVexrFLeQHy32XpIWqct+pDIHn94+e2z0brZNXMH6C01maC3n9cKdA6tU4QQQgghhJCjBT5oEEIIIYQQQhIOHzQIIYQQQgghCefYyGhY1XBjQfS02Tp1AF3+JM4+MPtr0O/txAzGGSesBd3sn+jrXN27sRsqYsvKAr3+9q6gPc2xfL1x499ircbpKdvxb8fBzY4jLOiLFBOfl3XTHzH7krMEvdlJ23EIvO39cVjC5GI8LlmLdoEOrF4X1/bEw7r/w4xR1k84PevlL5ts3YQcS5hg9H7D3gqHH70860PQz/sGgE6314HeWNMM9CsVLUD/97V/gz7j28tCn3dsxu+uv+B50FMq8dryWSUOb1voxj7JvfPYH85W489JB13pd+MM2I2L04nXgSqfE7TLitPf647Hs/uaraDPbIke+M+34b2JHp50fS0ur9Yfno5pkuOb1k/jfmv3LxxWeE8gNfS5lR3bfYYVczet3OWg1wcwd+VVw9vqTIZGD1frD+Lv+3YrNro6P/4te2oxQ1LjwTZYVxvWV7XHnFW2vVKtuyPoZf0wg5TzjDQJfKNBCCGEEEIISTh80CCEEEIIIYQkHD5oEEIIIYQQQhLOMZHRsFjRA2eUz1L7Mi/P/wT0rJ3dQW/cjV7YW7t9BvrM5NWgb7z9TtB5s3Ds4k2XhX29HYdi3uNM13eg5y3Cben0EvoHD2XNjqMJix19jcbnbWDOvVRd3gd0h5c3g/Zv2gK65Ia+oCtO9IGurMNn9vQbcf2rNvUCnbEkPDZ37tfoo5SF34O0dUev9eah6Bk1bTEzVJKEvuOsl4U0BSoXpNtU+kr0+ga/VeGZg8wVkSYgGH3M+vU3oKd+uac1aLsVv+8J4iW2S9pO0Nt9mKt4rhz91292D5+8bU5OhWlPlhaALg+ga79zEl6H8uxY06OyHc6ffhxEuQJJeDx21KY1MOdeXHY8nrnJ2FcvL8c6BGK243TVPvZ40W/frxVmNlZVYJ2P2gBe15Lr1fFgbxHG9skS0H/viPdRVbPC5+2pXV+FaZPLsLbJiMyloF/0ngXapzIaezx4TJPt0e890p2Y2yqtw++7bJj7Ka3B87RFKuZFN5aGp39SgvcKG8uwf8l6MgV04dyG6/QkEr7RIIQQQgghhCQcPmgQQgghhBBCEg4fNAghhBBCCCEJ58jJaNSvhaFDFjG8y8bvjzrdsmAZ6OVV6Ju8oc180A9WDAP9/GqssTA7sxvo/9z1KOiZ404E/fKasHe7+On2MM33DfpoO63Dmh4RKF+3xYmeXuM5RsdGj1ErJSKTcXoPkGtHozfRmofjR287D8fHt5VjG1HDpYt7K3pnLWr6hop80CkVeNyqW4fb9KrxeAztI7EuhkWdDoWv7wG9Ohd9mCkdMRtw3JDgzIP1pC6gN92HbbBuE/q7+/X9EfTCOegTLtDxqibMZGy+V9WFWYaZIteHi5ps3ccyk27EgeZXePJAd0gqAV0ZwLyUTZ3MLdQ493r69KpwnaWgwd8FN3kwS5jjrABdF8Q+Kt2K3vBdaE2X9P/IsY865UqVv15jUzUOtlVh/aQrCr4BPVMyQf9Uje1jZw3mRb/ahfcD3fLwfiDTgdep7fW+f+TcvB35pJ4frmN1u/SDabumYz9/Rvc1oDPUMdA5G11HQ9fF8Krrt57fYsFG6VYZDX8Az/uKOhfolnnh7FXtAMyA5QjqwwXfaBBCCCGEEEISDh80CCGEEEIIIQmHDxqEEEIIIYSQhHPobH4xPPaxxi9PJGv+2BX0fc/PBj39lOdBr/OjL3NG2cmgP6/tCPrd3w8B3fLdhQ1uS/R0yX5Qvu6jOpOhPfUWq5Lh6bFyOBVjsM5Fq/FYr6T5v/AYeddjZqO8kzJSKnzZ6HH3Ka+vLRm3L1Cl6npY8VSz14X/toAVF2avwf3SfjL6di0B3FZLa/SQ5qWjV9vWuTC8HQGPCFpQj2x0G6mPzjjEyDxYXOhtDfTFrNX6C3G6tMRzyyWYA2rZdRfohR9hNsubicepbgSa4t3vN9wvxMJ/DtZlOfVRHEf+pRaPgB6+7EbQ2R8e8KqPLWLkeqwnon/7bPcy0PMqM0G3cGDmQmc0WtirQOtMRqWqhZFsDbfBNDue5z/VYA2HXV70/1fZcN3d3FtBn9wL+0gcnf8YRR3uQDD6b616eooT+4B2TszkiMpofLqlEPTVHTEbNWndQNAltXhdape6G7QvEL6PYkYjMfjVMXaowGWJB+vX6NzMLsGsnl2HKhXeAB45q8po6Fo8uouy23D5Llsc9876PjzOPPSBwjcahBBCCCGEkITDBw1CCCGEEEJIwuGDBiGEEEIIISThxGfzs1jChrFYXi5tLIuRwbC3Lwh9XnMTjj3de9BPoIvPLIu+7hg4Z+PY10O+Gg96Uq/JoOsM+u31OMnbvZmgt1yKHr9O7za8LRY7HgJbdgvQJhP9f8EU9JFXt0VPp3t32EMa9NeJzJ/e8MoPNyqTEVEbQ8J+Qstp6H833/wAuvddi0GvvBW91alp6K21rcZjlPOULnIQH7bcHNA7LkFvbulJ+LdlFoTHvjbV6KVOX4fH2JeHGaHqVjg9KRnrZlT7sC6Ho0N4vH2/r67pMxr1+wl9jOP1hB6EZ9TWtRPorX9V55q1BnRA1UZxbMLjYi1F/3xtJXrik87H+ia+Cpx/04W4fmcfrJfi2hPuM60YCZKKzth+UtpgFuCtxaeBvmww9nFjOqCeq3zFxwvWNNWfVmMbEIP7eeP9eMwWevDAbKrFWhZudeAcloDS0bNm9TMZIiIp9fRGL14bUmw4b7IN+7gcB2a1Nqjvv9jhPdCjBNvjMYnqTrwB9KzbarC/qq7DvrQwCzMZW31Yw0hTuwb77jbdsI+weHB920twfslG6YjHj08aRYvU+NJJSeo88wWxDaXY8bys8uH12m1XnbvqEnRmQ6PrapT6wteZlnpmzSHMQteHbzQIIYQQQgghCYcPGoQQQgghhJCEwwcNQgghhBBCSMI58KGYY43HG4NVL6CneHiP70OfHTV1MK1TCo5X/+VrfUB3vHppXOvWtLtmFeg7fvYz0J5+6Ic+tfUW/H4yjnX9ycB/gr5+7pWhz9s/aQPTalujQc+aiv49mx33a0D584I+/H7S2rBfL+CxiMyXw0eMMeq1X9B3HraJumbh5pl2M+7zjfPPBG0fsQ50oAv67Uc/NRP0Wzedt/9t/h8WB3pzjc/bwJz/W99ObKPZk5RW85szw7VY9tyGx7T4HFzXbvxTpCB3G+gWDpx/Szn6fJXrt+kxRkJmaBOnJ1T1K7ZmmbjovPCerCrEv6y2Ge7HCiydIr5tuC1Z36s+TOVojPoZZuRVn4BeXY25nK8/x/o8+lccbc315uE/eFuHzw+bE89748FtrSrGbJYtBfuBG5ZcB7pDC+yjbJnhbIIxXpEyOTZRfVCwsrKBGfdSdi3mFH48cyLoVyqwdkX7ZPTs67oZuk6Gz+Al16fG1NcZjmJ/OAdU6sNj3sqJ2awMm8qbKJbX4rXn2nS17VeEaxH5fXUibx3B+b4EETTYPtThEa8HO98U5c9fWaNd8XhOZ65Qky9EaWuGfn6L8ucvL8P2preXHDwd1Xmww58JOsmma2hhX6zrZris0XNYTjXdb8Urha6zYVOZYK8fp3s9R35FFb7RIIQQQgghhCQcPmgQQgghhBBCEg4fNAghhBBCCCEJJz5z18F4rxWpK9ADf/2gz0OfXyw5C6bN2obe53+f8TLoR7peBjrw0+q4tsV40CeZs6QW9EnXLgedbscMycvf9gX9luMU0PYfw97a9A3ot2u5UGUwXMqQr7D40cNZ1xz9gsm7wh5Sv9/b5CUTxGoTsfxvG+KskbDlt5izqClA72L6T+Hn4N1f5MO0TgPWg66bh7VXtp6FXum/LhgGusvSH0FHJIz03xIrbxJrumLD7eHPHXMxz+FUY6W3SS4D3T6pGPSqavQJF9eglztpY/j7/gC29SZHZ7lO7w6yon0y6DqVs/BiqQrxJ4f3q6NK+avVqkT5nTNWYHdXfiae55ZS7JPcxbj8b8tbg9bHJXlbdP+0H/9Ucf2A6/PWi5zYld3en4J/i4oCiGMj9hvOSqzh8WMvXFeXvKp6C/Mc3oyGPndU7RWLNfp+NYF654s+72Kch+v+DzMZn135N9BPl+G1J82Kbcal6maU+vAgp6ox9eOto1EZDO8LPb5+XVDVfbHgeP1W5R3X/v5dAawfUHJSeHqwziLyVtRNPTpRTSnZgcev2K36fS+2RZ8Kbm2r1Qk49PvnzMe+2vEblcm0qSxWEDcwzYH3GnvqsG8nB89JqZj/XFOXCzrbibmu7R485jpDoTMaQd3oFG4bzr/Hj311mhv7hNJq7Nt91dHvGY8E+EaDEEIIIYQQknD4oEEIIYQQQghJOHzQIIQQQgghhCScuDIaVrdLrJa9/jFLBpqnA7vQixjLG5v3yBegH784XNfgqy+7wLTCu74C/f7inqA3j8AqBXkqo2E7AQfU3zkA569sj9sWcOG2b1zVA7RrKfokM9DqKgG0ykr6xrCHeFcvfLarzNc+bVx36hY1Drzyodfk4fxpM8LrMv6Dy9E0imAgwlPdWFK34rbnLEUdtIe9i5ZVOG3P8gLQgba4n3KWoO9xU56qP1ITfcx544/upY78QvT2Xn+MehGRVQMmhT5fuPp8mDa65SLQy6rbgt6hPKKbqrJA+wPYSIJrNoQ/G1XMoQnYNa6P2Fx7QwSP3PE8TPvZh71Bu0vwuDhUmQP3HrVf65WDcFahN7YmG5flRru0eJqhTvoBva5Zq1VdlyRc/tZ/YT+iTk2xpqLW/YCuy+HNbLjNeJqj9rdQx82HK/enqX6iOWYJ+qraP2URlV0OIxG5ClXPJL4STUDpdZjBuOkerA1xSwbWyXiopBdojy6soOzQG2tbgE5RmYwcRwXomiA2ioDyb0fU2agXPEq2Yg2HDBXk2e7NBB05P7aJHaqf8GWF93uw9hBcOw4DQRvub123Qmzq+puJ+8ym5l+8uh3oziqjISV7om6Pbvo6s6FhHY1GEkdmUuesdqt6NZ2SMEO5phr7TqcVzxWdpYpcH85fq2qj2VXmI9WJfUq1B+8Za+t0OLEecWZHmwq+0SCEEEIIIYQkHD5oEEIIIYQQQhIOHzQIIYQQQgghCSeujEawe6EE7Xu915uGpcE0Y0H/srGiF8xei14xu8o1dHIsDn2+ZshnMO0/fxoAuq3/O9Df3/kM6M5Z43FblIVND2WeuRJ1wIXbmj4bjbk70WYuKVuj+yo9GeHnubzPceUlJ+Oy8z9Gv2BFPk63qiOWoUuGBMz+Px+BFJ+m9ltmw77g3Oxy0NqnWLUZM0OuluitPScf626gYz0SiwOXb+2AOQl/M/RxVhWg39+bgm2ophXq0/4QbqMZG9BL/VoJZi6sFSpP4sU2YqvD6Tlp+PuB3xdevjkEGY289zeK3brXi36P/yaYZk7F9t+sH/pfY1FWE97PDjW++PBWq0BXqZBElgP3UytHGeiWDmxjbosvqj5B+e9b2TGk4VH7uiaIOtmK5/Y6X3j6Zj/mcDb40BfsiygagpSroh39U7GT++UZ4fYX8NaJrIi6uMOKvTXWyNk+AvNZpSeF+43bz54L037ZDDMY/y7HmjO/2dkTtM416IxFlSpgomtVxEL7wT3B6GPgb/Vkhj7r9qvbgCeIF4cKP25rqg3Pl0w13r+lXs0Ii/fY/A0y6MS/q5kL9+mWPbgPnS1xH2U48Lri3Br9+AV2Y0ZDZ3Tsdmw/VnXfVBfA5df6whqvOORASVe1cZJseI5m21Uf4MNj2MJdBdqmqnI51XmWZMM+plYdY6/KTunMR7ILv19+ZN/miQjfaBBCCCGEEEKaAD5oEEIIIYQQQhIOHzQIIYQQQgghCSeujIatok5s/xtnOnMletQzl5eBLu2RCdpdhj61qla46k+nhscvz1qN87rao7996fMnge7SFnXuUvTIBZwqH+LB6aWdcFvSN+L0kpPQr+8qAxmR6Qjg7BJ0hKeXdkY/nrMMDXZbz8LpLb7DbTFWXFe1qg/h3Foa+mwNoie3KfAUnSoBx14v8MaLcZpzl/K7luO222rwb/cnKW9iUrgdVNUpv30y+irTOuHfqsc7/2ZHPujkMeiBD9px26x+/L5PZS60NVvZMMVZjd93rcQv1P9+RYGqpXIi/q1BR5bSat0qdlHXAtfdeWI9HfSIbJImxXi8oZoR2RO/hGkHW70hJcq0JS7lWg6o8c2TsThF0IOZCosF24glNdraRETVWjF12AaDHnX+HaYxzEVEPpWeoHOahzMb/qBXDiU1l/QBXfBrzI+c1+wH0P2S5oOeVd0VdKEznPPZ5MNjfPPmfqB1HYI0R13U6Trn09aFnvt0O35f5yI21GGdjWTlz3apwODOAGbN6o+przMZq2owb2K3YHvXXnP9/bYqU5T7dfhzwCeyWY59emRsA/1TTSfQSQ48PjrnkrE2vvWt92AP6FLLr6nDa0GmE69ze2oxe0UaQNf2Mg3nP3UGo4Uq5lQRxOuKJ4D3NbouRkCi18XQmQt9nurlZzixj/GpDIclM0r/fRivOfXhGw1CCCGEEEJIwuGDBiGEEEIIISTh8EGDEEIIIYQQknDiymhYamrF8j+/WVVrfEapa9YMtBetpuJLRe+rJwu1uzjsJatsg5uVswR9iuXt0AebrTIZu09ED5uzDLfFWYnrTtmG369SuQdl0xU7bk7EdJ3ZMPUWl7wL16WzAc4KlcFoiX+LUUdMWYrFVIbHdDaHwHudvHSz2K17faVZ+YUwrQaHvxdPM+VNLFa5h50YPvC7w9qThsd8czP0F4sLfZLOZPQ96vHJ+/1yGegFW9uDzkhCX2SqXYUwFFbB5VuUD/PW/HmgV3pahT6vqcmBaUGD7S/FHj1rM3NNN9DdW+4E7f13OGtgAvGN+38gBHbvEYtl77GztUDPvDTLRG1X9SD8eBwtPpWDqDe/xd+w73bvzHgMTBKeqLYaPMZ63WKN8TuMyktZMlXOR89vUf2CTc1Rb30mCb3axqF8uf7ox9HYcF1BF3Yclq3hrIElaBfB6EHCsRe0CdVWueIvM2Cark3xTVX7qFrXi1hnC/veK/zop+6euhX0Vg/mnTQOlXPQfupY9Utizb/DgxdGfa5vrcHsWKojfO6fmYWBAJ3vKFW1U1qpC18zG473v92POmvGT6HPfnNoczuHCouqLaVr6dTl4XUjyYE6w451N7J+xH0Yi58qMVfTKh3zAaur1bVA1HmsL/jkoHm/7BTQ7dwloEt8WDNOHwNdF0NPt6tAp0sFOmsteN+T5ox+vXfYsI+y2Zv+mn6w8I0GIYQQQgghJOHwQYMQQgghhBCScPigQQgh5P/ZO+/wqMq0/9/T+6RXShJCBxVEBKQXRQE7FtYCKsqrYPmp67q7r6uuu/rqupbVFXVfF1zEV1FBVEDEBVFEFCkWpEPo6W2SSaY+vz9YZuZ7TzJJYAKE3J/r4mLuOXXO85znnJPz/d63IAiCIMSdFnk0gmXlFNQc1Q5rgjkwzVTFdGIsjzFLP00sVTFZy8K6s6oc3K3Sviw/PpMp1qWjDjZhF6s9wWXgZu6hwNjEalskb0WdZn0K7p/9EP64st6oOY787Xzb/LhZynhtCTyOjj2oCS3vi/rBQHll+LNiBRZagUBxSUiPn/ZqcRNzIxo9Hkctq1ugSQjrmYMJrKYB08/7kvCYa+tja9R3KszF70xGTXxQi1pq3X7U5mrdqMvkGnq/Hdf3bMqNuP4Ib47Oi23udeBvY7JxMlXhF51rWL783ayuy5E94c8noU/AtkvL8AseC8dFS7Ojc2V3pErYfxL6xI67skhrPnqO/kr3NUzbU4e1BdKNeHEIMB8D9z3srwv7LrLMqHn3sKIzHUwVEHOPhDuI5209W77Ih+NCXQCnpxhqITazIjeHPIkQ8zocFyZhDZFRlnCdh6/qsmDaKjeOYTur8Th+XtMD4gDTjs93sItw5cGIeU/uOHG6oLXF9uLp2JmnL66COPbSRD8XYhtekvcLxDVe9JHZmP7f42vRLVu7RaNj3tZgxDWTeeWyjNiGbma65bV0jNrYPi4ecxJ0aPLlY4iZ1dXwsroa3AOi1bXAo6Hhpt6TU2dD3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnZZ5NOo9FPxPTmBjFWq7Knqg9otJC6PqZvgcuLyhJkJTx2Vk7HGIS+BYWnWqT2Y1Plgq/6CJ5Tq3sxWymgslBrYDLI8xaVAPqHWxmgqRErpM9HN0zUJfQ2U9+lHcXtTvVTN9nu8n3JWkSC2iaqLOwClG+VHRGqhErSTxOAaxs9s3Pd3axHSuZGzqyPIneEuDczWMuelZYtKUTlgQTjYa/9F/RES5hhKYVmTC2hFVATxbUvXoSwuwC0RHY7gISFN1LCr86PWq8OGZzz0dJuax4NNTjLhvfHvJWvRsjE/EAbubAT1LM3b8CuKnFncIfQ6MQ38J9934/LhtHdNu89pAPRKw3s52an/wuilmC964pJix/XjfDBa2zJdYV4r9LZCHV4rODmzj7jZso03aDiScGBo9nsNaVueC+7L4OW1qoqYW92UZtLHvFnhdDU4982gkmdHjUeFq6u7l1CNvNARBEARBEARBiDvyoCEIgiAIgiAIQtw57lxpKW98g7EWXy9pzsXUe+6O+HqnlqWkdeWFXwTrMZMosexioVfwxzBiRsMoKZWzAF+nW8pwBYZqjDV+fJVm2I+v+v1H8HUmBZsvUeIpXXWdO0Kc4sXXYskW3BeNH7cVLD2AcbP3RBAE4eSQ9/v1pP9PGuybUm+HafcM/DfEI+zbIN7pycSVKRxD93vC2lieipKnm/Wwi4NeG2QxSltr/bi+IBMsmdjF6FxbAcReJrt48K1bIe782FqIjbQP4vSI2HYtpq/dXpIOsZZJfj0e/K117NrDU+s2LTA983AHsX35MUw3YQrg/XXJEAfrWYrgJjCUs/seHwpluUwmQYc3Q75A+2ujeMPT6Bs0KH/jY0RdAFNe8/SzPN0sHxOMTBrFpVhR8j22/mompq7zo7TLaePncQxY2YmTJa+XNxqCIAiCIAiCIMQdedAQBEEQBEEQBCHuyIOGIAiCIAiCIAhxJ3717JlPQX3/M8SW73H2lqT7PNXEM10oT+nq31MQx7ULgiCc3nSbtgHiT00ZEM/+wyUQz7h8OcTj7L9AfHZSWMN80I/pZvf47RBXBtArWOhPhNjGPBppOjQAXmRF/fQRtr0R//driLv8Br2MnQk9GS3hvo4rIP4ptRPEXPudqcf04BtqcyHmXpgN5gGhz1qlJWqB9LutELDg31YPepMg1rD0yJnMALqhFI+5nVrm0XCgBYdseuxvFd7Yd0Y+n3g0moWWJ38Oo0lwtGhVepae1sjiIKu/4GEeMp6+1qrDNueeEI6RlVOo8aKviKe7PR2RNxqCIAiCIAiCIMQdedAQBEEQBEEQBCHuyIOGIAiCIAiCIAhxJ34eDUEQBEFoClZzSXlQs5z7e/Q1LP+9E2MaDHHt1YNCn0v649/O9L1QYz8gG+sOdbdhDn3ORl8OxLPeHwRx3sO4r10I4yZhxyJWTaa7/3YXxHo3+gl0XpzfWIM1QkzlqBX/cSUuH2nKCCofnYkEDKjdrwtgTQKzAY9RAivqVVqFnh+MmsZajG3C9f08dujQKBMMNu49EJpHIAU9GryORYD9/Z1PNzCPhlaDbepmdTe0zPdjZnU2+PpMUZ6Q2C5hiz58rp6ubg15oyEIgiAIgiAIQtyRBw1BEARBEARBEOKOPGgIgiAIgiAIghB3xKMhCIIgnDxi+BCOB9sH30Z8jj1vUVRsbnC+MKi/zmupB6MpWnAsMl84/hocwlGCUR4NYyNzHoXr8331TdwyaZiHQqE+X1+H/anajzURvEH07Oyqxxozfo/csjUHDWuHyFbwO/CY8zYOKlyW16fh8DoZLZ2epK+FuEKHtX5cWra/rK4Gr/NxOiJvNARBEARBEARBiDvyoCEIgiAIgiAIQtyRBw1BEARBEARBEOKOCP4EQRAEQWh37HGlxJx+yJsEsaqLfcuk0bEaMX7U55uKsC5HPavjwf0BQWJeg/rYfgGhaXx2bEOb1tPInEfhbeLyoWeiqToX3KNR6sfqKyZWV6PSZ4m5Pl8A+8DW4rCPp6OmDGdWvFbOqUHeaAiCIAiCIAiCEHfkQUMQBEEQBEEQhLgjDxqCIAiCIAiCIMQd8WgIgiAIgnDG407Dv60OTDwC8fYqrFuRqq+BWONp4m+zzKNBzKOh9WKcYKiHmPsBEnR1uHp7bD+AcBQVw5vgdWAb6litnH62/RBfaMV4J/NQ8DocOsJtW5kHw8PqcliZh+OAzQmxWeOD+D3z+bi/ueH9ey+jP0zzF/LKQacGeaMhCIIgCIIgCELckQcNQRAEQRAEQRDijjxoCIIgCIIgCIIQd8SjIQiCIAjCGU/aD+iJWJZ9HsRKj/r61/ISIO6wuom6BIFAzMmq4CDEX+3rAnF6AnpCvtfmQGz8JXaNBeEoyuttdJrz/9ZBPHfbBIhd3RwQP5uKf48PmHF9fhvGPjv2kaARYw1aQihowOmGatyetRB9O/panH/Lzr6hz9rCzRQTFYw9vZWQNxqCIAiCIAiCIMQdedAQBEEQBEEQBCHuNEs6dSxVmJ98RKdHRXOhGfjpaFq0WKnejhfpE20T6RMCR/qEwGmtPnGq+0PAz9LJ1uNOcOlUwO2B2O/DWya/wtSjGna8lGLpbRVKegJu3B+/Hrfn07D5PeH5+bZbk7Y3RqDciGLstybA29gAccDLpFNs1QF2Fx1kfSgYbEI65Wfz17PteXGDGi/O74/o09om+0Tzj0tTtKRPaFQz5jp48CB16tTpuHdIOLUcOHCAOnbsGNd1Sp9o20ifEDjSJwROvPuE9Ie2jYwRAqc5faJZDxrBYJAOHz5MDoeDNBpNU7MLpwlKKXK5XJSdnU1abXxVctIn2ibSJwSO9AmB01p9QvpD20TGCIHTkj7RrAcNQRAEQRAEQRCEliBmcEEQBEEQBEEQ4o48aAiCIAiCIAiCEHfkQaOZzJ07lzQaDRUUFLR42WnTplFubm7c90k4tUifEI5RUFBAGo2Gnn322VO9K0IDTJs2jex2e5PzjRo1ikaNGhW37Y4aNYr69u3b9IyCIJxWtGRMf+yxx8RfEoPT+kHjp59+osmTJ1NOTg6ZzWbq0KEDXXjhhfTSSy+d6l0TThHSJ9ov0vbti1deeYU0Gg0NGjToVO9Km+TJJ5+kDz/88FTvxilBo9E0698XX3xxqndVOE7aahu73W567LHHYu5XRUUF6fV6WrBgARG1/XO5WXU0TgVr166l0aNHU+fOnen222+nzMxMOnDgAK1bt45efPFFuvvuu0/1LgonGekT7Rdp+/bH/PnzKTc3l7777jvatWsXde3a9VTvUpviySefpMmTJ9MVV1xxqnflpDNv3jyI//Wvf9GKFSuivu/Vq9fJ3C0hjpxObfzf//3f9PDDDzdrXrfbTY8//jgRUaNvT5cvX04ajYYuuugiImr75/Jp+6Dx5z//mRISEmj9+vWUmJgI04qLi0/NTgmnFOkT7Rdp+6MXKKvVeqp346Swd+9eWrt2LS1cuJBmzJhB8+fPp0cfffRU75bQRrjxxhshXrduHa1YsSLqe05bPcdqa2vJZrOd6t04qRxvG7cGer2e9PrYt9PBYJC8Xm/MeY6xdOlSGjp0aNS1rq1y2kqndu/eTX369GnwQKenp4c+z5kzh8aMGUPp6elkMpmod+/eNHv27KhlcnNzadKkSbRmzRo6//zzyWw2U5cuXehf//pX1LxbtmyhMWPGkMVioY4dO9Kf/vQnCgaDUfMtXryYJk6cSNnZ2WQymSg/P5+eeOIJCgQCJ/bjhQaRPtF+aW7bazQamjVrFn344YfUt29fMplM1KdPH/r000+jljt06BDdeuutlJGREZrvn//8J8zj9XrpD3/4Aw0YMIASEhLIZrPR8OHDadWqVU3us1KK7rjjDjIajbRw4cLQ92+99RYNGDCALBYLJScn0/XXX08HDhyAZY9p+zds2EAjRowgq9VKv/vd75rc5pnC/PnzKSkpiSZOnEiTJ0+m+fPnR80TqaF+/fXXKT8/n0wmEw0cOJDWr1/f5DY2b95MaWlpNGrUKKqpqWl0Po/HQ48++ih17dqVTCYTderUiR566CHyeDyNLsPZsGEDXXDBBWSxWCgvL49effXVqHmKi4vptttuo4yMDDKbzXTOOefQm2++GTVfbW0tPfDAA9SpUycymUzUo0cPevbZZ6FCr0ajodraWnrzzTdDEpJp06Y1e3/bA7HOsea0xRdffNGgNOdYv5w7d27ou8LCQrrllluoY8eOZDKZKCsriy6//PIof9+yZcto+PDhZLPZyOFw0MSJE2nLli0wzzG/0e7du2nChAnkcDjohhtuiNtxaS98//33NH78eEpNTQ2dl7feemuD8zY1vjTk0Th2LZo/fz716dOHTCYTvfrqq5SWlkZERI8//njo3HzsscdCywWDQfr0009p4sSJofXEOpc3bdpEl1xyCTmdTrLb7TR27Fhat24d7MsxP+mXX35JM2bMoJSUFHI6nXTzzTdTRUXF8R7CZnPavtHIycmhb775hn7++eeYZrrZs2dTnz596LLLLiO9Xk8ff/wx3XXXXRQMBmnmzJkw765du2jy5Ml022230dSpU+mf//wnTZs2jQYMGEB9+vQhoqMDwujRo8nv99PDDz9MNpuNXn/9dbJYLFHbnjt3Ltntdrr//vvJbrfTypUr6Q9/+ANVV1fTX/7yl/geEEH6RDumuW1PRLRmzRpauHAh3XXXXeRwOOhvf/sbXX311bR//35KSUkhIqKioiIaPHhw6GKQlpZGy5Yto9tuu42qq6vpvvvuIyKi6upq+t///V+aMmUK3X777eRyueiNN96g8ePH03fffUf9+vVrcB8CgQDdeuut9O6779KiRYtCF40///nP9Mgjj9C1115L06dPp5KSEnrppZdoxIgRtGnTJniQKisro0suuYSuv/56uvHGGykjI+OEj2NbYf78+XTVVVeR0WikKVOm0OzZs2n9+vU0cODAqHnffvttcrlcNGPGDNJoNPTMM8/QVVddRXv27CGDwdDg+tevX0/jx4+n8847jxYvXtzguUx09KJ/2WWX0Zo1a+iOO+6gXr160U8//UTPP/887dixo1m66YqKCpowYQJde+21NGXKFFqwYAHdeeedZDQaQzc2dXV1NGrUKNq1axfNmjWL8vLy6L333qNp06ZRZWUl3XvvvUR09OH1sssuo1WrVtFtt91G/fr1o+XLl9Ovf/1rOnToED3//PNEdFRWMn36dDr//PPpjjvuICKi/Pz8Jve1vdHQOdbctmgJV199NW3ZsoXuvvtuys3NpeLiYlqxYgXt378/lBRk3rx5NHXqVBo/fjw9/fTT5Ha7afbs2TRs2DDatGkTJA/x+/00fvx4GjZsGD377LNt8i3MqaS4uJguuugiSktLo4cffpgSExOpoKAA/iB0jOMZX46xcuVKWrBgAc2aNYtSU1PpnHPOodmzZ9Odd95JV155JV111VVERHT22WeHllm/fj2VlJTQhAkTiCj2ubxlyxYaPnw4OZ1Oeuihh8hgMNBrr71Go0aNotWrV0f522bNmkWJiYn02GOP0fbt22n27Nm0b9++0ENzq6FOUz777DOl0+mUTqdTQ4YMUQ899JBavny58nq9MJ/b7Y5advz48apLly7wXU5OjiIi9eWXX4a+Ky4uViaTST3wwAOh7+677z5FROrbb7+F+RISEhQRqb1798bc9owZM5TValX19fWh76ZOnapycnKa/duFhpE+0X5pbtsTkTIajWrXrl2h73744QdFROqll14KfXfbbbeprKwsVVpaCstff/31KiEhIdSOfr9feTwemKeiokJlZGSoW2+9NfTd3r17FRGpv/zlL8rn86nrrrtOWSwWtXz58tA8BQUFSqfTqT//+c+wvp9++knp9Xr4fuTIkYqI1KuvvtrSQ9Xm+f777xURqRUrViillAoGg6pjx47q3nvvhfmOHfOUlBRVXl4e+n7x4sWKiNTHH38c+m7q1KnKZrMppZRas2aNcjqdauLEiXBOKnX0uI8cOTIUz5s3T2m1WvXVV1/BfK+++qoiIvX111/H/C3H2vGvf/1r6DuPx6P69eun0tPTQ/33hRdeUESk3nrrrdB8Xq9XDRkyRNntdlVdXa2UUurDDz9URKT+9Kc/wXYmT56sNBoN9HubzaamTp0ac//aCzNnzlT8dqexc6y5bbFq1SpFRGrVqlWw/LF+OWfOHKXU0fHi2NjQGC6XSyUmJqrbb78dvi8sLFQJCQnw/dSpUxURqYcffrjZv7890FAbN8aiRYsUEan169c3Ok9LxpdHH300attEpLRardqyZQt8X1JSoohIPfroow1u95FHHom6N2jsXL7iiiuU0WhUu3fvDn13+PBh5XA41IgRI0LfzZkzRxGRGjBgAFwzn3nmGUVEavHixY0eh3hw2kqnLrzwQvrmm2/osssuox9++IGeeeYZGj9+PHXo0IE++uij0HyRf4mqqqqi0tJSGjlyJO3Zs4eqqqpgnb1796bhw4eH4rS0NOrRowft2bMn9N3SpUtp8ODBdP7558N8Db2ajNy2y+Wi0tJSGj58OLndbtq2bduJHQAhCukT7Zfmtj0R0bhx4+Cvt2effTY5nc5Qmyql6IMPPqBLL72UlFJUWloa+jd+/HiqqqqijRs3EhGRTqcjo9FIREf/ul1eXk5+v5/OO++80DyReL1euuaaa+iTTz6hpUuXhsx8REQLFy6kYDBI1157LWwzMzOTunXrFiXHMplMdMstt8TnALYh5s+fTxkZGTR69GgiOioduO666+idd95pUIJ43XXXUVJSUig+dj5HnsPHWLVqFY0fP57Gjh1LCxcuJJPJFHNf3nvvPerVqxf17NkT2mzMmDGh9TWFXq+nGTNmhGKj0UgzZsyg4uJi2rBhAxEdHWMyMzNpypQpofkMBgPdc889VFNTQ6tXrw7Np9Pp6J577oFtPPDAA6SUomXLljW5P0KYhs6x5rZFc7FYLGQ0GumLL75oVKayYsUKqqyspClTpkA/0+l0NGjQoAb72Z133tmi/RDCHHtz/Mknn5DP54s5b0vGF87IkSOpd+/eLdq3pUuXht6AxyIQCNBnn31GV1xxBXXp0iX0fVZWFv3qV7+iNWvWUHV1NSxzxx13wFuYO++8k/R6PS1durRF+9hSTtsHDSKigQMH0sKFC6miooK+++47+u1vf0sul4smT55Mv/zyCxERff311zRu3Diy2WyUmJhIaWlpIZ0lv6ns3Llz1DaSkpLg5N+3bx9169Ytar4ePXpEfbdlyxa68sorKSEhgZxOJ6WlpYWMSHzbQnyQPtF+aU7bEzXdpiUlJVRZWUmvv/46paWlwb9jNx2RBvM333yTzj77bDKbzZSSkkJpaWm0ZMmSBtvzqaeeog8//JDef//9qIwiO3fuJKUUdevWLWq7W7dujTK1d+jQIfSQ014IBAL0zjvv0OjRo2nv3r20a9cu2rVrFw0aNIiKioro3//+d9QyvL2P3RTwm7r6+nqaOHEi9e/fnxYsWNCsY7tz507asmVLVHt1796diJqXiCA7OzvKqHts+WMa/WNjjFaLl+RjGXP27dsX+j87O5scDkfM+YTm0dA51ty2aC4mk4mefvppWrZsGWVkZNCIESPomWeeocLCwtA8O3fuJCKiMWPGRPW1zz77LKqf6fV66tixY4v2oz1SU1NDhYWFoX8lJSVEdPQB4Oqrr6bHH3+cUlNT6fLLL6c5c+Y06Ltq7vjSEHl5eS3a38LCQtq4cWOzHjRKSkrI7XY3eB/Sq1cvCgaDUd4/fh9jt9spKyvruGqBtYTT1qMRidFopIEDB9LAgQOpe/fudMstt9B7771HN954I40dO5Z69uxJzz33HHXq1ImMRiMtXbqUnn/++Sizrk6na3D9KsJE11wqKytp5MiR5HQ66Y9//CPl5+eT2WymjRs30m9+85sGjcJC/JA+0X5prO2PZSVqqk2PtcONN95IU6dObXDeY5rZt956i6ZNm0ZXXHEF/frXv6b09HTS6XT01FNP0e7du6OWGz9+PH366af0zDPP0KhRo8hsNoemBYNB0mg0tGzZsgb3kReUa8w3cCazcuVKOnLkCL3zzjv0zjvvRE2fP38+vCUiav45bDKZaMKECbR48WL69NNPadKkSU3uTzAYpLPOOouee+65Bqd36tSpyXUIpy8nco41pmlv6K3bfffdR5deeil9+OGHtHz5cnrkkUfoqaeeopUrV1L//v1DY9K8efMoMzMzanme0chkMkU9CAnRPPvss6FUskRHvX7HzPrvv/8+rVu3jj7++GNavnw53XrrrfTXv/6V1q1bB2PxidwjtLR/LVu2jMxmc+ht7plCm3jQiOS8884jIqIjR47Qxx9/TB6Phz766CN46mzO6+zGyMnJCf11IZLt27dD/MUXX1BZWRktXLiQRowYEfp+7969x71t4fiQPtF+iWz75pKWlkYOh4MCgQCNGzcu5rzvv/8+denShRYuXAg3Fo2lWh08eDD913/9F02aNImuueYaWrRoUegmIT8/n5RSlJeXF/qLtoDMnz+f0tPT6e9//3vUtIULF9KiRYvo1VdfPa4bRI1GQ/Pnz6fLL7+crrnmGlq2bFmTVcDz8/Pphx9+oLFjxx63WfLw4cNR6Ud37NhBRBQy+Obk5NCPP/5IwWAQbiCPyS1zcnJC/3/++efkcrngrQaf79jvFVpOc9vi2F+2KysrYfnG3njk5+fTAw88QA888ADt3LmT+vXrR3/961/prbfeCkk909PTmxyThOZz880307Bhw0IxHzcGDx5MgwcPpj//+c/09ttv0w033EDvvPMOTZ8+vdX2KdZ5uWTJEho9enTUfja0TFpaGlmt1qj7EKKjfVWr1Ub9IWTnzp3wEFNTU0NHjhwJGc9bi9P2kXjVqlUNPjEe05L16NEj9KQZOV9VVRXNmTPnuLc7YcIEWrduHX333Xeh70pKSqLSKza0ba/XS6+88spxb1uIjfSJ9ktz2r656HQ6uvrqq+mDDz6gn3/+OWr6sdfrx+Ylwjb99ttv6Ztvvml0/ePGjaN33nmHPv30U7rppptCf6286qqrSKfT0eOPPx71W5RSVFZW1uzfcCZSV1dHCxcupEmTJtHkyZOj/s2aNYtcLleUJ6clHEs1PHDgQLr00kvhnG6Ia6+9lg4dOkT/+Mc/Gtzf2traJrfp9/vptddeC8Ver5dee+01SktLowEDBhDR0TGmsLCQ3n33XVjupZdeIrvdTiNHjgzNFwgE6OWXX4ZtPP/886TRaOiSSy4JfWez2aJugoWmaW5b5OTkkE6noy+//BKW5+O92+2m+vp6+C4/P58cDkdIqjN+/HhyOp305JNPNugZiByThObTpUsXGjduXOjf0KFDieio7ImPwccyCLYkbfXxcCxDGD83fT4frVixokHZVEPnsk6no4suuogWL14M0qeioiJ6++23adiwYeR0OmGZ119/HfrX7Nmzye/3w7jRGpy2bzTuvvtucrvddOWVV1LPnj3J6/XS2rVr6d1336Xc3Fy65ZZbqKioiIxGI1166aU0Y8YMqqmpoX/84x+Unp7eor9wRvLQQw/RvHnz6OKLL6Z77703lMr02F85jnHBBRdQUlISTZ06le655x7SaDQ0b96845LcCM1D+kT7pTlt3xL+53/+h1atWkWDBg2i22+/nXr37k3l5eW0ceNG+vzzz6m8vJyIiCZNmkQLFy6kK6+8kiZOnEh79+6lV199lXr37h2z9sIVV1xBc+bMoZtvvpmcTie99tprlJ+fT3/605/ot7/9LRUUFNAVV1xBDoeD9u7dS4sWLaI77riDHnzwwRM6Tm2Zjz76iFwuF1122WUNTh88eDClpaXR/Pnz6brrrjvu7VgsFvrkk09ozJgxdMkll9Dq1asbTZl800030YIFC+i//uu/aNWqVTR06FAKBAK0bds2WrBgAS1fvjz0Vq0xsrOz6emnn6aCggLq3r07vfvuu7R582Z6/fXXQ8bMO+64g1577TWaNm0abdiwgXJzc+n999+nr7/+ml544YXQ24tLL72URo8eTb///e+poKCAzjnnHPrss89o8eLFdN9990EShAEDBtDnn39Ozz33HGVnZ1NeXl5Uukshmua2RUJCAl1zzTX00ksvkUajofz8fPrkk0+i/BQ7duygsWPH0rXXXku9e/cmvV5PixYtoqKiIrr++uuJiMjpdNLs2bPppptuonPPPZeuv/56SktLo/3799OSJUto6NChUQ+XwvHz5ptv0iuvvEJXXnkl5efnk8vlon/84x/kdDpb/a/7FouFevfuTe+++y51796dkpOTqW/fvlRSUkLV1dUNPmg0di7/6U9/ohUrVtCwYcPorrvuIr1eT6+99hp5PB565plnotbj9XpDfXH79u30yiuv0LBhwxodc+NGq+a0OgGWLVumbr31VtWzZ09lt9uV0WhUXbt2VXfffbcqKioKzffRRx+ps88+W5nNZpWbm6uefvpp9c9//jMq7WhOTo6aOHFi1HZ4OkOllPrxxx/VyJEjldlsVh06dFBPPPGEeuONN6LW+fXXX6vBgwcri8WisrOzQyk3iaW8k1Sm8UH6RPuluW1PRGrmzJlRy+fk5ESlBywqKlIzZ85UnTp1UgaDQWVmZqqxY8eq119/PTRPMBhUTz75pMrJyVEmk0n1799fffLJJ1HtF5neNpJXXnlFEZF68MEHQ9998MEHatiwYcpmsymbzaZ69uypZs6cqbZv3x6aZ+TIkapPnz7He7jaJJdeeqkym82qtra20XmmTZumDAaDKi0tbfSYK6Wi0kdGprc9Rmlpqerdu7fKzMxUO3fuVEo1fO57vV719NNPqz59+iiTyaSSkpLUgAED1OOPP66qqqpi/qZj7fj999+rIUOGKLPZrHJyctTLL78cNW9RUZG65ZZbVGpqqjIajeqss84KpUiNxOVyqf/3//6fys7OVgaDQXXr1k395S9/UcFgEObbtm2bGjFihLJYLIqI2nWq28bS2zZ2jjW3LUpKStTVV1+trFarSkpKUjNmzFA///wzpLctLS1VM2fOVD179lQ2m00lJCSoQYMGqQULFkStb9WqVWr8+PEqISFBmc1mlZ+fr6ZNm6a+//770DwN9WWhZeltN27cqKZMmaI6d+6sTCaTSk9PV5MmTYLj3JLxpbH0tg1di5RSau3atWrAgAHKaDSG1vXggw+q3r17Nzh/rHN548aNavz48cputyur1apGjx6t1q5dC8sfS2+7evVqdccdd6ikpCRlt9vVDTfcoMrKypo6XCeMRin5c6sgCIIgCIIgnAp69+5NkyZNavBNxIkyd+5cuuWWW2j9+vVNvoFtDU5b6ZQgCIIgCIIgnMl4vV667rrr6Nprrz3Vu9IqNOtBIxgM0uHDh8nhcEgmizaEUopcLhdlZ2fHPRWe9Im2ifQJgSN9QuC0Vp+Q/tA2kTGi9fl//+//ERFFFdmLB3V1dUR0NMtUvNbfkj7RLOnUwYMHJV94G+bAgQNxL+4jfaJtI31C4EifEDjx7hPSH9o2MkYInOb0iWa90TiWZWEYTSA9GZqY+z9oWZGTYKBl0yNnNZvwi+5YbbH8LEzhlfo1ZhfyF2B1xBNF17MrxJVnJ0HseO97XKAlNpgWHJem8JOP1tDSqCqy8eC4+sSJ0MLjoktKhLhuAOszvbAabOpPmNJOV4/rr+lghth2BOfXrv2RYsL/UnOKrFFtrk+cwHFzX4Za1Kpc7ENZf/v2uHfreDj0IGb8SfnZD7H50w0nc3dCtLk+0QK0DiyCGHQ1ninsdEBjwHFJ+bynZD9aq0+c9P7Q0r+QNzG+6PJzIT5weQbEvgRcPqjHOPtLvK6Ylm+MvT+xxr+TeE05k8cI4fhoSZ9o1oPGsddZejKQXtPMjqBhN4YabcumR6DV4OBLOnzw0BnxJlCvZQ8mzd3nZqLj2zew7UdtrwUDQAuOS5P8Z7Ot8TryuPrECW2wZcdFx/qMXo9tpDPx6XiMdHq8IOh5G7P5tU0dg6g2OEU5GNpanziB48bbTGfCPnRS+i1sn/UhAz5onOz9CdHW+kQL4NeO4Kk6xs1Ew/ZPac6sceLkXzdauv9NPGjwaz87pwNmtjx70NAb2HXlRK4bJ/OacgaPEcJx0oI+cdoW7BMEQRAEQRAEoe3SelmnVBDjFkhf9rzdD2KjCStlej341Nsx7TDECbej2SVIyRA79Ch7+fyXnhAbzPiXxoAfn8dGdNuF02vdEO+48FyIbQnhqqDmpSjzSvlfVmH4BCRmZzRN/G7NeVhwy5OAf3mq6IF/2XT1QUmCsQqnmyuw/3oS8andb8a/ZCVo+0OsXb0Jd1CySMcdfSbKFpIW4nndzfYVxO4gtvGCPgMg1uhYGwXZX2q0OD0xEatCK4Xz90otgviSxKUQ+36F53bpE+FX0JuxOwnHSdDlgljLzltNHmrDgzv34gqaeHOqdaI0S/Ofqr/HUHYLxN4MlBkYi1HKFfhlR8ztCXGmiXG56sbBEDtuOYSLV1ZB7CvF9ic2hFTPwHsTf88LIM7669oW7R9u6/SQ5woCR95oCIIgCIIgCIIQd+RBQxAEQRAEQRCEuCMPGoIgCIIgCIIgxJ3W82hwbWsTGvsdr5wf+pyRWA7TigoTIdYacV37DqdAXOq0QdwrDbXSaxefA3H3p9An0fd71DpursAcwT8UZ0NcWY46Xa0e9f31dWFtuPXKUtz3TqjRzHkUNZoaLe4Lt760V7Tn9ILYlYtt7tiF2mx3JurzdSbsQ7ZC7K+2HWW4vd7Yx8zF6AfwJKMnRD8W9f/6f5+a1KVtnhg644K/p0J8f8Y7EL9dMgTiugB6uyb2/Rni74o7Q5xuQ/38nn9jimR1Hnqz3PXYxzpZK3D5ujSI/Qo9GjenfB36/On/uxumZT7PtNvCcbHvLUxN/kr/tyHe5smCWMuyPlX4cZyxavHaYtKinzDIfDtdjMUQ6zQ4oD+Tf1ZDuy0cL3z84J5HhdeB8ltxzLBdj6nyLXps30AArxtaG/o7VTmOCZUFiRA7huMYEfyOef2+Yl6/yP1vr35Noc0hbzQEQRAEQRAEQYg78qAhCIIgCIIgCELckQcNQRAEQRAEQRDiTqt5NDQ61EIqpifUno21K7r3CNfC2HUYtcxcT89ll4rlu685gp6JAiPqKt2dUEdZegfmyi7ybIX4YFkixN4a1F3y/Ps8n77yheOSwgSYZuqFXgKNHptE+f0tmt5e8KZgvnLroXqINXVYJ8N2CNvkpstWQzxoCNZGue37qRBbVuNxd2xC7a7hAPaBuh5Y40HrwPz5PL+/0EwiNMoX5m6HSYsrsH5NP8cBiDe7sGaCRYd95LJOP0F82JMIccVQrIlwdcfNELsCrBI509/7g/h3HYsOx6WVNb1Dn++5YyFMW/B8JgknzhX5P0K8prY7xAGFbZSsx1opo+2/QNxJh16txTU9IN5dnw5xkQ/H/xIvjgtEHhLiCK8t0YSvoXo8tne/hBKIhyfgmPP4/kshNpjwejx8ENZF2VjcAdfPaoCtmdUF4i7rcUwJ1kdc5860GlsaTbi9TmUNkKbqkTQxPeoeLcDapYXra9H007R2irzREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDut5tFQPm/M6QcvToY4XYVz0putuKzHg/nvdbrYxSQU80yUFKEu1piMen7fJaiV/npLN4gNdtwfnYXlymYekaAPn9802oj9YXo7oxHXVXsp1l+wLvoW4qj6JGcyERpU7dmoffY5UZ9afC7WsXAcQD294xAe5xsTUI/vCmKfMbF2cWfh9OIxWFulphO2a30eaq2No/tCnP9mOJ9+YMduEprHjtlhH8ZgPdaWqPFjH6gKYB/wBHG4K/WilyvdWA1xngX12R2zMee9lnkwDBrU4nKPB/eEpBpYrZdAeP/3e7FuS9l0zO+f8r9Y+0doHiMcqLH/oQ5rpxR68FqxoRKnT8jdAvG7Ljyvi71OiKv95pjxyx3WQDyJcPwXTpCWatZ3YZ2UVQG8F1izHWtwmditCLPs0Po1OH8A7Z20JhHPc30vHIO0aVgrKHjgYOhzUz7YNodSRNRwe6mh/SDWevG3+px4YE+oblVTfaaJ6S32zZ7g9k5XX0Yk7eiuVRAEQRAEQRCEk4U8aAiCIAiCIAiCEHfkQUMQBEEQBEEQhLjTah6NpqjpgXrlTE1YZ+a0ooeizIu7ydMKc1mfCuAMWgPq+fxe1DZ63egB0Zhiz681oDCTezTIw+Z3hn+rluXZ5jU3yvrgstZFuOqmvC9nEpG+DFc+5ps31GIbJO1itVHOwj6T8R1O/6ouC+Kr7aiNfaLPYoh/s3EaxGXnYR+xHMR2S1vNaq0w+WzhmHB+/eRs1IXrvthIwn9gueIvOTfsreluLoRpG2tyIK7wYa2VqFWzgeOQJwniCxw7Yy5v1rA6GNW9IeYeDu4B4Z6OHFNp6HOmvgqm7bwF6zGU/W/MXRMaIVHrhtgdxPM00YDTt/qwHs5XdVjnwBPEa4dJi+OMP4j9t8KLvqEgYR/R9WZ1PX7BOgxC66LtXgNxdiKes4f3YPvpeqLPyrOT1Usy4hgTsDJTBzN5+GrQZxZMZnVWIkoDaXT4d2Llb6LewmmOzukgnebo+XjoNvQ+JVyMdasO/YLnJRtqST8SPW32iOPmScTj5HPgcUrAklpUl4bzW0piH1e+fp2H1dlg+8qGCKpPweVNeCmImp+vH7bFJgUNzE+MwxcFsPuRJxlX0O318DVXBTxEexrdNCBvNARBEARBEARBiDvyoCEIgiAIgiAIQtyRBw1BEARBEARBEOLOKfNodM0tgtjjD++KWY86V7MFfQn19SgsC/qYaI15NJgNgjS8Dgere8FFdNzzEfCz+bk20ti4h8NoRl22honoPKmxa4S0J7wpYT2s9TD6drzJLCE50yJ2XobaWl05am9fm3YlxInz3oKY6+87raiFWOvHdgrqsU/Up6PY0eDCdg8aw/PXdMDfkpyEXoFABdZvaFew3PC7B4bjrxaNh2kze6yGeBvz4Ri0uC6TDseZugCOKz+6sYZCX8tBiFe7esZcPtOEfdDH6nikGVHffZYpvP6ZW38F0xImMOGw0Cy0NqyLMNCEY/VHVXjt4LVWeB/Z58G6BiVe1NBXs1ouHc2VMffvB2a5c+egX8v0S8zFBaJo02ZkrakmakscfvACiD2HcVw/vA1r7fA/zdYXYv8iO7v26/HCNHnQeoiX7OkDcSCAG9gzORHi3B/Cn4P1eE3kfjZSbauuRtE1vUhnPFpnpvos5uF9FM8zyyg8TqljDkPs8uA11fxD+JrqysVltT7sPyXn43EzluP8dWm43/5kHCM09Ti/qZR5grvVQawqcF/5/JV9cf3aOly/sSoca1kdF/MFpRDnJ5ZDvGELes4cO3H889vxWNT0Df94v69ePBqCIAiCIAiCIJw65EFDEARBEARBEIS4c9KkUxoTvlIuq8XUk+n2sLTF7cNXSWenY2qzzYUdIPZ7mNxIi6/CoqRSUfsW+xWjNoYUiohINfG8ZjCGX311SMBcZbuO4Hs4Wy7LZdaO0Drw9WjAFPFKkMnV9LUsBbEVXzfWZWL/MlpQ1mLYcQhihxZfQ/9h7xU4/15MpVo7AGU1Gj++IlesDyrWRYL6iOnszX+wa0f8Yn07lk7FIPtK1JXM+3QQxHN6zYP4qSMXQ5xsQDlckGksefrZH92dIA6w8z6b5SHMMGDsDuIY2M2IfeqGefeGPuf84RsSThxNFqYF9iiUIeyowenZltjjb7XfHHN6pRfHnc4WPHdrA3htW12L8jtPIo5jLNuk0BAsjatGHz6Gikmnaq/GMcJ9DpOx1OEtUcDP5Ejs2q+vwTHA58TtGSpw+UX/HgyxqYKlWs3G5VU2Snh3zBkQ+tz9lg1s39h9DJeUnebpbu2HA6T/TymCCiZHLxyEEjZff5RCl7hQwuauxvNUOyy8vuyv8H6uJhvb6Nor10A876thECd0wjEiwK4b1vdR/ujGTLyktaIszJqE16FSMy7fqxveq+z4HtO4myLUUNVdsQ90c7JrkB/HH50Lf3t9KvaRSwb+CPGeN/JDn/0BptOKgbzREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDsnzaOh7YKa9gQLauIDESL2dCumfextR4/Guro8iDVaFTPWalkqUsU9HEy7GJUPN7a2kXs2NF58fhveJ5wDrKgefQg6PWrqshz429sTmmwmZow4rDo3aqsDVuy65hLWn8wsTZsNY0MqppCd9dg9EFvKsF3MnZmWl+lf9R6mrdXjdC3zcNSkhLWROi9Oc3ewQGzBjIjtm8gUjkyTbL8Yc+3d1+dWiJ/4BD0bb5ejXtqpxz7EPRpB5ruxa1CjyufnzEzaDvGVvcZCnFMtvox4409zQlwUYPpoPcsvyzDrfDGn61nKZH5t0bFU6ZUePLcPeXAcqkvFawfuvdAclL/xNisahMdXVaFmXetl1/IsNiZsRQ9OfTecbt2K3gC/jd2L4GWMzGVs7M/B/mIoQm+h3xGers/KxGlH0POl0aH+XvnZxk8zKrrrSWc6ep1Ozca0rLqOeFxqt2KaaUMe3jd16VQCcYeelaHPBavRF+XOxDZYfqgXbjsZx/laNzqn1AHsE1aWa1/HrAw1h9Bvktgd9zU1G30VqWb0o+zA1ZG1KHxszBeXwbRdZXicfFtxRNHk4X3NlD54s5FvwjIUO63hYxPwN78Ug7zREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDsnzaNRMhi1Ymn6fRBrI3wQ6UyTZmUityDLsaw1xK5zwXWzUR6MpmDz8/VHeTiYVLsuENZZ5tqYhk6Px+VgJeZQzumD+aEDW1DnfSYRtKL20WeNqKORgFpaYxnzZNhxuibIdJL12CiaGjfEVRNw296vUUdp24Hza5NRixtkngwe8zof7qzw9LRNqCmuzUJdLqq62xk8F3yEL0Ojx+ErSoN8uBjCHD0eZy07b7nHwsAE1b4Aq3GgRX2/WRt7/SYNtmugupqEVqaJoT7RgBrlOlbngpNkwHHAyvpAYT1qoHmf8gWxD/Hlg7E3LzREC+pF+FmdC50ztkfHX4PnrLMY113XEdszYOF+Twx9yTimlCfGvjeJ9GQQESlDeIVVF2A9BdsH6NEg5tGg09yjYapQpDMe/X3dktC3sLUU/Ztm5sngPtw+iejr/bE8XHutMh+vG2PHb4R42U99Ic7OLoe4aAvW3jl/6DaIN+RgvSXtVryXOPucAoh//h49x+cPxnu8/a5k3J+zsZ2PBMJenXR2HAZl4312UTJ6hJNNWMNjJ6srFOVTNIbvyYLa5r+nkDcagiAIgiAIgiDEHXnQEARBEARBEAQh7siDhiAIgiAIgiAIceekeTTqMpivgumXa7xhjXxGEmqXd7lRn8c9GUE/Pi9F1dVg+6JhOjbFdJFB7sHgsksfez7jsxtwgWpfWM8/Oe17mPZvTXdcFVtXyfmoz0veQmcsPuZ7MLrC7eRNYHUwqrENtB7UnwYtsbu2sqHzwboadZTO/Wx9Ntw3fR1O97Pt6TzYBwJmVnfDHTkv9kc/bqpFGuQzjhi/VQVjH4eg2x1zulWH+uwEPc5f4Ud/FNerck8Gx6ZFb5k7GFsPDrTnNo8jQRPq1H1ssPYE8bw9UoceC6cBvWA7alHDvHZvF4hvYHno97rRg8f9gj6F+9dEKRahAWLVi9B36ojzWnHc1u7H64A/C89Zy370aJSfy8551p6eDFy/8xdc3tuB+cKKmc+M3Vo4e6Gns7w43D/L+qKhx/YBLktNjI+nG36rhpTp6PHccBB9DuZ1eH22jMU6G04znqcr9mKtjHpX+P5Sn4bH5bvX+0OsHYHr6pmIXr+eQzFe9X0fiDPWYp+o6QAhbf93PsS6PuhJviNzNcS3rMJ6UFkrsM+YcsPb4/6RpAHoQevhwLoYnKV78Ld8W5+Lyx8M1/jQBViBkBjIGw1BEARBEARBEOKOPGgIgiAIgiAIghB35EFDEARBEARBEIS4c9I8GrW5qF206lGvXO0JC9P7Wwtg2luuIRDzOhZaPWrcOdyTwXWVWh1O13B9NINvX6NDzZ+qRc2oMSIfv1mDGk/uD+H5oKvQwkHo2Gjb6Jyoh65NbNznUJWHx9RQg3UvTKyuBrEm1zCjTdCE2lmji7UhS0FOOubj0eEzOq+bwet4+Cw4f31KxLwBnNdvY36ODtk4/eAhEohIxT7vlQc1pFWsTew67DPuJooYONj8Wg1u3xPEPmXQ4Jh3JNACj4YQF7xOHFMqm2hjXivFZsE2q/KhgYp7DTsYKyDmeenr/bg/3CMSNe4ITaNp/O+l+6/rjLOW4jmbsAPnr/bjdSVgwvZ1bMdzvD6Nj924fm8S29U6bGBdPfPs2HH5ZCtq7CsjairUZ8Sui6F8bWu8qU9TpDUfPZ7eCjzPvGfhb+ljxzoadX5sl2QH1odISA17XVJ7oSfi4Eq8ySpjnt9b07+EeNZzs3BbddgH6q/DMeD8jIMQf//u2RBrWM2uwn5YS822C8csP6vV0nNSuBPn29G78tl+9Kpwz9moZKzZ8YW5K8TB7bhvgaSwiSzglzoagiAIgiAIgiCcQuRBQxAEQRAEQRCEuCMPGoIgCIIgCIIgxJ2T5tFwZqKmLsmIOesPuBJDnzvoK2FatRf1ejpd7DoYHK2W55NmdTbY4r5Ay56/gh4mrDXi+vdXh4Wajg6oueT7lmBBDd2hDGuL9qUtoVhtAC3zKvjs4XbwOXBZfX3LEs4HDdim+iCrXYHp1MlQF7tP+ZwsdzvrRDov/pbKbrh9T1bYqxM0sn2rZcehE+bi17Rnj0bkcW5hbYnXy4dB3N1cCPFBLzqguCfDxOpmmDWoG+Y1EXgdjW0+bEeh9fGb8dxyBfFa4g9im3lZbNKiDr6wFn1lgUI2cDAcTBPN4R6NqBo6QtPE8Gp5UtkYwYb10uHMx8D8l+YDqI/3onyefOk4JmhqsD2DzA+gqtADwk05gSTsb0Uu1Mjr3OH9C1rZ9dOK9wpN1RE63Uj9IUj6/9RIO3gpXt8te/C47SjKhbj7kAKI+yQegXjN/54X+rw3Hds4+X68DiR6sM1nvoCeDFsR7pv9v/B63CMBa1XUMt+PeyC2S8pSPOkf/78pEFuHou+iZyru71dbwx6TrTvRb5JzUQHEF6f8BPE/9+M10WzA/ufrWwmx55twf/T7mn/9lTcagiAIgiAIgiDEHXnQEARBEARBEAQh7siDhiAIgiAIgiAIceekeTQ6JVZCbNd5Gp6RiGoVauQq62PrYHmdDO57iPZosOVZLnQ9OypBptsMBHAGrRE1eyxdP1XXNi68NepRE5dtr4LYn3nmPgtqTNjO+ho8jgFD+Ljz7mIoRM+PL5OZOJhsN2jANlRaPK4G5ovQu3EFQRNrc+bBYCUUovAzPa2hXB/xuRqmBcwsl7sVt33STtrTAW6gaqEvI5LOpjKI3UE8zgYN9r9yvw3iHCNqZfd40yA2s7oZh3zo+eB1NvSZGRD7CyO0vbw2gGqZJ0k4SsAY22vF4XUueK2UOh+rv1OJ7XTEm9ii7XGCpuPv3+0V5W+8noSlZyXEnh8TIQ4wPb6hK6vP4MP2tRxioy9rruSfsL9V1+IYwi8TtoOsBkM2Lm8zoYfEEzkMsG0HzukGseabH6gtYagNkF5/9Ac+OuRjmDa3wwUQuz7IgnhLUieIdybh2Jy1P9xHkiajh6KDrRLiCcnoY3h8A3omEnfhmFC6ALddfil6ZXTs/tT0I06vzoMwqnZLJye7J2Q+MkdyuGZIyibsPzuTciD+fkwJxKX/xhpdY65ZD3G6Ec+HFdoRoc9K2/yx9cy9ixUEQRAEQRAE4ZQhDxqCIAiCIAiCIMQdedAQBEEQBEEQBCHunDS5d7KpFmIt80UkmML5xs8zoi6x2o0eB62u8bzZDcE9FtyzwetyeDyxBfeaJup4aIw43VsfXl9lEPV5dqbBdOjRjMD1fWcSGgfmCFd6fO6N7CKeJGwzZUFtLfdk8EdoLc/5rGP6QhbWpeCpYXChDlhXjxv02Vg+fAvugJZJ7L1p4fXVdUAdr7kM99VvQU1mu/JoxPJkaFn9miAe5MMPoq7Xpn0f4q11qE/NMKBXxqPwSNcrHBdqAjguOQyVEB/yJkE8wr4N4hefGw1x/q8itMNB8WTEA1amgFK0sWsL8LHcqcc6GB4/rlDLyjDw2isGDXrH/AFcnnsVA2xYE1pOpPep1s38bul4XvXqcRDirVs7QmwuwjGgLpc1OLtu+K34haUYp9ezuh6uXJyus7PrDLtPUt3C91H6IF5jCofgdSTrG2pTVHQzku4/vs2/7xoF0/ystll1Tzwu6WtZPRIDHosjQ8Offb+gv+OgqwPE67ujr8F+ALd1YAq20cAuuyH+YUVPiLk/0zK4AvfVh31M9xOOGZUe9CjvqUDvX11EH983AY+Tcxf2x6//cR7E9V3ZvumwLgyvDVXdKbyvAW/z70TkjYYgCIIgCIIgCHFHHjQEQRAEQRAEQYg78qAhCIIgCIIgCELcaTW5t9ZqjTk91VADcZ+EI6HPfypBHVldFWqhk9Iwt2+9F7XT3JPBPRjco+HjGrkmPCCBOpxfo8f59ayuhr8kvP8HvCkwrUciijh53nYf0/RqTKg5VZ7G65Gc7vgyEyEOmLDdghE+Cn1d7HVp/LzuBTturLiJpr7x3OtERIo9guvqULsYYO3Ami1Ka20qZ7VYzOH9U6y/6Zn/o7oz9rfGq7K0M1Ts81Q/vBzi2ibqZnBS9ThGVQZwTEvQYafk6zNF1dVAz8a1vTZCvEH+7hN3WMp5MrE24l7BANO9pxrwWlNTiX0gpZB5DXXoAakL4LWJ12ziKIPU0ThhIuoQOe14jmr/jXr3glTUuxM7/rZDGBurcGCvS2eeiy7sOmTG2JiEHp7AQexPJjN6QHhv0G4P+xq9ydiX+b60NRJ3+UhvOHrCai/D47S/GNvJuZP5Oa/H+6iK7akQJ2wPX39vnLUCpr3603CI89OwXtKOi3BbnVKwrsXFKT9D/L2tB8S8BtiGgW9BfOGWqyHen459Ylg6ekD21+F1ZFjirtDnp1ZPgmkBvOSRc2IhxK6NmRB/8Et/iP938JsQr9k2OPTZ72/+vadc2QRBEARBEARBiDvyoCEIgiAIgiAIQtyRBw1BEARBEARBEOJO63k0MtLYN5g72KRFzXuuuSz0OcCSU2sMTXgmWI5lnnpfo2F6Pi6ob4JggBdlYHU42P75fSgMVtawlvKgF7WG09K+gvgvBy6B2GrA46TtjDmfAzv3NLLXpz/cRxEwYrtXdg0fd8WOuWbfEYh9g7pCbKhGrWvA0kRXZ31GG4jt6fAm8NoX2E5F56OTwliF6zOXhH9bbUbsmh4etPUIx4hVY4OIeqSibjfIjDdWVgTBxepiJOhRb+/Qoia1ys9q4uhw/e4g6rmD7O861X7UixPF0Lw2UTNEaB4uVgslyOpmBJi/L9eIem39EWzTpG2sjzDfjo/1uWRL7DoewXZVJKd1KPhVuBaGrxbrd9mZd85pRS/Anb3weqwditf2XGMJxBPZ8l0WzoD4+bFvQ1zoS4C4vBfWkuphxuvabzdeAXHQHt4fcxb+Ns8BXFdbI2jQUNBw9Pw7vA7vc4i1W+1w/O2/yf83xL8tRN+DPqKW2ZLCvjBteB56IDjbVQbExV9h/aVPL8b1BVLZvYcHx+7nyrHOxqGNWNeDLHhd4z6xZD3+drMmvD3LIRxAavLxvuWnsxZBPCNpCMSrP+0H8e2am3FfMsLHMeBr/jVI3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnVZThAZSnRAnGg5DrGOi+E7GsEfj47J+ME1vRJ0Zry3B617wOhpcyq3TBmNO17LHLx9bH4crxfUG1K756sP7++Ges2HaZf0xl36tH8WIBh2uK+hEb0BbRuvF36Z0TNNuCh9ZXodCY8YE0T4bNpqhOva2A05cXu/BVvTacX3+JNTT81oXhlLUXtd2Ri24fhv22cx1YW3vvotxX5K34L4qbuEYeBZOX/8TtRs0EQejCY/G0ETU3tYrHO649nU/M8PwuhgBprf3sPXpCPsE94DUB7FPdLUWQbxTG7F98WDEhajaPKwNa1nBGw+rqWTVoG/GegTXZziMtVpyDejpcLPx3McKe9SwRPeqCT+i0DR+a3hc8NXiOVfZm137i9AzkdAF9e/cV3XIhx7L0sBOiA1VzIfFfF+ZBqzBYGZeVR3zjw7OKYB4TUmv8L794oBpmnz0i7Q1arN0pDMePT8MLjzP/DYc6z1VeN784wDWwtC48Dw2XB8ea/slHYRpW6uxlkSVB9ts5jlfQPxSYDTE323qBrFzN57jflb46q3dF0Ks+qGvKz0Jr0v/3Ik+ii5JOOZMSA9f/9OH43126b/RT/LfxXjv0INdg75g977qEPMRRtYBin1bDMgbDUEQBEEQBEEQ4o48aAiCIAiCIAiCEHfkQUMQBEEQBEEQhLjTeh4NViOh1o+aukhPBhFRsq4m9PnL1agjS+yD83r8uG6tNrZWW69HvbPVxLTTXtRxGtj8Hu4BYaJ5kwl1lj5WR0NjCq+vfjd6V3IH4r5kWFCfV+PD41bjwJhl129T+K3Y/TSsdkVkXY3sVahtVUHmkajhfo/Yz9BaH9NCsy7UVD57fS3z4aSymgp7YreM8UjYRGKqSIdpOi/um4b1t7oM1E0yCeiZTWRNHBXbx5DDct5v92C+8sj840REniYaneunOQH2d5sgE7Hy6Zl67NP69B6hz/5C1M4Kx0cQh0vSsjbUshOf+/16GrH+k8GF8/v3HYDYoWF1jzQ4P792WHQ4P1nEm3OiBCLqEGiMbCw14/EdnFcAcb1CTw33XXHczCfG/XQ61v5atj7u++L0c6CfYOOhcM0GnwPXbbW1bY+G0aVIZzj6m2pZGQ1POrZb8ia8vh4u7Agx5eGxOFKUGPq8cP8AmJbdGe8v3R7sA3/7fgzEvG6adSfuizcJd4UNIVSfzsYcdr9ZWoHem54dCiHeV4kb+FtZ2DOS4cT7RxqE15gl+/rg9BXoOfJ1Y+dLMnrUbIfDHdzvx+tnLOSNhiAIgiAIgiAIcUceNARBEARBEARBiDvyoCEIgiAIgiAIQtxpNY+G1h9b28i1iu4IMS1LP09GPdbRKK/EWhIa5tFQrO6FX4caOreb5S4P4Px6I2rmuAeD4y5DfT7X+6d2COvkAt/gtrf58LfY9KiJK6pDvZ43EZuMZTluU+g82AeMriCbHm43rRf7gIYXO2mCgJnV2Sjn22L+EDPrExWY69qdi14bxSwZiXtwf10dsN3UwSOhz35bGm7biNu2HcR9M9TguoWG+awSvV5dLOjZcDMBP9fP8zoafMyy61AHzJfn+n9ewyFRh7VXghkRelnxaMQFrpnnHgqbPrbOuLPeDnHintg6+J2+VIiTjNjGZfU43vM+ptHF9hsKzSAr3EaOb/HazMpWkKM7tqdNi9dfXvvGxwd6DvdosDHDyNrboMGxvJaNSXyM8SSF+0f6OThGpFmwBog3EWuEBCpRr3/aESQ6ZqFi5W3oonOxVtT2LhkQJ7LaaLl2rDWx9tNw/TL7PjzHBpyLPqtPd/aG2PoLuiCDbN8G37AJYpcP599ThfWZOlhwTNi7KhfirO+xk9bdj33w+i4bIH7znXBdDv+POL50vh89Phek7IH4qyu7Qnx12i6IPznYF2JvYvga5fc1//FB3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnVbzaPhtqCurZaK7Ej9q3FP04ToaunoUOloNqFnrkFYJcVEl+hisNtTd5iRiIuPd5Uwzl4DaRbcP97W8FnWeaUmYqzglGzV3h6vZb7OGtZMlCrc9ghVB+JsHNXYuD2o2NRZ8NmzLHg3+mMvlr4aIw6ypqsF5naid1vqZT0eHfUjDpxtYzQMDE9dyixFbH5/fXI59zm/GH1OP0m3SWMINn/kt6nS9dlzWUMc8GpXMG0DtB402fNwV++EaPQ5naUY8TwNMQG1leuyoOhhM4G/mNQ+awMwE4VzfHeVT6xQex8w/tGhTQjMxszoaJi2ee1Yjtpk7iOe1Yct+iHnVix/rOkOcbcJrS4EGx3/hxNGlocfNZo04rzV47a7JxbH0bDtq2E8YdhnhdVs4vM4G92jkG9GHEbCE11e5OhOmGUYfhtiWyIrInOYeDdsRD+n1Rw9gRS+8s1m1uzvERhOet7x+xFer0J/X+YvwNbN4AN50fbz5HIgte/H+L8BusgImbLNvDudC3D0FvYDJzJPhNDLfTSqro3EW3ju7t2H9p7kV6L3xZISXr+yC18AD+7GPGLW4rY62Soj5NaqqFn98p6LwueX34/UzFvJGQxAEQRAEQRCEuCMPGoIgCIIgCIIgxJ1Wk04FTPgM09eBr/V6mjCuV+HXRX4HTwuJ7yPtRnxlcziAr5K8fnz9Y2UpDPOSMfXZ1Ky1ED+5/WKIa0vw9asvEdfPX3+m2TDNXCAiraWtEF9dfVGHx2nj7hyI++YdgrjQiK+J2zJczsTlSJFp5PwH8Tj4xw5o0bb09XjclQ6PO0+1SxpsY18SvkLU1+H8PnvsU0mPXYL83TqGPtt+PALTasZ3YvuGx8WbwvYl5pbPLFSw8fSfWjtPHYqv03Us3Sw/b3kqSk7U8izm0isum+CvpXVsut8qf/eJNzqWvZZlraZqP8pL0m0o0XQrlFIFm5Cf7KhNh7ijuRJigw7HISvfQZaaXWga1QGvidWFYVmtpisb9/V4zn5dgek9b8v8EuKdHpSe8DEiwIcjFvsUjs5eNgYE2L1NZ0MZxCPM2D8yupWGPleWYopXqwHnrT4XryPWApT9nW5U9DSTznhU1jTh0nUwbX0p3hdxOfvBskSIb5v0OcRv5F4Q+qz/Bbeb07kU4vpsbLPaVXhO686uhrhzYiXExW6U8nO6OlBalZSH0n53Oeqs83ri/QH/7VQe7lPVZ2EfGNNjB8QHaxMh1lvw/ODpnEfkYLrbtcP6hz4HPDqi76hZyJVNEARBEARBEIS4Iw8agiAIgiAIgiDEHXnQEARBEARBEAQh7rSavNvrQC1iZ2NpI3MexaENp/zKPhc1aVx/1ycLpwe9uC29FT0c3iBON7KUhhtqcyF21WL6M50d59frUddWXImpVi/uuhXiPTVhzd3usajJTNZh6jNHIsYuL2qI6zJw+SQ6c9HVx5jmxjZRRpaaVI8x94NoAkEWM78IOzO0HmxzvxX7FE9Ja6rE/TNWs/WbwvMHilGzqXSordUo5g2o50k1BSIi5WV6epZr0qDB4xaVbpZ5NnjM0+OaWPraoGK+HybYDnJPB5uf+36EE0fHU0NrsA0zTOjj8bNrxR4/prpUfjyvOT+XYCrKvBzU3GeYcXu8Tyqf/O2vpdRnoGY9MSusoa/aj/5N+x4c2C8e9RPEZQG8lvMU1fyc5fDJBg32lyD7224f5lV9u3wwxP8qwv2vcIV/q4FdHz0B/G2qjdl9jDWKdIaj5+uiNefDNGXCsbFPzwMQ17D7pDd+vgBif+Q9ohXHhEwbei7q/ehT+Lkfei4CVXh/WGGNXWSgkqWI/WT7uRBz3xBlxh5jeqQWQ/xt5whPkg6P0/pCvJfoyEo5VPlw33iq3pr9WKqh07bwvvl9sfczEhnVBEEQBEEQBEGIO/KgIQiCIAiCIAhC3JEHDUEQBEEQBEEQ4k6reTTq0vAZ5v2i8yDOtaF2tYslrFM/WILOA6MJdZIuH2rk9Gac7vPH1l4nGdEHcbA+EeJgkGmtmSfDz9bvq0Z9YCcz1umojNDBKSPuywE/bntizhaI3UHUCP9bdaAzFT+rveLcHz7uutQUmFZ0NupyUzdh/ntlRZ1lkNXN0BiwDZUOBa1Mmku6OvzC34H1QU9szwdfX8Ac3r7Oy3LpM5iliJQe97WNSXFbjaAbz2t3AM+dVD3q45vSWze5vRYuz+tqcIyVvkanabTYykrsHMfF/1X3hpjXsUhnHop3ywexNcQ+8BVHUNNszcP1c98Q76Maj/ztr6W403Gsr64OX2/1aXUwrcaE1+oiP3ogOhnw2q3l7c0GW0MLB9/aIG6f+7g+fR89GjkfFEF834crQ5//cujSmNsK6tvWlcHj0JDOeHSfzaWsphY70AOGYE2Qd7ZhXS3TRqyplFAaPs6lQ/CCergG+0CyGa8jSQmsLtoneC9yuB/WvUjtWAkxv5+0HGGeYRxyqKYj9olaL44RFj32IW1V+DY+aMN7VffORIgLqvHeOndMAcSa1Tjdipumqrzw54Cn+Y8PMqoJgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnVbzaARQRkZ2Pda2cPlR456sC2vsWdkA8tShBrPMiPp8P9OK+WNL3qmHFXWPy4r6xJxfwzwe3nrcH9Lh9A1VORAHIxJa62rw2W6PJwNiDyvgwPMcc71+W8abgMfR1QmPTfrGcJ/x98B80C48xJS2AdsgynPhR62tYpp37qlwHMYDzXO1s/T3pK/BL7yJ2I4GN9NdZoSnG1mHZ6nXqS6V+UuYrhszvwvHqPRjm3W3FELsVS0b/riemnsueF0OswY9F1r2dx0f4fyGwnCOc14pRQXZoCg0C1cuxgMteyDeXN8Z4l5mrGvw1NaLIc4krJHEsRzEMY3XWkk2oN4714z1pRI6YZ57oWnMlXi26A6F7y0CJnbeJODgmsPqe3HfFa97wceMNXV4XQpk4X3Ojnqsq8LriW2oxwvZ/TcvhHjAHfsgfuZwuD86d+O+9RjG6iskoJ8Tq0GcfqRsqSP9f2pKFA5m11s/Xq/fXjYCYjb0Uk0PvAn0JobPS2Mxu8fagm3kHY/HsawMr7CmdNwXnQs3XvkLejiMFdxvgvvqZ2U4rEdw/rqidIh3pGOfjrQQa6tw5fXZ7BpUitO37sQ+os9i17gcHK+cC8Pt4vc13ygobzQEQRAEQRAEQYg78qAhCIIgCIIgCELckQcNQRAEQRAEQRDiTqt5NPS1qPXKtWLdjFWF3SDOt4braKSnVMO0NCvqxMrqUL+nS8EaCv4APj+V1KHGbr8lGWKHoR5is7nxfPZERHo76jDtZowjPRk81nZkuf5ZnYwaZm7ZW416v4S9Z45Jw/od6qVt21BFqkojcppnoU6xy0I8Dn47HkfWBKThekINzqCvZzpfVhfDk4TaRmMVbt/nQJ0m93AY3fhFXWp4fVoz+pVS3vgG9yUF+6uqZ/2NhIYY4dwec3plAMcRXm+HE2BJ9A2skblHw8f03Hx5VwDFuRoXjnMwTepoHBeJOzB+r2IgxBvLUWM/IetniOt/TmzR9lJ/wnFh66Wo/95Xg+eyiZnugqtwutA0Pite7/328MmhTUKtfpIDr7/Ly8+CeELyjxB3MaJe38hG22Qd3iskJOD6+1sLID6LeTRcQR2L8Tr2v6XoRThcG675UNUdx5/P/90f9622bfm6NOt+Io3m6HUx6+tTuCMvYpjQ8FztHr+KfZ8cibzREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDut5tFI/RG1ikUeJ8TTc1GEN/u5K0OfeR2BvSmoT7aUovaQSZ3JlY/TLxn7C8TcHxII4vPWuBzUdu+oRn+AVY+6z59W4/rKtWkQ+51hXaexHLe1yHkOxPfl/xviAhd6NDRLNkPctlSYSKAUfTvE4wjqR/SMuS5dPa88gPgchpjTeR0NbwKeGlo2nXsy/ObYz+xeO64P5Pw9u+DMm7G/BsrKSfgPLTAn/OhG/f0IB57XhX5U33Y0VkCcayiBOEWHHopKHXrD6lXsPlboS4TYqvU0PGMDSB2N4yNxHvqdfp6H042EdQo+Z9UGcgmXbwrLh99BvO8Tdt77D0G8gf2tL5PWtmh7ApGe+en6nb039HlfVRJMKz+M5/zBy3BMeJ1wLA4Ovxrimk7ooaxLwfZL/Qn9nv/d+1bcWXaZMNTgeZ2yGeuoBNm1wKw/GPqc9yn+7kEpBRCv3ngBCcLpgLzREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDut5tHQrP0B4i0vDYZ41ZA+EPeYtyn0OViPOseWksZiroN10u6Yy2+N+uYwRC42NZdK6XjRpeHePvHqBIi161BTmu07SO0FjSGcU5x7MPR1GPst6JnQu5nRh0nctT5cPmhgy7P1a9j8dVloDLIWoW/HxzwZpircAUNduE9qK7BHRbkQtLhvFIztRzmjUc33KnxTmgdxrhnP0yPeRIi3V2dA/JH/bIhTzOjRqPejJ0OrwZbzs7oaXey4/VQDejyiPEvCCcNr1JzotUVrs0GsvJhLXvlwHFD+2HWPNHocJzRGrKMQdKPXUYiG+2LK78oNffb68fh2n7G+RevWfrUJYiebzmNO+hct2lyTNZEi+1PBEfRvHqnEvem0YF3LNi4IrYS80RAEQRAEQRAEIe7Ig4YgCIIgCIIgCHGnWdIp9R+5gp98x51PNeDFV9bBOlyRX4VfOQdbUNq8raOC+Ko94MaUl8qDx60lZd/9dHRe1QK5SXOJR59oCo0KpzX2+5nkwc+kU34mL+KSBS6dCjDplIYtr8WUyhq+PR9O17Lt+X0sPa6f9Xdf+BnfH8Q2j2pjntJVHb90qq33iZbgr8XjWleDbeSpx+Psq8Vz0c/azBdg8jg2vSnplJdwe/UGjCPbXSnef+PXBzhncp/QKvxb2oleW7SKSaNYO6kWrl/DjrmGHaNTdS1srT5xMvpD5HkfcLM05GfQvUXQjdfEgGp8PDlRzuQxQjg+WtInNKoZcx08eJA6derU1GzCacqBAweoY8eOcV2n9Im2jfQJgSN9QuDEu09If2jbyBghcJrTJ5r1oBEMBunw4cPkcDhIo9E0NbtwmqCUIpfLRdnZ2aTVxlclJ32ibSJ9QuBInxA4rdUnpD+0TWSMEDgt6RPNetAQBEEQBEEQBEFoCWIGFwRBEARBEAQh7siDhiAIgiAIxLtN7wAAmaZJREFUgiAIcaddPGhoNBqaNWtWk/PNnTuXNBoNFRQUtP5OCYIgCIIgCMIZTJt/0Pjpp59o8uTJlJOTQ2azmTp06EAXXnghvfTSS62+7SeffJI+/PDDVt+OcHzs3r2bZsyYQV26dCGz2UxOp5OGDh1KL774ItXV1bXKNt9++2164YUXWmXdQvM49geDY//MZjNlZ2fT+PHj6W9/+xu5XK6mVyK0GSLbOta/L7744lTvqtAGkOuG0BD8uqLRaCg9PZ1Gjx5Ny5YtO9W7d1rTps3ga9eupdGjR1Pnzp1p6tSplJmZSQcOHKB169bR7t27adeuXUR09EI0c+ZMevnll2OuLxAIkM/nI5PJ1KzsB3a7nSZPnkxz586Nx88R4siSJUvommuuIZPJRDfffDP17duXvF4vrVmzhj744AOaNm0avf7663Hf7qRJk+jnn3+Wt2KnkLlz59Itt9xCf/zjHykvL498Ph8VFhbSF198QStWrKDOnTvTRx99RGefffap3lUhDrz11lsQ/+tf/6IVK1bQvHnz4PsLL7yQMjIyTuauCW0MuW4IjcGvK0opKioqorlz59KWLVvo448/pkmTJp3q3TwtaVbBvtOVP//5z5SQkEDr16+nxMREmFZcXNzi9el0OtLpdDHnUUpRfX09WSyWFq9fODns3buXrr/+esrJyaGVK1dSVlZWaNrMmTNp165dtGTJklO4h8LJ4JJLLqHzzjsvFP/2t7+llStX0qRJk+iyyy6jrVu3Nnoe19bWks1mO1m7KpwAN954I8Tr1q2jFStWRH3PcbvdZLVaW3PXWgXpm62DXDeE5sCvK7fddhtlZGTQ//3f/8mDRiO0aenU7t27qU+fPlEPGURE6enpUd99+OGH1LdvXzKZTNSnTx/69NNPYXpDHo3c3FyaNGkSLV++nM477zyyWCz02muvkUajodraWnrzzTdDr9GmTZsW518oHA/PPPMM1dTU0BtvvAEXi2N07dqV7r33XiIi8vv99MQTT1B+fj6ZTCbKzc2l3/3ud+TxYFXpxYsX08SJEyk7O5tMJhPl5+fTE088QYGICuOjRo2iJUuW0L59+0J9Ijc3t1V/q9AyxowZQ4888gjt27cv9JfwadOmkd1up927d9OECRPI4XDQDTfcQERHc7y/8MIL1KdPHzKbzZSRkUEzZsygiooKWO/3339P48ePp9TUVLJYLJSXl0e33norzPPOO+/QgAEDyOFwkNPppLPOOotefPHFk/PD2zmjRo2ivn370oYNG2jEiBFktVrpd7/7HREd/aPUsZsFs9lM55xzDr355puw/BdffNGg/KqgoIA0Gg281S4sLKRbbrmFOnbsSCaTibKysujyyy+P+mv1smXLaPjw4WSz2cjhcNDEiRNpy5YtME+svinEF7luCMdDYmIiWSwW0uvDf7d/9tln6YILLqCUlBSyWCw0YMAAev/996OWrauro3vuuYdSU1PJ4XDQZZddRocOHSKNRkOPPfbYSfwVrUubfqORk5ND33zzDf3888/Ut2/fmPOuWbOGFi5cSHfddRc5HA7629/+RldffTXt37+fUlJSYi67fft2mjJlCs2YMYNuv/126tGjB82bN4+mT59O559/Pt1xxx1ERJSfnx+33yYcPx9//DF16dKFLrjggibnnT59Or355ps0efJkeuCBB+jbb7+lp556irZu3UqLFi0KzTd37lyy2+10//33k91up5UrV9If/vAHqq6upr/85S9ERPT73/+eqqqq6ODBg/T8888T0VF5nXB6cdNNN9Hvfvc7+uyzz+j2228noqM3DuPHj6dhw4bRs88+G/pL94wZM0KvzO+55x7au3cvvfzyy7Rp0yb6+uuvyWAwUHFxMV100UWUlpZGDz/8MCUmJlJBQQEtXLgwtM0VK1bQlClTaOzYsfT0008TEdHWrVvp66+/Dt28CK1LWVkZXXLJJXT99dfTjTfeSBkZGVRXV0ejRo2iXbt20axZsygvL4/ee+89mjZtGlVWVh5X21x99dW0ZcsWuvvuuyk3N5eKi4tpxYoVtH///tAN5Lx582jq1Kk0fvx4evrpp8ntdtPs2bNp2LBhtGnTJrjRbKxvCvFFrhtCc6iqqqLS0lJSSlFxcTG99NJLVFNTA29QX3zxRbrsssvohhtuIK/XS++88w5dc8019Mknn9DEiRND802bNo0WLFhAN910Ew0ePJhWr14N088YVBvms88+UzqdTul0OjVkyBD10EMPqeXLlyuv1wvzEZEyGo1q165doe9++OEHRUTqpZdeCn03Z84cRURq7969oe9ycnIUEalPP/00avs2m01NnTo17r9LOH6qqqoUEanLL7+8yXk3b96siEhNnz4dvn/wwQcVEamVK1eGvnO73VHLz5gxQ1mtVlVfXx/6buLEiSonJ+e49184cY6dx+vXr290noSEBNW/f3+llFJTp05VRKQefvhhmOerr75SRKTmz58P33/66afw/aJFi5rc3r333qucTqfy+/3H+7OEZjJz5kzFL20jR45URKReffVV+P6FF15QRKTeeuut0Hder1cNGTJE2e12VV1drZRSatWqVYqI1KpVq2D5vXv3KiJSc+bMUUopVVFRoYhI/eUvf2l0/1wul0pMTFS33347fF9YWKgSEhLg+8b6phBf5LohNMWx6wr/ZzKZ1Ny5c2Fe3u5er1f17dtXjRkzJvTdhg0bFBGp++67D+adNm2aIiL16KOPttpvOdm0aenUhRdeSN988w1ddtll9MMPP9AzzzxD48ePpw4dOtBHH30E844bNw7eOJx99tnkdDppz549TW4nLy+Pxo8fH/f9F+JPdXU1ERE5HI4m5126dCkREd1///3w/QMPPEBEBHrcSC2/y+Wi0tJSGj58OLndbtq2bdsJ77dwcrHb7VHZp+68806I33vvPUpISKALL7yQSktLQ/8GDBhAdrudVq1aRUQUkm5+8skn5PP5GtxeYmIi1dbW0ooVK+L/Y4RmYTKZ6JZbboHvli5dSpmZmTRlypTQdwaDge655x6qqamh1atXt2gbFouFjEYjffHFF1HyumOsWLGCKisracqUKdCvdDodDRo0KNSvIuF9U4gvct0Qmsvf//53WrFiBa1YsYLeeustGj16NE2fPh3eYEe2e0VFBVVVVdHw4cNp48aNoe+PSffvuusuWP/dd9/dyr/g5NOmHzSIiAYOHEgLFy6kiooK+u677+i3v/0tuVwumjx5Mv3yyy+h+Tp37hy1bFJSUqMXg0jy8vLius9C6+F0OomImpXCdN++faTVaqlr167wfWZmJiUmJtK+fftC323ZsoWuvPJKSkhIIKfTSWlpaaFXpVVVVXH8BcLJoKamBm4q9Ho9dezYEebZuXMnVVVVUXp6OqWlpcG/mpqaUMKJkSNH0tVXX02PP/44paam0uWXX05z5swBvfZdd91F3bt3p0suuYQ6duxIt956a5RHTGhdOnToQEajEb7bt28fdevWjbRavBT26tUrNL0lmEwmevrpp2nZsmWUkZFBI0aMoGeeeYYKCwtD8+zcuZOIjvqFeL/67LPPohKZNNQ3hfgi1w2huZx//vk0btw4GjduHN1www20ZMkS6t27N82aNYu8Xi8RHf2j0+DBg8lsNlNycjKlpaXR7Nmzoc2P9SN+f8n71ZlAm/ZoRGI0GmngwIE0cOBA6t69O91yyy303nvv0aOPPkpE1Gg2KdWM7L6SYart4HQ6KTs7m37++edmL9NUKuPKykoaOXIkOZ1O+uMf/0j5+flkNptp48aN9Jvf/IaCweCJ7rZwEjl48CBVVVXBgG4ymaJuNoPBIKWnp9P8+fMbXE9aWhoRHe0/77//Pq1bt44+/vhjWr58Od16663017/+ldatW0d2u53S09Np8+bNtHz5clq2bBktW7aM5syZQzfffHOU8VhoHU5kHG9sjIg09R7jvvvuo0svvZQ+/PBDWr58OT3yyCP01FNP0cqVK6l///6h8WLevHmUmZkZtXykqZSo4b4pxBe5bgjHi1arpdGjR9OLL75IO3fupPLycrrssstoxIgR9Morr1BWVhYZDAaaM2cOvf3226d6d08JZ8yDRiTHUo8dOXKkVbfTnFobwsln0qRJ9Prrr9M333xDQ4YMaXS+nJwcCgaDtHPnztBfMImIioqKqLKyknJycojoaMaZsrIyWrhwIY0YMSI03969e6PWKX3i9OdYfYWm5JD5+fn0+eef09ChQ5t1kzp48GAaPHgw/fnPf6a3336bbrjhBnrnnXdo+vTpRHT0jyGXXnopXXrppRQMBumuu+6i1157jR555JEz8q9YbYGcnBz68ccfKRgMws38MVnLsTEgKSmJiI7ePEbS2BuP/Px8euCBB+iBBx6gnTt3Ur9+/eivf/0rvfXWWyEJb3p6Oo0bNy7eP0k4TuS6IRwvfr+fiI6+Kf/ggw/IbDbT8uXLyWQyheaZM2cOLHOsH+3du5e6desW+v5Y/bcziTb9Z5JVq1Y1+EbimIayR48erbp9m80WdeERTj0PPfQQ2Ww2mj59OhUVFUVN3717N7344os0YcIEIqKoiqzPPfccEVEo+8Oxt2GRfc3r9dIrr7wStW6bzSavxE9jVq5cSU888QTl5eU1mSb02muvpUAgQE888UTUNL/fHzr3Kyoqosahfv36ERGF5FNlZWUwXavVhgoG8pSYwsljwoQJVFhYSO+++27oO7/fTy+99BLZ7XYaOXIkER29KdDpdPTll1/C8nwMcLvdVF9fD9/l5+eTw+EItfP48ePJ6XTSk08+2aCnp6SkJC6/TWgZct0Qjgefz0efffYZGY1G6tWrF+l0OtJoNPC2s6CggD788ENY7tgfunh/eOmll1p9n082bfqNxt13301ut5uuvPJK6tmzJ3m9Xlq7di29++67lJubG2X8izcDBgygzz//nJ577jnKzs6mvLw8GjRoUKtuU2ia/Px8evvtt+m6666jXr16QYXXtWvXhtJX3nvvvTR16lR6/fXXQ6+5v/vuO3rzzTfpiiuuoNGjRxMR0QUXXEBJSUk0depUuueee0ij0dC8efMafMgdMGAAvfvuu3T//ffTwIEDyW6306WXXnqyD4FAR+sUbNu2jfx+PxUVFdHKlStpxYoVlJOTQx999BGZzeaYy48cOZJmzJhBTz31FG3evJkuuugiMhgMtHPnTnrvvffoxRdfpMmTJ9Obb75Jr7zyCl155ZWUn59PLpeL/vGPf5DT6QzdlEyfPp3Ky8tpzJgx1LFjR9q3bx+99NJL1K9fP/irqHByueOOO+i1116jadOm0YYNGyg3N5fef/99+vrrr+mFF14I+XgSEhLommuuoZdeeok0Gg3l5+fTJ598EuWn2LFjB40dO5auvfZa6t27N+n1elq0aBEVFRXR9ddfT0RHZTqzZ8+mm266ic4991y6/vrrKS0tjfbv309LliyhoUOH0ssvv3zSj0V7R64bQnM4dl0hOlqD5+2336adO3fSww8/TE6nkyZOnEjPPfccXXzxxfSrX/2KiouL6e9//zt17dqVfvzxx9B6BgwYQFdffTW98MILVFZWFkpvu2PHDiI6w95yncKMVyfMsmXL1K233qp69uyp7Ha7MhqNqmvXruruu+9WRUVFofmISM2cOTNq+ZycHEhP21h624kTJza4/W3btqkRI0Yoi8WiiEhS3Z5m7NixQ91+++0qNzdXGY1G5XA41NChQ9VLL70USi3o8/nU448/rvLy8pTBYFCdOnVSv/3tbyH1oFJKff3112rw4MHKYrGo7OzsUCplYikva2pq1K9+9SuVmJioiEhSFp4CeBpCo9GoMjMz1YUXXqhefPHFUMrSY0ydOlXZbLZG1/f666+rAQMGKIvFohwOhzrrrLPUQw89pA4fPqyUUmrjxo1qypQpqnPnzspkMqn09HQ1adIk9f3334fW8f7776uLLrpIpaenK6PRqDp37qxmzJihjhw50joHoR3TWHrbPn36NDh/UVGRuuWWW1RqaqoyGo3qrLPOCqWrjaSkpERdffXVymq1qqSkJDVjxgz1888/Q3rb0tJSNXPmTNWzZ09ls9lUQkKCGjRokFqwYEHU+latWqXGjx+vEhISlNlsVvn5+WratGnQb5rqm0L8keuG0BANpbc1m82qX79+avbs2SoYDIbmfeONN1S3bt2UyWRSPXv2VHPmzFGPPvpo1LhUW1urZs6cqZKTk5XdbldXXHGF2r59uyIi9T//8z8n+ye2GhqlmuGGFgRBEARBEASh1di8eTP179+f3nrrrSblvW2FNu3REARBEARBEIS2Rl1dXdR3L7zwAmm1Wkgg0NZplkcjGAzS4cOHyeFwnFm6sTMcpRS5XC7Kzs6Oe3pE6RNtE+kTAkf6hMBprT4h/aFtImNE63DM/zdixAjS6XS0YsUK+vzzz2natGmUkJAQKiR5OtKSPtEs6dTBgwepU6dOcdtB4eRy4MCBuBd8kj7RtpE+IXCkTwicePcJ6Q9tGxkjBE5z+kSz3mgcy7wxjCaQngwnvmdxpuQOzPRUd0ENxNnJmDbOrPdD3MmK1cG3V6VDXLghC+LOf/zuuPbzZOMnH62hpVABOV6c7n2Co0tJhjhQVn5C6/OP7AexfvXmE1rfyeJM7hOei86F+MhQHN4enLQY4uffuwLi9I2YatRUgWlnfU6sKl3dGX+j4wqs23N/zme4/cVTIe7ybiXEwV920KngtOsT/K+acbQRuq4eCLH2BkwlOzi9AOKvCvMhTjK72a7hvup1WITtqowNEC84jNuvfwWvLeZlOP+porX6xKkeI9o82ojCw0FWLLIVz5vTbow4jfCMx+uOoRbvLzVeHBO8CXgdsazdBnGwFseY05WW9IlmPWgce52lJwPpNadfR9AZMU2l1ooNrbdhXnODHl/zGG3Y8Hq/CWItS4N5Oh6DBvnPONMaryNP9z7B0WmxjTUnus966ROcU90nAgY2DphxeLPYMdaZWBsadBjr8RgpPfYhnRF/o96G44bNgeuLGkd0OH/wVPWh061PRO1H/G6Y9LyPsDYz2XEfdVacrrfgzR1/0DDocDrvc7yP8P05bcaRVuoTp3qMaPNoIsYUDZOrtOJ5c9qNEacR/LqjZ3/I1rAK8EEDu9/UYBzURNfWOS1pQZ8QM7ggCIIgCIIgCHHn9CnYF+uVIOOFgrUQdzXg6+ZdPpQ8rHRjhfBcI74uL/CmQXx9yjqIu/VAKZb5Znw+u77TBTH3F/7SINmEW4Udr6Ek4cHhn0Js0x6G2KDBPvbM1osgvirvB4hvSUK53GE/9rllrrMhXvzGSIgz/oZ9Vmge+qxMiKsuyAl9PjKcvXFI9kKsO4zD2xPrJ0K8YwYWRdP914n93eXaPWMhfvjZ6bh/3fDc33afHWLTofA40mkFvj7Xrtl8QvvWpmjhGKnrEx7fgy/hWP1Mlw8g7qTD8/AXH/41ko8LT2dsbtG+cDZ4sE8+0WURxOe/hn/B3fw3vHY9V3hh6HPpdJRZBbZsP6F9O2OJcb3V2mwQl16L43b5GFQ/DMnfC/F+VxLEPRKxYGNdANuTz5/MpHc/bcyDOP89zEKkWYvXoch7I40exzflx7+kC63DZb+UQXy5/XmIV7pzIfYpbKcOBpTqF/tRejS/ZxMeGC2+KScV8cbkNL2/lDcagiAIgiAIgiDEHXnQEARBEARBEAQh7siDhiAIgiAIgiAIcef08WjE8GVo+/WG2KhZA/Gjxf0h7mlBPf731bkQfxPElIUmLWobK/yo41zss0J8VdL3EO945XyIu9/F0t9G6ua4vq4JP4rQMDtfHAzxjkl/h3iZG3WPOg1mfkjR1kL83FkLIDazzA97fE6I9/swXe4Q2y6I738I+8il+++F2PJh20iRHG80LOOG8qGGvey2IRDPe+SvEH9QHU4luKYUz+NDVQkQB7riuuuqUI/f68tbIO6SUQqxJxB7eCw4mAqxtoJlLBqFfUzLMhQ5rKjHP6tPeNwad90vMO39ovNw336NvjL67qeY+9qWaKqPBIfjeD/zn++GPruCFpg2vwLHCU8Q29TFPBr5VvTvvVyYAXGeFfXZ60pRYz+lA57X5X704Xxe0hPisxLxWpVlrIT4urTw+mwf4XF47J7bIDYtWQ9xa6Y7PZ3QmDCTl/KEzyt9Xg5Mu27Z1xCn63GcfmIX+rhGJGHKaV8iXr+3u9FDlmhAD8boJExdWuTDMaqoJ/aPobO3QvxhAXpI0i8Pry/Kk9FO2rtBWvDbefa/YH19I3MeZe+TeE3KN/4T4tV12MecOlxfdQC3V6/wOmHT4nndbxNufzMOdzHvGaPOBS+u+1T1CXmjIQiCIAiCIAhC3JEHDUEQBEEQBEEQ4o48aAiCIAiCIAiCEHdOnkejJRq6vqhjLX4CtYg7fSkQj3VugdihRY1cZmoVxIk61FFm61Ar/UkN1t2wMg3d5nrU5N0+bDXEc/9nDMR5D38TDri+Tjwbx8X1IzAf/lYfeircQVbdnXk0XAFLzOn1Qaa312B/5TrMQj9qb7d6sY/l/oZpdT+kdgnX23Oqu2I84dP7IO4UUR4lYMS/k9hQ2k+KjTlONuYY3HjuuYMdYu4bL7TbgVUO99nYGLcZvV7MokF6D/bBw4VhL9gLvfrANM0E9Ab4h6AHKfMMsvw01UeSntoPcaY+PL7/7OoE04LsoCfp8bzkHo1zrPsgnuTEOgYFzJtVk4jjTDdjIa5fj218JAHHiV7MT1gZQD9gZI2nniacd+AT6C/4cQkhZ6pGn53XkZ4Mzp6b8JzmXqeff8JrubYOx5T0/OqYu/KtDz0645LQW3WzE31f/12M3qrC/dif/lU2COKJPX+GeFe3LqHPgZ17cGfO1PZuDvy3x7ivasqTsf+9syC+uccqiL904f3h+XZshz2edIzrsM3HJeL96meVONYPde6E2LUeL4o/PXUOxNaF34Y+xzoXiOiU+XjkjYYgCIIgCIIgCHFHHjQEQRAEQRAEQYg78qAhCIIgCIIgCELcOXkejSa0YPsWhHVxL5yLNQ2+d+fFjIfYmKYtiLpbmxZ1a5+5UIM3JQG1rrlG1FWm6VwQH/CjrvKQJwniP175DsSvDRgR+my8EDXA4tk4PiYmbI453axFz4aW0IMR1DTxjM0mB5WWTcb1cQoDqMV+ozPqPCfRgNjbbyfUXY41aD751bMQj195D8SB/6oIfbYasI0TjHUxt+UP4rnFfTl+xc49hpaZNPTa2OdmfQB9PhlmVyNzHsWiC/+eJT/3xW1tQV9a1oQjuPCLMVfdptHndoZ4RhaaESLHcxfLWV/tx5jX0Ug2Yq2T90sHQvxE9jKIF9Ri7ZZ0I7apjdXfqddgH/i+DH/LNUloruHXpkiv2H4P9oF+NvSqbOkxGuLAdqztc8bQxL3E3v8J1z3wJaK/86etePxJh+sylaOG/Y9bsa7Gv/vPgTgxHWt6dTGgp6M4gOtbtGA4xNpUdh2pwzHok3Xn4vTfh39P4rdY3yFt9jfUbuHegxj3TcUzL4C4wzV7IR5sLoD4qxL0SIzLwFon3Fc1xobT/ysR/Zmr6rEmV6IBr1tVAfT2JTJf2SWPfQHx2zeGfUdJb2Fdlkj/BhFJHQ1BEARBEARBEM4c5EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnZPn0WC4r8J80Q+fvSj0+V9FqKEz6VBnWevHhPmHPYkQV3oxd3mQUL+XYy2H+O4910LcyVYB8dhEzI3Nayzsr0PPxsYKzOV+Y8ewTu6pZ6+AafkProNYPBnNY6gZn5G/rsc+EeCeCqbH9zI9Pvdg8On1yhhzOtdp8louBg3Or+vVLbyvW9Fj1J6w78Bzbfzn90Ks0WO7ZVjDmvhNOzAHvvkgtpG2iZTiURYLJpdmpVNIw205LFZNjKYH2Pa8iRjXdwrXj7jkbMyfn3Euar9XHMFaQ2cyW+/PgniEGetslPiLQp93eTJg2gAb6q/XurpBfKQevVQG1imW16I++yLnTxC/fHgsxA8mb4d4bjXm0B+Rjr6JbR78bQYNbr8iYlzRsg6ZayiBePt/pULc9f+doR4Nhq53d4h9KeH7BUsBXqs9acyr58B7C9MQrFdTuRf9l6t7YY2EK2w1uG2F9x6/LsT7HE8f1OP373wA4k0bsL8Zy/C6YdkajquG4rqyPsaaIf6Dh6jd0IT3YM/b/UKfx3TdhNNceN5sLsLjaDai78rHfF6ba9H3w8/hWoXnaWRtHKLoOm3fVqEHmd/P+gLYJ/plhtu552NYx+eNcSMg7n7XqSm4JG80BEEQBEEQBEGIO/KgIQiCIAiCIAhC3JEHDUEQBEEQBEEQ4s4p82iUTsHcwK5AWIeW2EQ+/IBCz0W5F/Xx/iA+P7m8mEs9Ml89EZEngIfByzR4v/t4CsTaDrjvw3P3QJxswum/uLNDn53dUZMuNA+NyRRzuo8J5HVMUO8O4vJcR+lWqOXldTJ0LDay5fn6EnWYn59zZHRYp5nejj0aBy5FvWqPPKwzc2gp+jC2bwtr7PUJqMv1d8fzLuDnxVBYrnVuwmAoNr9Gq2JOp3pWh4PNr3fguMMxFITHwHVv9Idpzv2oJT98Pfa37gP64L5t2BJzW22Ji4f8APGPXvztZYFw7vhfXOh5GGfH43BtFtZMeqMqE+LlZXgcf6hFv91ZZtTUj0vBnPk6Vp/noBf9e+fbduP63di/3UH0GXki/IBDnOi54D61Xv3x3Ind284cii/A+iLG4vBnPbuVMO3EY1bbEcd9fwpON1bhOf5+yXkQd9J/BvEhfyLEP5Sj3l+3F+9FStNY3YODsf/2648osaDbj+squhi9Ain/2448Goydb2L9kZv6hH2yS/6GvoXaTtjGAy5CT+7mQmzD9wv6QZxuR59Ob+thiAtZnyj1OSBO1uO9QmcLeohL63EM8jM/aUlduA99fxDrAHXtgfWWym/F2ivJ/zw5tVfkjYYgCIIgCIIgCHFHHjQEQRAEQRAEQYg7p0w6ZTCgFMAakYuyq6UYpn185CyII1NcNgeTHrfFpVM8pSGXZjm6VuL62L4PSkDp1H4PvsqtC4Rfzw7M3A/TChreZYGh7ZrLvvkWoqh0tCwFcYA9UxsI29ysiS00CLLla5kUK0WHr0+j14fL12WQQES1nZkEyInn/pCbMD1pTSB83Bdu6QfT7N+hhDIqHS1PV8vjQGwpFSeox3EiwNV9TFmld2Of9KFqgnpO2hH6fEkqprddXNwP4h/zP4T44sWYFti2IXp/2yppRhzvCwNOiCPlTFUO7AP/KB4J8f5kTE97uR2lTCl6PI/fKhwM8eeuvhD/LhXT2foU9ue+loMQv1k4FOLxKSjt2utBKWFkWu5+JlzXZ248DpMzsdH/j7KpPeBJZCdaRKpTnnK6qeTxdTsSIU5mGYJ/OdwL4hvGoKzFU4FypuSNuAMJmPWc9qViulwHG7P82J1RCsZ+tjsTv8C7kDMcDf72fnkocVxTkh/6nLgb855X9ka5ok2P03VabBSnGafXeHHg97B7j11+vNgf9mBK7ff39IO4V1oRxDytNb9fNUeUf7CY8L5j9xYcA+68H6V+n/8TZVythbzREARBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDunzKORm4RpXn0RGvthNtS9rjHlQ1zjQ02cmXkueHpaLRNn61kqUq6B4+s/PwvTBlb5sCR8QT2WsL87ZS3Eb1SGU+KlM73xvv7nQ6w2nTlpKeNJ6XnJMadzD0U9S1fL08/6mKfDocM8iAGWQs4bYB4Qtv5OhjKI7/vleojXn7sA15fHxLrtFGM5HuePN58Dsc6KfqhAffjcNh7BNtCPLYU40RL7GDelfeXwcUbPtLtVHhwXuDeML79xP+q7dy7sHvrsvwL7264SHGMGld4GsdPEBNtnEENsu2JOL/SHNc/8vM6zYp9YU90d4h/dmBL0tiRM99it08cQP1t4EcRf1uO1KlOHfS5TXwnxf3dcAvHZRtT0u4Po4XupIpxu18fGpE11uRCfY8FlqZ14NLiPIRJ2yEjvjT2d2TOpNouluGYeikABGq2MzJrns+PyXpTnE5lwzFE6vHdhly3YP3abQ/UZTTlQzlw8F2Pa4cEJeA+29ED4PHL+N44JExIxBayHHVjumQiyTtLJgveyPEU1j/1BHKM6JFRBzK9LXR0lEJd7bRDXR5RnGJJdANM+r8Px7odqvOZozTheBetb575E3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnVPm0ehorWx0WqIWhZSDkgog3sR0Zm4/auCMWtRGc7jGzcqEm1Haa+bJ4NtLN1ZDnKrD+SN1w1mGSphWm4saT+umRna6nVPVNfb0bD3qHCsDMYS7FO2xSCbMn6/jRRYYXEeZqXNDXPsNaurpXLa8nhd5aJ+cN24rxFvLMK98qhWPa2RO83tG/Bum/fqnqyHeswfzl2s8+HcVrVcTM+Z6bK6XjhJ0MwJm7CMBG65w7ECsleHJC48TyUb83T9sycGVG3Fd3nNwX5xvx9y1NsXFVsxb/6m78Ro2CXo8bqU+zBPPz9tkfS3EXzHfwwAz5uP/Q9YyiPf4UXS/04fVCw54MS7y4fzLtCjqzzNhHZkbEsIXhF0+rJuRZUBtOD9Oz1P7IGjCNvVbwzE/B03leJ74HXhS62pRPx81BnCPRgYec38d3lIZqpnngl9W2BjCfRc65ilxZ4V3IGDFndFY269HoyoPr+fphupG5iSa2hH9G1UBvB8s9eM9Wa0fx5tzE9ALtd2N15lD1YkQj0pCH9emSrx/dRrRF9HfiWPOEWbs6WwphziyRtjuGrzv6JuN/pMhiVg3aOFQ9Jzp/906BZjkjYYgCIIgCIIgCHFHHjQEQRAEQRAEQYg78qAhCIIgCIIgCELcOWUejdtSv4R4rbtb6HNiE48/eiaUdBpQ42bTo24yyJJl+1ncVP58C8t/z+tyeIKoDwwS7h+fP5KyvqgJtS6KuSvtFm8HX8zpG+sxH75Di32CezLqWZu5guirCRBqZ91B1GlyrTef329vmcejvfLNnjyIdXo8FzcMwPoj/f98V+jzo65bYVrtODzvtUxvHXSwmhysjYI6VlfDhPMbTdgHrcbYdTU8fhxeS4tQY3+gNhFiNeZQ6PO5Wyph2v0jl0P8dSXWFjpcwxP0nzmsq8c+kaxDP1Xk+J7IvFKHPEkQZxnRy7XZ1RHiYYlYs+NfFUMgviN5DcQ/1aPe+gcXxjYmsu9kRn0191m8fWQwxOkdV4Q+8zHNyWp21ATbZ20en4NdbyO8VtqO2B/8B1F/zz0ZpgocxwNY5oSMlRirQOybFWbBIT9eZkhXxu4d8DJDit2haQIR+8fGK3Kdstu5U049WvvIocW6WHmJ4TpX7xzB2mVb92C9mf7dsG5aign70LpKvGblWPGcTjTgtmfvGAHx1K7fQsw9HrwW0ED7Xoi/rMLaGJ9v7xn6fN+5K2Gai3XgKlZ0RulOTv0leaMhCIIgCIIgCELckQcNQRAEQRAEQRDijjxoCIIgCIIgCIIQd06aqE+flQlxJz2KF93BcG2KJC3qykxM6JhlRp1tqgE1u3vqMJdwshFzpRtYQvwgy2VtYnU4dMwTYtOhFtzOtLIBxbTfEfr9AHu20/TD3yI0THJa43mxiYienTMZ4j9N/xfEZsI+5CLsY7VBrI3C62j4uFiWyWMr2fJ+W+w6GTaW8769oHVgXQObHc8dVzFqqD2KnfvvbAt9dp+PPoXtY/8B8auVXSAu92O+9PUVWJuiuBa3XVWDguraGuwzdVoUVHMPR8dEPLddDpx/RCr6AVZTeHv/eGsCTLMNK8Ftf5EGMZPeUmdCXW9bQt8BNdNmDWqaC/xYm+KXug6hzw42Fiexuhrj7Vi7ZLITCxf9tXgcxAPsBRAfCmAfWcf6WFcbthOv67GPXZsyDNhHzOy62CWiHsDaOvR/8GuJnV032wvKjtdzbWGE74Fd27lHwljNaucwuyYb1knxP81yq11T3ju2PK/rweT5UbGlODy/K4VtyxG7ftiZTH0OXk8zWV2tPo5wPYkNlejnzMxGn9Sm3czvmcTGkM7bIOb3j9wHdkXejxBvrMb1u/3o09lVjWP7ASf6zApcOP6N6xHen+1uvM8+z4HXAe5NrcnCGLcUP+SNhiAIgiAIgiAIcUceNARBEARBEARBiDvyoCEIgiAIgiAIQtw5aR4Nb/csiE0afMYJRIkfw/D84bUB1DrXBYwsRt0Zxx9E4SOvadBUXQ0fW57J/cmtYtfdiOSczMMQlzUyX3vHoIvteei0DHNZ19+KfSBNjx6PEj96BbgHw8eaTMt8OtznY9OgPtZ6CPtIQOHyCZb2mfPeM6QHxJ8PeBHixwrHQmzSYDsGysLtbF6J3que786EOOUH1M767EyPHcRG5jnF9dhFiHjdDTZ6erQoAN/rx7oZXG/9lnYgxJ0o7B9I3o7966U73oL4yQT0cLzYeTHE0//3Woj9h3CcOZ3xdEOdcT8TjveFARxfR9q3hj5H1mMiivZAzC4ZBfEtqVgX45UO6yCuCKA+u5BdGvo7D0B8yJMIcZEH+0CGCcchriWflvE1xJURnayM+UM6GWJfLXRpqPUOlJQ0MmfbQmtDr5XZgfr8QIRHIxjE+wp+aY8qg8HLCrDLTpQFI8gW4CGbn48ZuiZsFcwOSp7k8Ao19TigWLLQq9qe0OqZj1aLB84TceC72YthWq4Nj2OxEz0bNT4cf3a6sGhHigmvQ9w71dmE9ybck+FnFwZ+/7m9Euts5DtLIc6JqM1zkNUN0rIOPMG+HeKXM7HDikdDEARBEARBEIQ2gzxoCIIgCIIgCIIQd+RBQxAEQRAEQRCEuHPSPBq1WahzcwVRh+aL0KkZNEzfTtzPEVsXaWIaNwPT1+t0sXNd8/WnGFCDV82ScW+txbzvRdYdEGcZK0Ofec5lt58l6hYaRKeN7dHQ1Hkh7mYsgviQPzHm8vUKdZM6pm3ksYflo05jHhJuOQoyn47VEN7f2I6gMwt9LYqSL/hyFk434PQf075odF0aI5472677O8SvX5wbc194G3ICbGBxM29YkE1P1aNGmi/fyYBaXc7rFK7J4FxbANO+q8+DeGcZ6u+nea7HlXVgats25NGo7GaKOZ2fqxebw3rsJVWo30/W4dh9J+tPu314HInQQ5Gks7IY5+6VsjPmvh70Y59YWtsdYu676Gk8AnGk98vHtNxGXvSBEchDrwudKR6NZOzbRjZm1EV81unxGHmdOA7rPHiOBlj7Bk2xfVxRGPA6wO2cSs98XsbY9zLMRkY+Z3j9im3LYUFfgtaM5tFg/ZnrC+yciWMr91BG1kbj92+cwzUJEEfdD1rQt+Uw4HHlddh21XFPBy5f4cX94feI9X68TXf5cXz8PqIuSJ4NfVs2Ld4XVTKTECtR12rIGw1BEARBEARBEOKOPGgIgiAIgiAIghB35EFDEARBEARBEIS4c9I8GnWp+Exj0zT/GacmwLSGTABvYDUMuMaNa6mjPB5N4A6iFtyiQ91bkQcT7mfoGtf3+wj1xZ1tqC3ELMfCMZpqMU0N6h67GlCjubke89lzuAeDw2ut1DOto4uJafV1EFJVEHWc+gjPSXvyaBwaiZp3vcEFcYdkrCtQHsD5I9GmpUD8XHlPiN/cPghiHTsv69yodQ14mKDa28QYxbxeGqaZVizHPs/379uHfoJ8Ctdw8Beix+jzsl4Q19bhmLRzfweIO2BIjR/F04+AgY/XeFx/qcMfd4Wt8VGT59M/FED99fZ6rO/0aF0niG9P+hZiF6vLYGPeMasG9/1zdxeIK/zY5p9W9IF4WPJuiAdZd4U+5xoxf35tEPuvT+EY6EvE6bEdSW0HZcX7gVj+vdQE9MgUmdn4U8tq67Dl/XYWs5pZBjveC/hq8ShzGxivpRMwxfaMsFsPUsbwbzUkYN826/E+SGNjZ/0Z7NEoXY5jgq0bHov+1oLQ50f2Xg7T+P1ihwS8BpW58ZxNM2Gf4vcO3B/C664lG9E3tqGoI8Qm5jlKNOPNRIWn8dGc+0P4+Odj9851mbH9yvFC3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnZPm0fCwtO6r69MbnpGIfvSilnBdJeaQTzKiFlWraUJfz2oY8Pz23PPB8TONnVWPukynHnVwvzk0HuI+9nAO+wQd7ntvK+a33048r7tARNSkklCLbWjWYNfmufe5jpLrNHntFlLcd8PqYjBxr5/LYxXO7/KG9dPtqZKKdmAlxN2SMe/33R0/h3ioufFE34FkFFC/tmEExJYdTMPOyjMwSwXpjNhGfksTvY61uTJgn9H6WT505vnQZTdfM/1i58UQf5uBNRKWVZwF8cY89BpYFzV7U6ccZmOg3X7UKHtU45ctrlEu9KMng9etuDNpE8S17DxfUH02xFtrmacjaznEL5WfD3GeCWtX/IbV3XiakMnOHyFeUds19HmgpQCm/eRBXbpPMW24Ha9bZ4xHw4Ttbzfh9dcVcZoVlaM3T1cXu26Fjp2SpnKcgdcd8LLrhobVyWDWPtK7NDGn8/Vzj4fGH/5xyU68l+D1FmwOZjApi13Hpy3DSqdFeRF6GsPn4cU5W2Hakr3okzpcjX0m2YrjT20Ar9h6beM1O4iIEg3YTofqEiHumozeK28A23FfJd48Zzmx1k+dP9xJ8s3FMC1Th/Pye1+/4+Q4ROWNhiAIgiAIgiAIcUceNARBEARBEARBiDvyoCEIgiAIgiAIQtw5aR4NrndO1KJuLbLWxTZvBkzbVZ4K8YTOv0Bc4kUtItfMcQ+HjuvUgrHrbhhY7GE1FNKMWAvgvd39Ic7rGtbgpepRM2fmokyhQWrqWc0DpqXmudW17BnaxxKYmzXsuLO6LoEm5Pkm1m68FVkXiarSUXAw3Ke7077YGzuDyL4Sz11Pv94QP3zuHRCnfl/B1rAt9KnkXKxfs/XCv0E8e2A3iLuZCiHmdQj2eXGcKfSgvl+vbbw+DlF0rRU+TlhZ/Z39dckQo1sLGfrRAxBH5tMnIkr8AcXcGd/hmHRysqXHB28i7q2bHccyNt67g+Hj2styCKb96O4M8c1J6yD+e8UAiLubj0CcbcD+NyhtF8R7WKGFg3Wopy7xYh89y3QQ4h5sewVsfQPM4bHBxupF8XpQRQHsX14bjmltqZZKLJQBx3KLHkdfFeGTCPrxGGiYT0uDJQ2oPp35OVmdC1se1ljQ+7BvGozYRvVnsTFjL16n/HZWf6mGG78wjCy6lG3HfdnN7pOUjRXtOIPJuhSvoYUB9Fl00Yb9Kam8dhOrm1HjQw+G1YDnlUXnixnzcZ7fe2SY8B7wSD1eZ4Ls/tVsxPVHejKIiEprwqY2vq2OrLbK4QBO1yfgvrYW8kZDEARBEARBEIS4Iw8agiAIgiAIgiDEHXnQEARBEARBEAQh7pw0j4auHrWHVi3mvrZHJLB+68gQmFZZgYnV87phbvI9tahN5Jo5A/No8LoaXFvtCzJ9P6ujoddgnKBHv0ltEe5vQo9wHmYjq9/A6zVoTCgiVR48Tu0VkwG1hjruqUhhOcMZvFZKlGeDeS6MTA9dzxKac33+Yb8FYm83zL3dWc/2zy/P+EREwc3o2UjezKbHWDZ1cw3E5714L8T2A7h0wBg7h76+HscBxeXSTPKsNMzbxUZTXt5H58P1l56Ny3ehb6gxus36ttFpDdGWPBlN4WVjJPfQeVT4XN1Vj/VFhtixbsXccry2DLAVQDzeinnoXUEcBzhmNg5dlfo9xN/UoE/obCN2omQt+obMrM9FXi34uVCvUEvOpweYH+FMQenwmNcyTX3AFj4SGua/5HUyOMYK5t9kNV00q9GD4+mPK1RsXLdtx33zJLE6G6x78THDwDwbPmc4zrag1v/numyIg5aTUyPhdMBpxHZYWon1b57I/DL02c1OjENV6JHomFgZc91RngxtbE8Gv3eo9KFbKsvMvDY1WEvNbsT121gdtypd2PdzlvkATDOze1Vee8doOjkeYbnbEQRBEARBEAQh7siDhiAIgiAIgiAIcUceNARBEARBEARBiDsnzaPBbBDkYHUMIjX0h6oxBzIXSxuYsNHLPBQmHU7nml69pmXaRT/T9/P8+J0M5RAby3F/yiOEnjyXf7Ef86xr83MgDvyyo0X7eqbi/gp1i112z8DYHFtryGupcF8O9wxxXaWB9Zl6hdN7MR0llaIOtNu8OyFOQ2tC+4H5GqIm65gRgmnglS98nA+Ow3Pn/Tuehfi5ogsh5vnLuS8nwM7zZD0m2Y+qncJNGwzu43EFMYf+ZMcPEN/y1f8Lb2vJ+pjrPpPR+GP3ka4W9FFoI/rU3CVjYNpTV8+HuMyHovtMfSXE233YBw740fPxSx1qnH+Xuh3ic4ylEFdacHvfeLDPfFOLNZfcQdT0358S9nx4VCzHUgPEPoxtFr8dj1FVHY7NGlv4+q/RMj+mBw8KO+VJyzwTfLofT2Ei5gEhH8a8TJaxmk33Mk8IK3ai5WUOIq5b/L4mEMCd9duxr53JVTW8Abwn4/do7mC4j4x24MV3sf4siHm9pAQD+i3316JP57AGPR69nVgbp6MRa/GUe3FMqGPnfJoZvYcuVwrEvN1VxP0xv0/xsTFjrwfvo3iNjtZC3mgIgiAIgiAIghB35EFDEARBEARBEIS4Iw8agiAIgiAIgiDEnZPn0WDaRyPTzEfqn8uL0KOh0aPOMsiej+oDqJe3sjzDHqbf42JFgxZ1bdyTweto8JjrfI2VqKFbvC+sAZx89gaYVuhHfZ8vDfV78iR4lA7/szbmdM+EgRBrmY4xUYe1Trge38w8Q25CjwX3BXG9vVWDOktjBa6/8x9j73+7QcWu8KD8sesWRFKXheftnTt+BXFpDZ5LVhPLd+7H89hdz/LxM81zSyXvinnLAm4ch+YmD4bY1Dk8HZW0DcC9Lk0c1zYF80/xGjjJetQw6yJaJvtL7D+516NnYqgT62ps82DtAe69mp6wB+JsPeqtny7rDfFvUnD9NzjKIC4OoO9nCSvUcMCN+u+ENKzPEwn3CPFrhd9yZpo0fA783bVVeIzM9rDfrq4ETQ+sBEKUB4PdSkTVztExz4RGh/cxSsvqO7FaJnx93JOh42Wz2GmtjI2f50EX7ryPlW46kz0aGaymCKc84p6tgw7HDz+rm2ZmncTEjDtBNq5nWHHbRzx4T8f9oMlGHAO2V2fg9vW4fYue+5lx+8m28L0N9z7XMo9GIds3p/nk1GmT+1hBEARBEARBEOKOPGgIgiAIgiAIghB35EFDEARBEARBEIS4c9I8GjyfdIApnpMjdHPGI6g1DORjHuPKAAobucaOa3p5puAgE2I69PUQG7W4b7V+1G5Hafq4AYXJKCv3J4Y+J/RDXblXsfzPSbhvjSt02xcaA7ZBZD0FIqKACdtkC5uuZTUNuC/HxupolPjRJ2Rl4lmHwj7zo5e1a3LsnPcafbjdW+JLOONpgfdAn4ptcPCHLJyOwwa5eM571kT8ry7aE/wzTJB5y7RstHUHcRxzXhZRH2J2Eytn9UVItaw20OmMNxEbpjrIixcgeyJOH1MZ9omuBjwuJQEXxJ9U9IM40YBeLpMGx+MgO849zJgzf4kb9/WQLxniXznQ83Fz0jcQP+u5COI/lfYMfZ7E6q7wOi0HAijKd2eeQb6dCAJGPI81FdhGpqSwBr6O19FgHgvuoWCXhag6F9xjwU/DKE8FO+ejluf3RXx/2HRnJvbfSAxVuPKAqYV1V9owOuaD0LKGqAyGD+xQM/NPJlZCzD2//H7SbsB7ATu7N7Czek0lXqz3dNCdCDG/n0xjHjTOdxu7QTxpyMbQ50RWA8TF/BylrIZHkgnHO3SPxA95oyEIgiAIgiAIQtyRBw1BEARBEARBEOLOyZNOMXWIj72Oikw/aj/I5j0LX00Ve1HWwtOH8fS00T8SXy/xcvUcPUvFW8PebxYGcH/8LK1cJE2lmHOn4hwinfoPKvZrYEMtvvM2sDY2anC6lrWpgU3nqSN5+lsXaxkDWx9X03FU8MyUNbQ26oJzQp9fHvg2TPu/PEwXm25CmYGZ6RCsTEdhYtN17PU7l3t6giydJOszPIXy/jqU0ZR58DU2l2i2V5QBj/umulyIuVzpfw5dEvocsGGbJGjxPP2pviPE5zn2QjzcgtKmN6q6QnyhbRfEm+s7Q7ymEmUNWeYqiB9w5UDsZLLdcxwHcPs7Lgh93p2FSY+npK6DmKfcDnTCdZ8xRMkrMYxMU21KwmOg8+C1PmBmKajZKRgwc+kVm9+L57jWggO/rh77oycZ16f34/qCJpxuxK5OCfawuIWn2dd6uMzrzExv3Bz4PV12xP3ldx68fztcjfdvIzrshrjWj/NzqRMf9/l1ZWzCLxB/pe2O26/DlLM8ne7G8g4Q69NQE7y9Kpwe93AKdmAruxGp8eFv4fe2rYW80RAEQRAEQRAEIe7Ig4YgCIIgCIIgCHFHHjQEQRAEQRAEQYg7J82jwdO2cSI18CxbGAWZB4N7JKI8GkxDp2Up7gws9jI9X4ClBNNrub4fly/0JUKsuDQyQgbnYDkuK/yo0/bZ26+u8kTQ+rgnA+MA8ZTEqMc3ErZxvUJtLfd4cGxMC6n1SzseFzHS2RIReRPDGtS7350O0xwFOC+3XkU1IW8inpqS/RmGnfZRPpyo6Uz+yiTVFDDhDlT2D/fJHv1RN6w2baF2A2sX7nU511QI8f2780Kfu3pja44HWtCTYWVprV8tGw4xT135fuBsiK91/hhzffu9qRCnGjB1ZTFLfdnFWAxxnTt8rfuhOBumTWZ+vgPeFIiDvqYcgW0TDfO3Ba3MRxFxfc9LLYNph0x4vP3MBMm9pPwcZpcFIh/2TY2RXXfYfU8TdtCoewefFb+w6MNjREk9mkEDFnYc/O3HB8j9Ktynm6wLT59b2Q+muWqwE3Q2lUO8n9BbV1CDcaYR09m6g+iTqGUx93A49DhmHK7Dsb9XCo4Jtgyc/7Of+oQ+v2ofDdOe7fA5xEbWwfm9bGshbzQEQRAEQRAEQYg78qAhCIIgCIIgCELckQcNQRAEQRAEQRDizknzaPitGNcq3HQnfTjfuDsTdYneOtS4NaUr49O5x4LDPRm85DyvucDXz/OXexNZTYVAeP3lQdTIVTGRaABXJTQTXS16LvgTtIEJ6nlsZjGvoaBldTl4TQYD09bynOZCfKifVRH6fE32dpiWasC6GU2dx1FtrOH1dVCQzWut8LobTRFk44w7iALuQ57E0OcVY7AmSNamFm2qTaNh/iaep55jOBA+jpqvv4Fp33mwjTbXY50Lvu4kvRtifp7Xsz7xvqsvxGl67INa1sf4eB99LcHp9m/DcWV3vA4aemN/TNaj/8NgaVn/bCtofXjMIq+vRER2S1jDXlSDPoaEvTjOVxjxPkTHSo/wuhncw8ErlQTqsD/x9ZlZ3zaX4W/hnoykXdiGvxSEfTqje+L4F1USof1YNMjA7vH8ARz7D0a028f78Jz112EfKPKhR6K4Hn09Nj16LLKNFRBvrMFaOTtUFsTcw8HHgIJK9ICM7bgD4p4WLK7yGYU9GptLsOaGoQP2x1pWRyPbhnV+cPSKH/JGQxAEQRAEQRCEuCMPGoIgCIIgCIIgxB150BAEQRAEQRAEIe6cNI8GTzK/05sJ8ZW2sO6M56/3uVHTdrguAWJeN8MbiP2zuCaOa6ebijnfV+VCrBwo5LTuCO9/eQA1vry+QwB/qtBMtO7YemReB8PA6maYmtDf8+V1zLPB06sbq0hoBYoKwvrVBVXnwjS/F/WoRqZR1zRhm9HpsE15SY+mlufz+7ysPo8fz/VgLfYavTOs/bWzWkLRG4tdL6Ito1ido/NseyD+idWmsB5pvGHON+ExXlWDMT/PzTocuwOsqIeDie759BI/6rn5/FZWl8PNCi3c4MC6D68eDI87NZ1xWym6Woi/c+fjvhWyIhFnCNyLoHfheeU0h4/5obWoWa8ahssacpmvS8u8eEbsHzU/YK0SrRX7S9CN53x9GvblxD7YvpygD5ff3wX9Avoj4el65tHhlowgNw6eweSY8bi6mNnVEeHhqDyQCNO0Cei5qGP3aG4/3pTl2nFb3LfFa+9U+3Ffij04RmSasQ5H1+RSiH+qxPo5R+rx/tdoD+9/aTH2lyHfT4XYwvpzr0SsSXSYWgd5oyEIgiAIgiAIQtyRBw1BEARBEARBEOKOPGgIgiAIgiAIghB3Tp5Hg7HPgzpbnT2sFUvYgzrJ9NElEOfZUCNXaUQtqoklu7boYuv3m/JgcOqYkcKmR01e15wi3L81HUOf61n9EJ6nPWhsR8mv44jmSDHELhW7a/sI9fxuNn+pD3WUHQzlENcr1GXqmIA/oSB27RaNNjz/GSy3bxpufOBGB4YuMaxHDbBc6cqHsb8Yc+g3UX6HAqwdombnwwT3cPB2ZH/G0RjYAglM3x1RD8CVx8ZAvi/sOGn02H+VnyX8b0NYDuFvOeBFXXymAQ1Q5vLGT6DxV90Msf4I5rynYBOdQnuCOvem1u/D8f/iDudBbN3wbeizvt8QmMb9IbwmSPp3zd3JtoW+lnkTNPi7TRE+m86fYl0U3+OVEHdPwOtGUR1q3Cs9rM5VEauFo0P9vakWpwcs2P55iXjvUsPqGnSwYt/2ZOJvO/zbrqHPJUPZ+EaIpqm+dwaxvhJrV2Rb8DgeiCjk5tiFx7QuDdvwnAEHIOae3ixmwOS1c/j4lKjFPlgcwHsLXu+pzILtWsWK0J1nRc/a9vLw1cG3Bpdd9usXIH6hDE1Knx/sDnEqYc2OeCFvNARBEARBEARBiDvyoCEIgiAIgiAIQtyRBw1BEARBEARBEOLOSfNoaH2oILzcuRlikyashXTuRM3bgZWYC3vFENTU1dahzpHnw9eyvOwaprnjWm8ec7iMPNmJGryq71BR3WlbON95mq4OpvW37oP4Xymxtf3tFRWIfVwCZeihWF+XC/F42y6IUaVJlKVHbePZxl8g3u/HduugQx2mgSlknRswIzVXzDf1e9oLGh22BPcWaAzoh3p/yGuhz388MAmm3Zb9FcQpWqwzoGUmCq6NNWtw21ybq4t2bQD1TCPPNfOc6iCOY/8qHhr63KFvJUzbHHNNZxbmcjzO2Qb0Vdi06IlL+ndYsxx1Vq37EcLT3rlSWNTopA5fYL7/bregv2OAdS/Eaw+fH7/9Oo3QsAuwPwFb3RhRM0GzH2sSaC48BHFB1NpxnDexqRkNLNESmiqvtL+J6aa8sMfDG8TbN5+TeVe07efvyDdmroP4i+qeENs04XPFlY/HqdusbyF+stMlEAfr2W1yAK/1GhbzOkAaP3PPBFmsw/n1NVoW4/zv1I2FOOuva0Ofj3yI15xkHe/ByCWdtkK8PurOKD60n54oCIIgCIIgCMJJQx40BEEQBEEQBEGIO/KgIQiCIAiCIAhC3DlpHo2cRaihv2fkdbgjEfpp3UGsm9HxqS0x1512gvsWbxJoV6PTrtx0O8Q6pgPP+0C0+w3SRH0FzjPvXwnxB8PQC7N/eS7E6RtR/7z3GqbDNLBc/bV46tj2obYxe99aEpqmKa+K8mG7PHTDHaHPhn04Tvzdjp4NCvLCGKwP6ZrQo/L5W9gHNbwwh485BHSsDoglrKctNaMvjSj2GHgmeX7Sv6uG+N6vfoUzePG4dS9qvGAE9/jw46RhdTLUKa49oDGweiiesB/F9GMBTLtg3QyIPW6s7dNt9cb47txpQm0mtimZ0Kvy477wudOzZvfJ2KWThqoMnxvbD+XCNK0Dj4PWx47TGcwTz94Ese+SSoiX7eod+txzNk7jI2fXmzbFcc9OLvb/S4C4n+9WiP0+vOaZN2ONjmxqnfsWeaMhCIIgCIIgCELckQcNQRAEQRAEQRDiTrOkU+o/kgE/+aiJDI+Nog1gSkJ/LcYUIZ1SQXwFGFAYt2UCbv67Wao+v45NPv7f7qejy6oWSj6aQzz6RGsSrK+HmPe3gIdN96NEJ1jHpFN+JoOpw1Mn4MF28zfZbhHrb4X2aYzTr0+wVH9N7Jfyh9tNE8Q2VQEmhWpKOtVUKr8TlU7x7QeZdErDpFMR7/CDAdyWakl/OrpAM/bwKKdbn9CwawU/F7l0Kta5plFMGqUCTUw/xdIp1Xi7qyCOUQE3jmHBOvxtTY9BjdNafSIe142Aj/9u/J2aiHShfsWOWRu/l1ARvyfI2l+x4cbvwy9Ox/4Quc4T6hNePBb8PivoCZ8b/sCZ1Sci8fv4cWDnCpNOBTzNH0ujttWCPqFRzZjr4MGD1KlTp2bvgHB6ceDAAerYsWNc1yl9om0jfULgSJ8QOPHuE9If2jYyRgic5vSJZj1oBINBOnz4MDkcDtJoNE3NLpwmKKXI5XJRdnY2aeNcvEf6RNtE+oTAkT4hcFqrT0h/aJvIGCFwWtInmvWgIQiCIAiCIAiC0BLEDC4IgiAIgiAIQtyRBw1BEARBEARBEOKOPGgIgnDGUlBQQBqNhp599tkm533sscdEI9zO0Wg09Nhjj4XiuXPnkkajoYKCglO2T4IgCG2ZM+ZBY/fu3TRjxgzq0qULmc1mcjqdNHToUHrxxReprq6uVbb59ttv0wsvvNAq6xaax7EbgWP/zGYzZWdn0/jx4+lvf/sbuVyuU72LQgwi2y7Wvy+++OJU7yrgdrvpsccei7lfFRUVpNfracGCBURE9OSTT9KHH354cnawndDQ+d+9e3eaNWsWFRUVnerdE9ogci8hcKRPnBjNqqNxurNkyRK65ppryGQy0c0330x9+/Ylr9dLa9asoV//+te0ZcsWev311+O+3bfffpt+/vlnuu++++K+bqFl/PGPf6S8vDzy+XxUWFhIX3zxBd1333303HPP0UcffURnn332qd5FoQHmzZsH8b/+9S9asWJF1Pe9evVq9X357//+b3r44YebNa/b7abHH3+ciIhGjRrV4DzLly8njUZDF110EREdfdCYPHkyXXHFFfHYXSGCY+d/fX09rVmzhmbPnk1Lly6ln3/+maxW66nePaGNIPcSAkf6xInT5h809u7dS9dffz3l5OTQypUrKSsrKzRt5syZtGvXLlqyZMkp3EPhZHDJJZfQeeedF4p/+9vf0sqVK2nSpEl02WWX0datW8lisTS4bG1tLdlstpO1q0IEN954I8Tr1q2jFStWRH1/MtDr9aTXxx4Sg8Egeb3emPMcY+nSpTR06FBKTEyMw94JsYg8/6dPn04pKSn03HPP0eLFi2nKlCmneO9aDxm74ofcSwgc6RPxoc1Lp5555hmqqamhN954AzrBMbp27Ur33nsvERH5/X564oknKD8/n0wmE+Xm5tLvfvc78niwiuTixYtp4sSJlJ2dTSaTifLz8+mJJ56gQCBcXXLUqFG0ZMkS2rdvX+i1fW5ubqv+VqFljBkzhh555BHat28fvfXWW0RENG3aNLLb7bR7926aMGECORwOuuGGG4jo6E3kCy+8QH369CGz2UwZGRk0Y8YMqqiogPV+//33NH78eEpNTSWLxUJ5eXl06623wjzvvPMODRgwgBwOBzmdTjrrrLPoxRdfPDk/vB3RnLY4xuuvvx469wcOHEjr16+H6Q15NDQaDc2aNYvmz59Pffr0IZPJRK+++iqlpaUREdHjjz8eOv8jtf3BYJA+/fRTmjhxYmg9tbW19Oabb4bmnzZtWmj+TZs20SWXXEJOp5PsdjuNHTuW1q1bB/tyTCb05Zdf0owZMyglJYWcTifdfPPNUX20vTNmzBgiOnqjMGrUqAbfOk2bNu24x+xXXnkl1B+ys7Np5syZVFlZGZo+a9Ysstvt5Ha7o5adMmUKZWZmwvVk2bJlNHz4cLLZbORwOGjixIm0ZcuWqP1tbOwSThy5lxA40ifiQ5t/o/Hxxx9Tly5d6IILLmhy3unTp9Obb75JkydPpgceeIC+/fZbeuqpp2jr1q20aNGi0Hxz584lu91O999/P9ntdlq5ciX94Q9/oOrqavrLX/5CRES///3vqaqqig4ePEjPP/88ERHZ7fbW+ZHCcXPTTTfR7373O/rss8/o9ttvJ6KjA8L48eNp2LBh9Oyzz4akFTNmzKC5c+fSLbfcQvfccw/t3buXXn75Zdq0aRN9/fXXZDAYqLi4mC666CJKS0ujhx9+mBITE6mgoIAWLlwY2uaKFStoypQpNHbsWHr66aeJiGjr1q309ddfhwYl4cRpTlsc4+233yaXy0UzZswgjUZDzzzzDF111VW0Z88eMhgMMbezcuVKWrBgAc2aNYtSU1PpnHPOodmzZ9Odd95JV155JV111VVERCDPW79+PZWUlNCECROI6KhEbPr06XT++efTHXfcQURE+fn5RES0ZcsWGj58ODmdTnrooYfIYDDQa6+9RqNGjaLVq1fToEGDYH9mzZpFiYmJ9Nhjj9H27dtp9uzZtG/fPvriiy/EzP4fdu/eTUREKSkpcV/3Y489Ro8//jiNGzeO7rzzzlAbrF+/PjROXHfddfT3v/89JLs4htvtpo8//pimTZtGOp2OiI72jalTp9L48ePp6aefJrfbTbNnz6Zhw4bRpk2b4AajsbFLOHHkXkLgSJ+IE6oNU1VVpYhIXX755U3Ou3nzZkVEavr06fD9gw8+qIhIrVy5MvSd2+2OWn7GjBnKarWq+vr60HcTJ05UOTk5x73/wokzZ84cRURq/fr1jc6TkJCg+vfvr5RSaurUqYqI1MMPPwzzfPXVV4qI1Pz58+H7Tz/9FL5ftGhRk9u79957ldPpVH6//3h/Vrtl5syZqrnDUnPaYu/evYqIVEpKiiovLw99v3jxYkVE6uOPPw599+ijj0Ztm4iUVqtVW7Zsge9LSkoUEalHH320we0+8sgjUWODzWZTU6dOjZr3iiuuUEajUe3evTv03eHDh5XD4VAjRowIfXesrw8YMEB5vd7Q988884wiIrV48eJGj8OZyrFj8vnnn6uSkhJ14MAB9c4776iUlBRlsVjUwYMH1ciRI9XIkSOjlp06dWpUG/E2Pbb+vXv3KqWUKi4uVkajUV100UUqEAiE5nv55ZcVEal//vOfSimlgsGg6tChg7r66qth/QsWLFBEpL788kullFIul0slJiaq22+/HeYrLCxUCQkJ8H1jY5dw4si9hMCRPhE/2rR0qrq6moiIHA5Hk/MuXbqUiIjuv/9++P6BBx4gIgKdXaSW3+VyUWlpKQ0fPpzcbjdt27bthPdbOLnY7fao7FN33nknxO+99x4lJCTQhRdeSKWlpaF/AwYMILvdTqtWrSIiCuntP/nkE/L5fA1uLzExkWpra2nFihXx/zFCiOa0xTGuu+46SkpKCsXDhw8nIqI9e/Y0uZ2RI0dS7969W7RvS5cuDcmmYhEIBOizzz6jK664grp06RL6Pisri371q1/RmjVrQuPcMe644w54C3PnnXeSXq8PjXHtkXHjxlFaWtr/b+/Mo6Oqsra/b82VVCoTCRBCQhJmUNEIRkEQRBBFFEVQaIVGlE8cu18/WrtfWxGHt9XmE7GhwWWjrdKiNrYgIMYX1JZBQQQVBMMUxgyEzFMN93x/0KnK3hWqEqiEJDy/tbJWdt3p1D37nntP3f3sTV27dqU77riDHA4HffTRR9SlS5ewHufzzz8nl8tFjz76KBkM/tvnvffeS06n03cf0TSNbr/9dlqzZg1VVFT41lu+fDl16dKFhgwZQkSn336WlJTQnXfeycYdo9FIV1xxhW/cqY8cu8C5g2cJIIFPhI82PdFwOp1ERI1KYZqbm0sGg4G6d+/OPu/UqRPFxMRQbm6u77Ndu3bR+PHjKTo6mpxOJyUkJPjEqaWlpWH8BqAlqKioYIOFyWSi5ORktk5OTg6VlpZSYmIiJSQksL+KigoqKCggotMPnbfddhvNmTOHOnToQDfffDMtXbqUxWHOmjWLevbsSWPGjKHk5GSaPn06ffrppy3zZdshFRUVlJeX5/srLCwkosb1RR0pKSnMrpt0NEbbkJaW1qT25uXl0fbt2xs10SgsLKSqqirq1atXwLI+ffqQrut05MgR9nmPHj2Y7XA4qHPnzhd0rYe//OUvlJ2dTRs2bKDdu3fTgQMHaPTo0WE/Tt19QvaXxWKh9PR0dh+ZNGkSVVdX08qVK4notB+vWbOGbr/9dl+IW05ODhGd1pTIceezzz7zjTt1NDR2gXMHzxJAAp8IH21ao+F0OikpKYl++umnRm8TKoa5pKSEhg0bRk6nk5555hnKyMggm81G27dvp9/97nek6/q5Nhu0IEePHqXS0lI2AFitVvZrJNFp8W5iYiK9++67De6nTvyraRp9+OGHtGXLFlq1ahWtW7eOpk+fTn/+859py5Yt5HA4KDExkXbs2EHr1q2jtWvX0tq1a2np0qV0991301tvvdV8X7ad8vLLL/tSyRIRpaam+grxheqLOuri4SVKqZDHP1O2sjOxdu1astlsNHz48CZtB86eQYMGsaxz9dE0rcF+ri++bA6ysrKoW7du9P7779PkyZNp1apVVF1dTZMmTfKtU3c/efvtt6lTp04B+5BZ0Boau8C5g2cJIIFPhI82PdEgIho7diwtWbKENm/eTFdeeeUZ10tNTSVd1yknJ4fl5M/Pz6eSkhJKTU0lIqIvvviCioqKaMWKFTR06FDfegcPHgzYJ4SXrZ+6egyhft3MyMigzz//nAYPHtyoB8usrCzKysqi5557jpYtW0ZTpkyh9957j2bMmEFEp3/hvOmmm+imm24iXddp1qxZtHjxYnryyScDfvUAwbn77rt9oSZEgQ/+ofqiOQh27a9evZqGDx8e0M6GtklISKCIiAjau3dvwLI9e/aQwWCgrl27ss9zcnLYJKaiooJOnDjhE54DTmxsbIMhcvV/ZWwsdfeJvXv3slA3l8tFBw8epJEjR7L1J06cSPPnz6eysjJavnw5devWjbKysnzL6xICJCYmBmwLWhY8SwAJfCI8tPmfRmbPnk2RkZE0Y8aMBivB7t+/n+bPn++7CctKi/PmzSMi8oU51P3yWf8XMJfLRQsXLgzYd2RkZLt91dUeWL9+Pc2dO5fS0tJCpoGcOHEieb1emjt3bsAyj8fjS11ZXFwc8OvogAEDiIh8ITtFRUVsucFg8GUkaiisBwQnPT2dRo4c6fsbPHgwETWuL5qLumw/9VOaEhG53W7Kzs5uMGwqMjIyYH2j0UijRo2ijz/+mIU+5efn07Jly2jIkCG+V/h1LFmyhGlSFi1aRB6Ph8aMGXNuX6qdkpGRQXv27PGF3BER7dy5kzZu3NjkfY0cOZIsFgu9+uqrzPfeeOMNKi0tDej3SZMmUW1tLb311lv06aef0sSJE9ny0aNHk9PppOeff75BnVH9NoPmBc8SQAKfCA9t/o1GRkYGLVu2jCZNmkR9+vRhlRs3bdpEH3zwAU2bNo0eeeQRmjp1Ki1ZssT3+urbb7+lt956i2655RbfL4RXXXUVxcbG0tSpU+nhhx8mTdPo7bffbvDVe2ZmJi1fvpx++9vf0sCBA8nhcNBNN93U0qcA0OlwlT179pDH46H8/Hxav349ZWdnU2pqKq1cuZJsNlvQ7YcNG0YzZ86kF154gXbs2EGjRo0is9lMOTk59MEHH9D8+fNpwoQJ9NZbb9HChQtp/PjxlJGRQeXl5fT666+T0+n0DTYzZsygU6dO0YgRIyg5OZlyc3NpwYIFNGDAgBapcH2h0Ji+aC7sdjv17duXli9fTj179qS4uDjq378/FRYWUllZWYMTjczMTPr8889p3rx5lJSURGlpaXTFFVfQs88+S9nZ2TRkyBCaNWsWmUwmWrx4MdXW1tKLL74YsB+Xy0XXXnstTZw4kfbu3UsLFy6kIUOG0Lhx45r1O7dVpk+fTvPmzaPRo0fTPffcQwUFBfTXv/6V+vXrFyC0D0VCQgI98cQTNGfOHLr++utp3Lhxvj4YOHBgQKHJyy67jLp3705/+MMfqLa2loVNEZ0Oz1i0aBHddddddNlll9Edd9xBCQkJdPjwYVq9ejUNHjyYXnvttXM+ByA0eJYAEvhEmDhP2a7Czi+//KLuvfde1a1bN2WxWFRUVJQaPHiwWrBggS9lmNvtVnPmzFFpaWnKbDarrl27qieeeIKlFFNKqY0bN6qsrCxlt9tVUlKSmj17tlq3bp0iIrVhwwbfehUVFWry5MkqJiZGEVG7SUXWlqhLP1n3Z7FYVKdOndR1112n5s+fr8rKytj6U6dOVZGRkWfc35IlS1RmZqay2+0qKipKXXTRRWr27Nnq+PHjSimltm/fru68806VkpKirFarSkxMVGPHjlXbtm3z7ePDDz9Uo0aNUomJicpisaiUlBQ1c+ZMdeLEieY5Ce2IpqS3bUxf1KW3femllwK2J5HK9EzpbR944IEGj79p0yaVmZmpLBaLb1+PPfaY6tu3b4Pr79mzRw0dOlTZ7XZFRCzV7fbt29Xo0aOVw+FQERERavjw4WrTpk1s+zpf//LLL9V9992nYmNjlcPhUFOmTFFFRUWhTle7pDHprZVS6p133lHp6enKYrGoAQMGqHXr1p1Vets6XnvtNdW7d29lNptVx44d1f3336+Ki4sbPPYf/vAHRUSqe/fuZ2zfhg0b1OjRo1V0dLSy2WwqIyNDTZs2jflyqLELhAc8SwAJfOLc0JRqhBoSAABASPr27Utjx45t8E3EuVJXTHLr1q1nFD4DAAAArYk2HzoFAACtAZfLRZMmTQqIwwcAAAAuVBo10dB1nY4fP05RUVHtSgnf3lFKUXl5OSUlJYU9JSJ8om0Cn2hefvOb3xARNTn2vzFUV1cT0eksU+HcP3wCSJrLJ+APbROMEUDSFJ9oVOjU0aNHA1IsgrbDkSNHwl7kCT7RtoFPAAl8AkjC7RPwh7YNxgggaYxPNOqNRl1V5SF0A5nIfO4tAy2Ch9z0Na1hVbHDRYv7hPylI8T8+MCSi5mdvtjDV/hu9zk1x3v1JczOvYu3J/2+H85p/81Fm/MJ2e9avV9O9HMruFY76jJml6fw4dAVxY8dkc/7uDqBL6/uzIstRebyX3k6LvrmrNrZIAZRgPAczkWb84lzIcQ4YoiMYPZ9G3cwO7vkImbbjC5mz4zfxOwb1zzE7IzHtp1T+1qK5vKJVucPA/sx88i1DmZ3/dO3fP0w98fhN/nx0/+7mNmeo8fDeryz5YIaI0KgmS3MVm4+BmiX8MySPRfkMDtnFB+79Zq2mfK+KT7RqIlG3essE5nJpLV+RwD/4T9jYnO8jmxxnwj4DsEHfEMET2drMomJxjm2WTPx/RsieHta7XXS1nwi2ERDO7dX+F4z70OjhQ+HRqsmlqugyw02XSzn7QurT2hionEu56Kt+cS5EGIcMWj8ISIiip9ni4d/B6uRbx8VxfvBYBfjUKhz0MRxrtloJp9odf4gxnGjNVR/hbc/Au5TBitfoTWcI6ILa4wIgSbaqDTuE5qR96HFwdc3afw+o2tttBp4E3yizRfsAwAAAAAAALQ+kHUKtA9EKIleyX9F0F84yeyiyl7MLjkUw2xl5r9SdOrGq30rxcW4al98o5sKghDq1xFV79efJoYPGcQr3lteymb28sOZzB4Yz8MWfilNZPZjqV8we0Uh395zOf8d5+S+gcy2rt7KGxjku2tG/l2V99zCxi5YQoS+GOJime1VvA/jLRXMtmr8TelN2+9ltrm4ib/lIdt80xHXjbFvT9//1V2dbJm1qIave+wUs4eO5WEuO7MymG0y8F+fe8UUMLuwlodeSV5L+5DZwz4ZxGzviTxmawN5qJ5u9vuTwc3borb9xA8GXwoP4j4jQ6UMkZHMPjYimq9/Pw+lyn2C34dSn+LhluEMi20t4I0GAAAAAAAAIOxgogEAAAAAAAAIO5hoAAAAAAAAAMIONBqgfaBExp8KPofed6ATsw02HlutxfK4S6PIJuPy8LjJUyd4HKZMAhSS+nHFiKX105RzoZoWu2r9hKcuXXH0UmZ3jSph9rcnUpndJbqU2b/bICqAKx4rfu9VXzJ72T0dmZ1ysCezvbt/CWx03a49MmsaCls1BmMHoZ1K5LYeyTPEeLb+yOxHsn/F7IO3LGF2lc7HjY5m7iMrHuUx+LqNZxmiXmnMNJzk23sL/NoyGRsOTqMPHcBsr8F/bUT8UsjXzeOaCs9/imDWcegKvu+Yy7h/VDzH138j5Wtmv1vO/WvO9rHMvn/qZGb3PMTT5waMfsIfTfFxfqNTAltWO4Kn6zb973dyb6AZOHUrT6VvKRG9+C3vw1sX82eV754Sv/e3A02GBG80AAAAAAAAAGEHEw0AAAAAAABA2MFEAwAAAAAAABB2oNEAbQMZuy9j1MVyr5PHORpLuYjCfExUIBXFOQ0iJL7SyuP7tTi+f1vnSgItS8ndVzK78Areib37HmF2SiSP1/aIGgkzOn3F7Ne81zL7QBGPv9Y8fPu5I3mO/A/yLmf21J5bmP3d61wDsr/Yr9lwr+vAlnVcIHKtQ9fjo74OQ0/lWiwq4zH15OYXtjGvitnisqeOG3kf/98srutZta8/s+1WN7NNI3hdjoQPS/gBqmqZqZw8Jz918m9vKuZjjOfAIboQMaV3Y7a3Qujr6p+nWr5Mk5XanbymgScvn9nqu13Mjryet2U0DQja1jTayfcvlhsixH3F0vjK2FpJObMtRn5P1PrxWlHeXXsbvW/gJ6CGkdBQFFzNe7XH0uBaqkIX9zljv2RmB/RTO6irgTcaAAAAAAAAgLCDiQYAAAAAAAAg7GCiAQAAAAAAAAg70GiAtkEITYbEfJK7trlCEzZf32MXuxdhkXJ9TecruGodQdsTAGLsz4qjT1zl+/+6CTwHfbmbx1//cDKJ2T8f4LahnPvIchtPov/jPh47O7jPPr7c0JnZT20bx/d/hLdnN6Uz2x3HY3uvuXiP7//KSUVs2dYBXO/R855tBP5DvdoYxvwStkiJOgmaOXgMvLE7r2sR9w2P2f9xEL/uUz08R37A/kScvCY0AaqMDyyaxcK3r/C339uB1+4xJvA6Ct5CrkFqL2hWXsuibACvR+PcwfvIlRTj+9+cX8aWqTKuayCv0PLVr1NBRHqp2F7WswmBbLs8nl7FNUIkTLm9wen0tyWCjy9aNdcGuJJjmG2tTGG259DhhpoMBKHq13RJ4WO1tvlA0PW/XnMJsyOz+LNAPJcFtQvwRgMAAAAAAAAQdjDRAAAAAAAAAIQdTDQAAAAAAAAAYQcaDdA20MScWAXPJW2q4poMTySPgzS4RM5xUUdDExIKA0+PT16r2J9HaEhCUT83dhvMi91iCG2O6Ypi3//bT3Zly47s5zHr9mN8eDPG8U42Ch/5sYhrLkj06Y6P+zL74Wn/YvYLm25gtlns32vnPmMs5e3bWeDXkFTt4LHixowaZldMzGK2431eo6M9I7UJ5Dnz9aOJOgUkY+xN4hZYzmtVKBGjb+jGfU5F8jh5w8lSvvx4AbfF8TSbiOE3inHO6/dZYzHXF6g4rtmgdqrRMKRyrZStgNce8SQ6mW0u9uta3B35MsO+g3znYdbKaaJ/VW2tWIGPCcYeXLel8ngf6hVCHFj/XiH25U4U9Rmqua974/lyOkSgATQz10lJjUbNTYOYfeww96GeFFyj0fUzPsbk3sDHKF6tKXQdj6C0khoceKMBAAAAAAAACDuYaAAAAAAAAADCDiYaAAAAAAAAgLADjQZoGzQxttAoUl+7RDhzwBRbaDR0cWVoMtRRpOM3lzdRo6H00OsAqh3D60fM6fcP3/9riy9iy44YOzC7prPIkV8lOl2Y3aJPMbuyhsfqVtXwGOcXV/O6GZauPAm+MnEn0VO4zsL6Ey/ecnfGN77/Xz0ymi2befHXzH79+EhmO96nCwbNws+rqherriL5OdUqeR2NUDH5MsZeS+A+pUS8tKFMFD4wh9BgGITT6SHGgfrtldsamjjmtFGqenC9UuTPXMdQm8qXu53+69a6eS9bdvzhK5ntGco1NcZN/EYRkc/7x2vh57wyids1iXzMceZwf4k+xHUT1fF8edGARGarOH4jS17h9y/rSVE3I5aPV5F7TvLloq6GuKWB/6AJnZQS+szD47lPxG8MXpsnYP+bdzJbv+XKM6z5n+OL2itBNSStRJMhwRsNAAAAAAAAQNjBRAMAAAAAAAAQdhA6BdolBhE6ZRBZLZWIOggVhKDElFymv7XwN/ChCXNaxfbKiav4EPVZSX/f/7kVPGTiot5HmP1TbhKzqZKHsRhqea/nvNeL2X9+9A1mP7l6OrO7TtvH7LkpK5l9T9RdzC4u52kMI/K5D8z/9lrf/ylr+bJPe/LUuvbuTXW49oMSKWq1Wv/Frsc4+LIqHq5GIvSJ3CIuQqa7lelwJdVi/6FCpSQiRaly8YFL7+oPpTFUiUHNe2GEX0Z8e4jZ3m6dmK25+Xmo6uIPLTFdxNPHdvm8iO/8c256d29m9r4/X8FsZeHH6jMvn9mlC3l/29/n6XX3/YqHvdiO8/7v8bvtzJapTd1X9Pb9X5PIfc1Uxdumx0Qy25LH0yO3jqCa1odeUxN0+c2X7GD23od4PzT1qpRh19rl/Zmttv3EN5BjGDt46+xVvNEAAAAAAAAAhB1MNAAAAAAAAABhBxMNAAAAAAAAQNiBRgO0S3QeCkseB4+cNJeJNJUiFFumx1Uya5yFx9BrUvQBwoKeztOTrtvTx/f/lRkH2bK+jhPMTnfw9I4fuwYwOyKPO0mvO/cwe1khj8/uPJUf71QNj4F+8jBPd/vb7tnMfurdKcwuHVXB7OTl/tSsCb/bz5Z9tzuN2UZHCO1AO0Yzi3SSNbW+fz0Ortsx6UKzcYLH6GsOrpsJQGg0lFXcMuN4OtQATUiodLZCqyXT63qi/D5qKakMvu92ireQp7M1ijh09wB+bdRPQStTvhqruCZH37E76LF7vVHM7Nyb4/n2eQXMrv7oEmZHHz3G7D5/4Nc8idSl3tpaZhviuT/XxPt9/8QQfs/puIXfpCJ28LZ58rieBDQOdSXv0wjD98zWK0OMxSFSzlrK+OLjw7iup/M20R7hM2z/0GgAAAAAAAAALhQw0QAAAAAAAACEHUw0AAAAAAAAAGEHGg3QLqnoyUUWWrXQZIhQxpp4ESstQqntBSLfvZBklGXwDTo2sp0gOD068zjjn/cnnWFNor/vGcRs3ct/R3F24DHuN039htm7y3h+/u+PJgdtm7aHx/8fs3Mf2n+8B7Ntw08xu+QEj8U1zcrz/f/dLp7/X7OL2hGykMsFhLIJAVapq+EViUhZ+C1OM4jr2MTHBU3WphB6EM0jlos6GFI3EbD/Wq4RUHaeg19qPGpj/Me35InvUs3j+TUr35cS8f7tBW8Rv45sB/l1dHh0Z9//rmjef9XxXFMTY7uY2cZycc7yuD4k+YVfmK0s3Bc7LNnCl8fF8v3FxXBb+I8pKorZlf07M9tc4fe/9A+5L1kOQpPRHOTcza+rnO/5faYnCRFFCE2GJH4X97lD00JU4miKDiNUW5rY1rMFbzQAAAAAAAAAYQcTDQAAAAAAAEDYwUQDAAAAAAAAEHag0QBtAxkLrULEqIsptKmCf6CL0ER3Jx7vqhl5nGTECRvfXzVvjzu6deavbuuYDLwfNLPfrvHy4avj3+3MPnyz8JFDvGbC3ZfyeOrHy25htquMx+bGJJYzu9dIXndj78lEfrzDPAe+awu3b53Ajz85zm9P2PcgW2Yw8e/y3OUfMfsN4rUE2jOaLvq1ng5CmcV17uUXulHE1Cs5jrhlQR0xkHj4da65+LhBQuOheeT+hGajkteJUdFc9+O11htnpH5EjImGKLFtO9VoSDwHDjE7fbbfLp52JVtWli7OmYePCdZSfs1bosW4XxjDD24RNV0E7g4h6rR4uf95I7imwxPJ/S/ql1Lf//oPfPy5cCvrNC+PDP2M2dnX92d2wHlvos7BtGEHswc+w3VEvJJLEwnVlhaqu4E3GgAAAAAAAICwg4kGAAAAAAAAIOxgogEAAAAAAAAIO21Co6EPu5TZRX153GTMfh4na993ku+gludZ9xw7fm4NaqpeAJw7mpgTKx5baOokKlfU8PWtRbzPahJ4n8V8x2O3Regu1Yp06OYyodHgqdxJM/FLS3lFbHe9WG0l47gvYGQtgBhLFbMHdT/k+/+ujpvYskeu6c5s+2HuA0/f9S6zJz/7GLOtt/G88x278OjY/FyusfjmGO/09J55zD4ex9e3XMb3t3p/P2av2HmZ3zBw/7wqfT9ftzCT2QYbP096Da/H0K6Q463Vf+1q7uA56JVL1NfRQ+Ssl8cyi+ta2JoWIuZZ1NVQZVz3o4k6HLrJ70Oa1I/ItskxElBkHj9nJb14f9lP8uWmClHnRNRd0WMima25g/e3qZTrZJSR708TGo2aRD7+6SahKSmu8C+TB7uAnku8wy9jtsfOryuXk9umGv/ZMrj4eYncfpjZNe/wPng0dgez13a+mtlVA7sw236Cj72mEj42a8VlzFbxMczefoQfv0c3rr3SnfzhRLf5dULeSK4ZkuelKoH7f4dtvCaNd9deag4wMgEAAAAAAADCDiYaAAAAAAAAgLCDiQYAAAAAAAAg7DRJo6GZLaRpp2PAlMcdYm1BiHjBq3/wx7W5FY8r+3A5z49vGsRjnc1RPM71wCkeUG8x8zhMh41rPAq/5/H96f/k+1PbfuKNld/FIIoyqBBxv+GkHcdhMkKc0/IrUvkHVr6+QbirJ55/oB/nGg03D4skVyyPxY06IPpc1DnwZvFc24avdxAIjRK5/106j4n+/miy7/8qzzVsmaELr0kw4/p/M/uF+VOYHTXhBLN/l7GW2fGGSmb/+tuHmJ05ajezx3fYzuyPxwxg9vYTXZntPcSdLP2yY77/D/zSiS379+6ezJ5w6XfMLosUIqILSaNRr7aFsZZfpzUJfKw3llcwW0vswPcl49xF3QwSGgpl5+OGVsTjryVK1OXQ7PzeJjUcXku99sjvXSPqZAg9ASCy5fFr2Fgbw2xDCE1PKHRb8EcoqcGgEJogSyl/VjnVm8fri6v8gqUknZ+X6o7c901cFkHGGv9yoywvc1kKMzvZuR7upVMZzD46MorZUbm8T6v7cg2F0cVtdyQfc8zcRcktdELHxyYz23FcjHHR/jHFYxdjgHiVUNGV+6P9FK/ZYdtFzQLeaAAAAAAAAADCDiYaAAAAAAAAgLCDiQYAAAAAAAAg7DRJo6HcLlJaeDQBRfdeyWy3+sr3/5ZLeC7gZOL58gMQcbUdr+/M7NIMkVu4jH8HayLffu+9PG7WOfgqZie9voPZepUICGxJxHevX59BU4qovZRoCKFFKe4pXFnmnBeYHTyfPhl4rLVuEceL5nGTmpfHUmu1fM5e0pP7UNzXfHeondE4dMX9Wx30azY6duNaqt9fsZrZr5y4jtm2sbxORnEV76OXDlzP7CGJPFbXK3xi4w6um9jZOYnZrl08/tXQi+sDxozYxuxLIo/4/v/YPIAty9mQzuxjvWOYrVm4/7YrpAZO6ijq1ajRTfw6rEoUdROMYl9SgyH3LRHjkFYlAr5FXY2A9eXxRH0dFcXjuVnMtdhWyX23Zx8IRpD6EYYSfs0Zq2OYrZuD/9ZqrObjtKGK3zekRkOZRZ0UUTeDhP9pXr5/cwnXVukWrkUgdxO1se2UiCJ+LXitvB8ceXy5we33iVon73P7UX4f2VXA9XEmjWsw4vaced9ERKZaUfvEw5cb3aJWjhiSzIWyFgZf7ooUOrF6X91cKdsi6rTE821l25sLvNEAAAAAAAAAhB1MNAAAAAAAAABhBxMNAAAAAAAAQNhpkkbDM2wAkel0XnIZu2g6Wd7AFvUQcZTb5ixi9g0jJ9azfuGbmnnsqXKL+HoRq2pdu5XZnTsmMjvnNzwvcvR+vn3KM8eYXT6Q5zE+9NgAZqd9eJLZ3t28/c2K+O71Y/+Var86AEMEj2WuShL5yc3CFlNqu03U0RBXgtfGz2tUNK/R4LXy/PwGEZdZnYCc9meDIYrnKE+NOMXs7+ud1nIPj19+dM8kZucfDZ513lLIO720P/eZn0q55sIgLidzHI+nrjjJa35QJ+5j9h/4d1vr7sfszy29fP9Xn+T+bbJzf0yP5GPOtuQB/Ngn8qi9YLDwmGVlOrPOQhPjYWSeiLGP5Oc1AFnnQGouBJrUgkm9QECtCxFfLXUXIsbfU7+5Qs9BuoivDtHWCxJx/o2ivIysc+G1Cg2FOMeaVzyLSA1GCJSodSI1Hpqb97G5XNzf23N9nDDilvUk6tmeCL7MHc/HhEpRCmdzbm9mO5P4NSz7SOoihMSDjC6+PKKY3yfyr+X7d8dwO34X374sxe9DmnjOkfoP6f+eCL5Bc6m88EYDAAAAAAAAEHYw0QAAAAAAAACEHUw0AAAAAAAAAGGnSUGdh8YbyWA/HfR15xVcB/HeJl4Xw3aCB4eZRKmJ9OzpzO50sT86zDOQ70vGzyvZahGqWhMvYvCi+AqeOB5XW5TIl5f0TmF2REYps5Mclcz+uTPPu5y0IYsfz+pvj1HkLa7uwOd6Hh76H/BdjVwqQDoPX6aEH/z6FY+nhuh/P6b2iJbWldm6lQdCasam5YeWPqaJcOjYCH7iC808/l/Tuc95Re5r0DhU727Mthp28OUmf796dH7tlFbyk26olPHW/FjWIt5npSU8VvcXN3cKVwrXhk3u/T2z393Mxy1zscjtfoT7ZG0mjx8vO+7XcGiifojXwRtvM/C43qok/t3blfsJXUNATR3df7HWdOADqLmCj/Wqil/HWoQ4U2YxoEoNRYxDNIVHNRuKRIC3bKvUUbhEfZ5jBXxzQ5zfMMlaQaipEArl1YMvFxoLqcmQmg2psTDUihtFqPaI7Y1VQisoNBtGIUfV6mvYSvhzSahaU+0Jj42PCdUd+XJ5P2bnXQwnAbqcYm5HpPJrutTAtXZJXzEzoI9l3Qu3kPLVRnGtYdQuMfaLUiqVHcV9JLbe+kKaYnDL88CXmyua5r9nC95oAAAAAAAAAMIOJhoAAAAAAACAsIOJBgAAAAAAACDsNEmj0f3R78iknY5h/eiPQ9iyy0ftZXa/ISeY7VY87i2/1slsTy//nOd4ZTRbltXhILP/90QvZpuNPM6M75nIZOBxmpEmHvjoMPNYaYMI5o4x87heXQS6dbuU5/ov7MvjeG1GfxymLmKvpe0R56nWw7uouIbHFFfW8BjhygL/t/e6Wib+7nxQnczjJOWUWXmCxybK7Oe6SCBtENt3sFcwu1BsL7qRamO5DxkieWCmXsl1PuA0p8S1k2ItYvaAQft8/0ebeVLw2ipRbyFK1DjwcCeo5FIssjv4OHBJp+PMviPxG2Y/8sUUZpui+biiV3K9wKl+3ElsQmNSP65YCc3RlX33MbtGiLOq4/m40a40GgKthp9nVa+WhcwLH3lQXGeiJkeAJiPUsSu5z2lCw0GyxkcoTYaVDzzevHxm207647H1OD7maYfFd3NBsxGAqLklaxjoQqNhqhGaHENwDce5IuumGGpEfbIafjxXeoJ/3SNHw9qWtkREPu/Xyk58rDVJLavFfx69Zt6n5V35Ndr5az72dhvE7wM/ap2Zba7g9yw5BilR08MoSuu4o8R94aSonSKfXYTsyF5QT7cYKTREwt9rOgh/r2yZWmt4owEAAAAAAAAIO5hoAAAAAAAAAMIOJhoAAAAAAACAsNMkjUZ9Up7ZxOzSZ/jyzWYet+a++iJm13TgsbGVHf1zHheXaNBhEw+m1kWNBINXBMjLMEqx2CYC7C3lfANrKY/TtBXyoDqZ+1pzi7hOk6iNUeXfXpN5vWtFvHEtP5ZWXszsWLGcV3PgeFT7jdmtSOL+I8+rjK2VGgpdxMd7IrgPyDhIqQeQ9UtIE3GVFrEDUfeDftpDIJDIfB4zurUsjdm/FPljlAd0PMaWmW18W5dHCG/MwkfsfP1BXQ4ze3TsT8z+zTeTmD3iop/5+nE/Mvt3X9/ObEskv9YjrELT0ckfc1+TxzU9277qzWzDMH5sGXventCsIpG80EHUr4Uh88JrRSXMDlVXgXSxPFQND03ee0Isl/szCp2OnatrnLn16iKJfPsB6pILqI4CI9j3Tohnpig/I4dt0tyi/80i3l5qNhrVwMYjNUDmcj4O1Mb6e70967BCoYt+cfPHTTLy00iGesNCQG2ycm5XJvLxZWz8TmZLze6GyzKZbc8XtVjs8uGDm1KDITUbEmOt2H89zYl8bjFLGZd4tjbUijpDQY989uCNBgAAAAAAACDsYKIBAAAAAAAACDuYaAAAAAAAAADCzllrNEKhRP5q0/rvmC1C6gLs1kyIKF/QAtQkiFhZl9BkGGVsNDdlWK9u5R8Yq/j2GRFc2LNZliiRYZXCru7Kc+Bbefg/+A9eGz9xxS4eiVxe4B8phvTitSWGxfzC9yU6fXdVErP3lScwO8XO6+GUeCOY7djG2/KVoTuzq73BazJc0oVrSgY4eR58Y70A23934PvevTOV2yc7MluoUdoXQsdAonaFivXXDjKLvPB6Oa9/Y3CK+juy7oVLjO5uEdQfxX3Ca+d9biwSAd9VIqG/TehNhGZDufh903a4xPd/ZU+uNzDL8yL1JYDcSTwoXdalkHUxDB5+Dr3m8P4WK48ntQae5Bhmm6u4P1fV0+loJv74pjx83VDL2zKmcn5deq2ihpKJ30e89U6FR4hbTLKklejyMp1vkGQtYXZNIvcZ6yl+bDeX2QTU0ZBInYXE5eT7t5ScWVkhjy31IIZqcR6DH/qswRsNAAAAAAAAQNjBRAMAAAAAAAAQdjDRAAAAAAAAAISdZtNoANCcuKJFbK2bxy2KsErSRSi2EoU1dFH3wlTBN0i3FjA7II5ShEkaavgcvqQ7t3mEPaijPIkPSRXFPC7ddMq//KfKLmzZjqJkZheUcuWX9wC3lZl3WkFvvjzSwuPl7aO4D1T9wDUeuXG8qo0tlysntlVx3cU2RzdmJyaW+v5PcfL6ORKnjQf6FnXi/iXSpbdtZI0cUXvImxTn+98oYtr1Sh6AbYgRZ8bVxFpDQh9iqFJBlwfU0RBtlxoNg6gZolX6NR6uKL5upBSaXah1NILgjuDjSYBGwyvqH8k6GbKuhtD+BayvB+8Dg9yfQAnNhvl4KbNNzg7+ffXgNYa8P+fwfXmbK+L+/GMq4torSxkXI0gtAlsmngVkTSxdPBW7xQZJFj42awl8LFa/BK9wIp8dvEK2JdsXoKsQQ5Yn0u+Dpkruf6HqaHicNt62gNaGB7zRAAAAAAAAAIQdTDQAAAAAAAAAYQcTDQAAAAAAAEDYgUYDtElc8Tz+1FrAAxs9MTL2lm/v8YgPrCIO3MD3l2Aq4+vLYEah+ZDx0pXJiJ9uDDKGlNx8iLL18scsH6jowJblFfMaCbqX96EStVIspdwHSitEzQ4Dj1+tzec1FC4fwut2bN2dzuwIEUtrLuHHs3ThNRbyD/u1BrU/JrJl6jIe269pwr9FXG97IiD/v7A9UfW0MOIyM0mNRIh9a0IzQXbuA/K61qpFUnx5PKmbkMulbeEB43qJ3989tuDbtqc6CeHCFc0vDGuJ0NiIuhlSI0GhNBzygCE0GgH1nSTieHoM1x4Y3P7lrk58vDP+LA/Wfu85FX25ds/lFHWwavl5NtUbauWzgKy5Ud6d+0hv63FmF3qczO6fzJf/EpfBbE1IZWp40wM0G1KDIbeXdUDqb29wnXkZEZHtlPBnEz8Z0GgAAAAAAAAA2gyYaAAAAAAAAADCDkKnQJtAM/NUoZpdhDyInHSaSFcbkDJOl2kl+ftJTfEQhq4ydEogU6UGvO7s0MQ0mhcolqxTzL66y35mO001vv9XHerPlrmrRZ7CGt7pJpEC2R3J+6x/p3xmn6zmYQvHCvk7660/8VfkHVN42/PNPA7MepjnMYy21zC7xun3cYObt/2egV8ze7hjN7N/dXAmtVc0EU6kqvl581r817KpRlx4IUKXNJMp6PKAdLWyLWYx7nhEKJUxREybDMUS6W29J4v8q8qm2rk/1g+zAg0j08/KUKiA9Zua/lYg15ehWTIds1GkpPU4uL9ZC6t8/3sd/J54IVGezC+Gi67hYaw/HEtitqteGK0SXeYq4NecJbGK2V9V9GZ2mrWQby9y51cnixBGg8x9L1Nii/AlF/cZQzyPh9I9wqdq/ccX2WzJWMrPk0E0zV7EfYgHB4cPvNEAAAAAAAAAhB1MNAAAAAAAAABhBxMNAAAAAAAAQNiBRgO0CQzpKdw2i0BLmckvIC4y+OpGk4jFFsTIKbkM/ZZhmSKOUmpKDFH+1IR6eXnQY19IlP8Sy+x9zgRm39jxR9//nZ1cN1Pr4sNZLfH4U4+N97HxJF9uELkAe8UUMDuvmqec9Tr5/kYm7WX2sgNXMVvqdmJsPL1tnvJrOgzjitiyt38exOy/VQ9mtv2I0Ke0J6SOQuf9pFv915p1L9fJeAxSnCUuXLEvJWxNaDb0qBi+XKRH1WpEfklxvIB0uhbug6r0zFqwgAzaUTyiWhXw2PELFUPEmSPN9YD0skKrJzUXYv2Q6Wklcnuh2fBGcN+Wmg1DLR80dKt/fbfY1hoqtXI7IjKPn5e8Sp5y1l0i0lLX12yKezNF8D73FnHt06pcrgUsK+f+ZTgsjhUvrnGX0GCI4+vW4DofyuMaEk0OaTb/9uZivtAg9B61HXnb3PaWedeANxoAAAAAAACAsIOJBgAAAAAAACDsYKIBAAAAAAAACDvQaIA2QVV3HruvdB5rqIw8HtVoCh73aND4+hYLj/l0hZiCK7Fc00XcpUm0xyjiQPun+7fdvDP4wS4gjLxEAh39pBuzF17l94NLOh1nyxK7cq1LjJlrIKwiiXiZh8fW3pfwJbO/rOT50wdcf4TZwyK5JmNHTTKzO3fnMfMjr+brp1i4DuOf6jI6EyL9P5Wc4HHCejseyaVOQhn4xeexGuotE/HXenDtVcg49gger22o5vVwtFPBa1cot1hf6E2kJkOldeHH2+vXfNhPSW0K1+UE7LtW1PS4QDB0SjzjMttJPsC4nVwj47WK2jsVvP+MQjMhNRi6rJNRzcccXexfN4n4fXPwG099/za6pE6x/WoyJMZa/l0PH49jttQqaPVqXYQaKz1Ce+cVNbdMZt6ntTHCJ8SzgIrgy5XUiMj1HUKXU8G/i6zZRfWedbxCc+GJDK5l9diaqDk6S/BGAwAAAAAAABB2MNEAAAAAAAAAhB1MNAAAAAAAAABhpx1H9oL2RE2siFP0ijhGUUbAbBGxsbKuhsBq5rG4tSJXtVXjc3Ilc1nLsEs7P55eyy+1ihR/bHDU5qBNu6BwdXGLT3jHRtv8Meub92SwZYP77GP22l/6MVsv4JoMYxXvtJ8zOzE773tud7o0j9nDenHNxdNbbma2JZfnP3/XwWPH43pzjcbJIn9tFVsEr8dgt8r6DNx0xYTIxd6GUbXiuwvNhqnG/921yuqg65IYN5Q3xHlziwI5JnHhG4PX6dBsIse+PL6Lfzd3LNeEWKL99QE8Vv5dDC6hUzPgd0MiIt3hP+dGF+8PVyy/JgM0FyGQGiBNiKc0UYcjQDPkFXVVrLKmgtQWiPtIPU2HJ4Kva7by79aeNTr2E1XMNlplHSFu19dlSH2lN0rUV4ri96CyU5F8z2JsJqEPlXUzFJcBEZnkswi3TTYx5ghb1vyqr/+ssfKDSQVGTDQ/b/FLZeOaB4xMAAAAAAAAgLCDiQYAAAAAAAAg7GCiAQAAAAAAAAg70GiANsGpfiLaUIoiRNij28Vd2yBCqT0u/oFFxD0ahFTgk0peI0G3ijoZIhxWF6HZMld2weV+O2o5gTpEjnFPN5733mbyx6v2mcfrZpjf4H3Yr8sJZp+M47G2pyp4LYrECL6/oh58eZFY/67/91tmRwzjNRVq7SJe1su/m9vDfXBYzxzf/z8t6c+PPVTEBccLDcfP0uHaD5qNx557i4uZXdnJfx4jkhP4xie4roZErQnNLMVVIWoTSM1HqNoFQpMhj2+IiWa25eejfPP8At//tbHd+b48wfUeFyrK7PcHUxXvT4PQUEjNhIGCa3ZCaTSMos6K1861AgaPqIXiDa7xkNRvn+YRNTs6xDPbc4zXGWpPqG0/iU8uZZa1Nx+Lq3KddCYMNfw8eg3isVhoKtwVlqDLlUnW1RAH1IPXrtDFfULIQ8lVLXyq3vF1t9DtCD2JrAlC3/4YtC3hAm80AAAAAAAAAGEHEw0AAAAAAABA2MFEAwAAAAAAABB2oNEAbYLYn7ld0ZPH7rvTeWxsn84FzP6xLIXZcXEVzL4iMZfZK7vy2OkpUbzmwZNdeOyjquKxkR27nWJ2cTmP7484xOPOwWl63re10evKDPi5f7yc2f/ntQ+Y3c/C4/V/rE1ido3isa//SOcaj/+t5n14/ZVcmPNFNf/d5nDfOGYnmrgGJNXEtQYTv5/h+z/pb7y4Stzf6MJF1qoQuB3+mGZXNI+fNgtxlorgWhZN6BxI1OzQ43lsd/34fyIiQwhNh1YdvJaBiuK6ISopb3hFIqrsImoqRAldjh5CL3KBUJMYEXql/yDrVkgNRUCdDHmOvU0756E0HrI9koDj19+3U/jSsSY1rU3T83leH2Lfk/z+Gtfdfz8urxK1VIy8z2uqhLZO/BxvMPIxw27jzx52i6wFFRypm6hx88dyXWg6XLX8PhXl8NcOssTythUU8vEr+fESZouKHc0G3mgAAAAAAAAAwg4mGgAAAAAAAICwg4kGAAAAAAAAIOxAowHaBDF/FzHrH0Ux2315D2YXdu7GbOOloj7D5x2Yvd7E7Y4neNzmDc/exmzTr3kcZ9Qh3t7KA4nM7r6C5zT3HPiBQHgxf7aN2W/0TGO2KXUosysu7szs8mQeH/3/rNxnvEJW81A8j5d27ufL7Se5D0Xt5bnd9Z/2MDuJdhMIxHM0eLB50qv+flfu4LUk1GGxL4vIiS/0IIZyvlxZeXw0lXGtlyb3J+po6GVcg6Gqq7ntOXPUdI/5B5jtyec6tJA1PS4QIg6VnHGZ7D/d1rRHII9NaCiE7Y0QdVpknYyAuhu8v3UT/+3XXMz9Q6un4bGa+bFUOffFCwnvrr3MTpvM+6XyVr9+z9OJLyvtKdV+HN3C+8xr4du7haajsoj7mLmC30cMcogKXlaDdDHkKCe/r1RW2f3rFvKd9Xh1E7NbSpMhwRsNAAAAAAAAQNjBRAMAAAAAAAAQdhr13lD955Wsh9xEeDvbZvDQ6TRrqhleqZ9vnzAo/v7R4+Hpbr1u/npRrxFhMLXcVuLtqdze4+VpKvUacTzxOlTu36Pz7T2qaSnwwkV79omQyD5wyz4UYRDinbZ8wa7XiFfqwgc8oXzoPPmApK37hKb8/aRCnFOD4r+tabJNivuAJnxGeUU6W513ekD6UV2ExohxS7ZXqSDBDeJYAWNIGPuvuXyiJfxBec+cUlj2nx4kVK0hPO7gjTbIdLghQqdkqJwufvvVxHdh/qjzEUkJ//CGcXxpc2OEEmNvvbFejvN6dfDQKSVTGMsxQKDV8P15xbNHQLeECp0SzdMtIgVzvf0HPHc04z2mKT6hqUasdfToUerateu5twycF44cOULJyclh3Sd8om0DnwAS+ASQhNsn4A9tG4wRQNIYn2jUREPXdTp+/DhFRUWRpoWYfoFWg1KKysvLKSkpiQyG8EbJwSfaJvAJIIFPAElz+QT8oW2CMQJImuITjZpoAAAAAAAAAEBTgBgcAAAAAAAAEHYw0QAAAAAAAACEHUw0Gsmbb75JmqbRoUOHmrzttGnTqFu3bmFvEwAgPGiaRg8++GDI9c5lHABtC/jEhcOhQ4dI0zR6+eWXQ6779NNPQ0sAQBNo1RONH3/8kSZMmECpqalks9moS5cudN1119GCBQvOd9NAK6HuJl/3Z7PZKCkpiUaPHk2vvvoqlZeXh94JaNecz3Hk+eefp3/961/NfhzQNOATbYv6Y3ywvy+++OJ8N5VRVVVFTz/9dNB2FRcXk8lkovfff5+I4B+tFfmsoWkaJSYm0vDhw2nt2rXnu3mtmkbV0TgfbNq0iYYPH04pKSl07733UqdOnejIkSO0ZcsWmj9/Pj300EPnu4mgFfHMM89QWloaud1uysvLoy+++IIeffRRmjdvHq1cuZIuvvji891EcB4I9zhy11130R133EFWq7VR6z///PM0YcIEuuWWW86i9aA5gE+0Pd5++21m//3vf6fs7OyAz/v06dPsbfnv//5vevzxxxu1blVVFc2ZM4eIiK655poG11m3bh1pmkajRo0iIvhHa6fuWUMpRfn5+fTmm2/SDTfcQKtWraKxY8ee7+a1SlrtROO5556j6Oho2rp1K8XExLBlBQUF56dRoNUyZswYuvzyy332E088QevXr6exY8fSuHHj6Oeffya73d7gtpWVlRQZGdlSTQUtSLjHEaPRSEajMeg6Simqqak5o7+B8wt8ou3xq1/9itlbtmyh7OzsgM9bApPJRCZT8EcnXdfJ5XIFXaeONWvW0ODBgwN8EbRO5LPGPffcQx07dqR//OMfmGicgVYbOrV//37q169fgxdfYmKi7/+lS5fSiBEjKDExkaxWK/Xt25cWLVoUsE23bt1o7Nix9PXXX9OgQYPIZrNReno6/f3vfw9Yd9euXTRixAiy2+2UnJxMzz77LOl6YDXIjz/+mG688UZKSkoiq9VKGRkZNHfuXPJ6g1eaBC3DiBEj6Mknn6Tc3Fx65513iOi0XsbhcND+/fvphhtuoKioKJoyZQoRnb45vPLKK9SvXz+y2WzUsWNHmjlzJhUXF7P9btu2jUaPHk0dOnQgu91OaWlpNH36dLbOe++9R5mZmRQVFUVOp5Muuugimj9/fst8ceCjseNIHf/617+of//+ZLVaqV+/fvTpp5+y5Q3F49eNLevWraPLL7+c7HY7LV68mDRNo8rKSnrrrbd8r9qnTZsW5m8Imgp84sKjMWN2HUuWLKGMjAyyWq00cOBA2rp1K1vekEajTs/z7rvvUr9+/chqtdJf//pXSkhIICKiOXPm+Pr76aef9m2n6zp9+umndOONN/r2E8w/vv/+exozZgw5nU5yOBx07bXX0pYtW1hb6vzxq6++opkzZ1J8fDw5nU66++67A+5l4NyJiYkhu93OJp8vv/wyXXXVVRQfH092u50yMzPpww8/DNi2urqaHn74YerQoQNFRUXRuHHj6NixYwF+0tZptW80UlNTafPmzfTTTz9R//79z7jeokWLqF+/fjRu3DgymUy0atUqmjVrFum6Tg888ABbd9++fTRhwgS65557aOrUqfS3v/2Npk2bRpmZmdSvXz8iIsrLy6Phw4eTx+Ohxx9/nCIjI2nJkiUN/hL15ptvksPhoN/+9rfkcDho/fr19Mc//pHKysropZdeCu8JAWfFXXfdRb///e/ps88+o3vvvZeIiDweD40ePZqGDBlCL7/8MkVERBAR0cyZM+nNN9+kX//61/Twww/TwYMH6bXXXqPvv/+eNm7cSGazmQoKCmjUqFGUkJBAjz/+OMXExNChQ4doxYoVvmNmZ2fTnXfeSddeey396U9/IiKin3/+mTZu3EiPPPJIy5+EC5jGjiNERF9//TWtWLGCZs2aRVFRUfTqq6/SbbfdRocPH6b4+Pig2+7du5fuvPNOmjlzJt17773Uq1cvevvtt2nGjBk0aNAguu+++4iIKCMjI2zfDZwd8IkLi8aM2XUsW7aMysvLaebMmaRpGr344ot066230oEDB8hsNgc9zvr16+n999+nBx98kDp06ECXXHIJLVq0iO6//34aP3483XrrrURELIx369atVFhYSDfccAMRUVD/2LVrF1199dXkdDpp9uzZZDabafHixXTNNdfQl19+SVdccQVrz4MPPkgxMTH09NNP0969e2nRokWUm5tLX3zxBcTs50BpaSmdPHmSlFJUUFBACxYsoIqKCvZ2bf78+TRu3DiaMmUKuVwueu+99+j222+nTz75xDepJDr9w+f7779Pd911F2VlZdGXX37JlrcbVCvls88+U0ajURmNRnXllVeq2bNnq3Xr1imXy8XWq6qqCth29OjRKj09nX2WmpqqiEh99dVXvs8KCgqU1WpV//Vf/+X77NFHH1VEpL755hu2XnR0tCIidfDgwaDHnjlzpoqIiFA1NTW+z6ZOnapSU1Mb/d1B41m6dKkiIrV169YzrhMdHa0uvfRSpdTpviAi9fjjj7N1/v3vfysiUu+++y77/NNPP2Wff/TRRyGP98gjjyin06k8Hs/Zfi0QJho7jhCRslgsat++fb7Pdu7cqYhILViwwPdZnb/VHwfqxpZPP/004PiRkZFq6tSpYf9e4OyBT7R9HnjgAdXYx5fGjNkHDx5URKTi4+PVqVOnfJ9//PHHiojUqlWrfJ899dRTAccmImUwGNSuXbvY54WFhYqI1FNPPdXgcZ988smAZ4Mz+cctt9yiLBaL2r9/v++z48ePq6ioKDV06FDfZ3X+mJmZyXz6xRdfVESkPv744zOeB3Bm6s6r/LNarerNN99k68pnQ5fLpfr3769GjBjh++y7775TRKQeffRRtu60adOC+kxbpNWGTl133XW0efNmGjduHO3cuZNefPFFGj16NHXp0oVWrlzpW6/+m4a6meawYcPowIEDVFpayvbZt29fuvrqq312QkIC9erViw4cOOD7bM2aNZSVlUWDBg1i69WF19Sn/rHLy8vp5MmTdPXVV1NVVRXt2bPn3E4ACBsOhyMg+9T999/P7A8++ICio6Ppuuuuo5MnT/r+MjMzyeFw0IYNG4iIfOEWn3zyCbnd7gaPFxMTQ5WVlZSdnR3+LwOaRGPHESKikSNHsl+XL774YnI6nWx8OBNpaWk0evTosLcfhB/4xIVFY8bsOiZNmkSxsbE+u+55oTH9PWzYMOrbt2+T2rZmzZpG/YLt9Xrps88+o1tuuYXS09N9n3fu3JkmT55MX3/9NZWVlbFt7rvvPvYW5v777yeTyURr1qxpUhsB5y9/+QtlZ2dTdnY2vfPOOzR8+HCaMWMGe0NW/9mwuLiYSktL6eqrr6bt27f7Pq8LwZw1axbbf3tMdNRqJxpERAMHDqQVK1ZQcXExffvtt/TEE09QeXk5TZgwgXbv3k1ERBs3bqSRI0dSZGQkxcTEUEJCAv3+978nIgqYaKSkpAQcIzY2lsUt5ubmUo8ePQLW69WrV8Bnu3btovHjx1N0dDQ5nU5KSEjwvT6Txwbnj4qKCoqKivLZJpOJkpOT2To5OTlUWlpKiYmJlJCQwP4qKip8ItFhw4bRbbfdRnPmzKEOHTrQzTffTEuXLqXa2lrfvmbNmkU9e/akMWPGUHJyMk2fPj0grhu0HI0ZR4gaNz6cibS0tLC2GTQv8In2R0VFBeXl5fn+CgsLiahxY3Ydsr/rJh3N0d95eXm0ffv2Rk00CgsLqaqqqsHnkD59+pCu63TkyBH2uXyOcTgc1LlzZ9R7OUcGDRpEI0eOpJEjR9KUKVNo9erV1LdvX3rwwQd9CQA++eQTysrKIpvNRnFxcZSQkECLFi1iz4W5ublkMBgC/KZ79+4t+n1aglY90ajDYrHQwIED6fnnn6dFixaR2+2mDz74gPbv30/XXnstnTx5kubNm0erV6+m7Oxs+s1vfkNEFCDgPlNmEKVUk9tUUlJCw4YNo507d9IzzzxDq1atouzsbF9MfkPicdDyHD16lEpLS9nFa7VayWDgrq/rOiUmJvp+qZB/zzzzDBGdFut9+OGHtHnzZnrwwQfp2LFjNH36dMrMzKSKigoiOi0o3bFjB61cuZLGjRtHGzZsoDFjxtDUqVNb7ouDAM40jtRxLuMDsgm1TeAT7YeXX36ZOnfu7PsbOHAgETVuzK6jJft77dq1ZLPZaPjw4U3aDrQuDAYDDR8+nE6cOEE5OTn073//m8aNG0c2m40WLlxIa9asoezsbJo8efJZPWu2B1qtGPxM1KUVO3HiBK1atYpqa2tp5cqV7JeIujCXsyE1NZVycnICPt+7dy+zv/jiCyoqKqIVK1bQ0KFDfZ8fPHjwrI8Nwk9dnvVQIQwZGRn0+eef0+DBgxt1w8jKyqKsrCx67rnnaNmyZTRlyhR67733aMaMGUR0+gHmpptuoptuuol0XadZs2bR4sWL6cknn2yXv1i0NeqPI80JRJdtB/hE2+buu++mIUOG+Gw5jocas5uDYH29evVqGj58eEA7G9omISGBIiIiAp5DiIj27NlDBoOBunbtyj7Pyclhk5iKigo6ceKET3gOwofH4yGi0+f4n//8J9lsNlq3bh2rrbN06VK2TWpqKum6TgcPHmRvn/bt29cyjW5BWu0bjQ0bNjQ4+6uLL+zVq5fv14f665WWlgZ0aFO44YYbaMuWLfTtt9/6PissLKR3332XrdfQsV0uFy1cuPCsjw3Cy/r162nu3LmUlpbWoMamPhMnTiSv10tz584NWObxeKikpISITr9Cl345YMAAIiLfq/iioiK23GAw+DKNNPS6HjQfjRlHmpPIyEif74DWAXyifZKenu4LaRk5ciQNHjyYiBo3ZjcXdRkNZX+73W7Kzs5uMGyqIf8wGo00atQo+vjjj1noU35+Pi1btoyGDBlCTqeTbbNkyRKmSVm0aBF5PB4aM2bMuX0pwHC73fTZZ5+RxWKhPn36kNFoJE3TWJmDQ4cOBVR7r/vxUz4zLliwoNnb3NK02jcaDz30EFVVVdH48eOpd+/e5HK5aNOmTbR8+XLq1q0b/frXv6b8/HzfL8czZ86kiooKev311ykxMfGsf5WaPXs2vf3223T99dfTI4884ktvm5qaSj/88INvvauuuopiY2Np6tSp9PDDD5OmafT2229fsK/Gzjdr166lPXv2kMfjofz8fFq/fj1lZ2dTamoqrVy5kmw2W9Dthw0bRjNnzqQXXniBduzYQaNGjSKz2Uw5OTn0wQcf0Pz582nChAn01ltv0cKFC2n8+PGUkZFB5eXl9Prrr5PT6fT9UjRjxgw6deoUjRgxgpKTkyk3N5cWLFhAAwYMaJHKtcBPY8aR5iQzM5M+//xzmjdvHiUlJVFaWlpAGkrQssAnLiwaM2Y3F3a7nfr27UvLly+nnj17UlxcHPXv358KCwuprKyswYnGmfzj2WefpezsbBoyZAjNmjWLTCYTLV68mGpra+nFF18M2I/L5aJrr72WJk6cSHv37qWFCxfSkCFDaNy4cc36nds7dc8aRKdTJy9btoxycnLo8ccfJ6fTSTfeeCPNmzePrr/+epo8eTIVFBTQX/7yF+revTt7hszMzKTbbruNXnnlFSoqKvKlt/3ll1+IqJ29+Twvua4awdq1a9X06dNV7969lcPhUBaLRXXv3l099NBDKj8/37feypUr1cUXX6xsNpvq1q2b+tOf/qT+9re/NZhu8MYbbww4zrBhw9SwYcPYZz/88IMaNmyYstlsqkuXLmru3LnqjTfeCNjnxo0bVVZWlrLb7SopKcmXJpGI1IYNG3zrIb1t8yFTzlksFtWpUyd13XXXqfnz56uysjK2/tSpU1VkZOQZ97dkyRKVmZmp7Ha7ioqKUhdddJGaPXu2On78uFJKqe3bt6s777xTpaSkKKvVqhITE9XYsWPVtm3bfPv48MMP1ahRo1RiYqKyWCwqJSVFzZw5U504caJ5TgI4I40dR4hIPfDAAwHbp6amslSTZ0pl2tDYopRSe/bsUUOHDlV2u10REdKatgLgE22fpqS3bcyYXZfe9qWXXgrYnkSq0TOlt23IV5RSatOmTSozM1NZLBbfvh577DHVt2/fBtcP5h/bt29Xo0ePVg6HQ0VERKjhw4erTZs2se3r/PHLL79U9913n4qNjVUOh0NNmTJFFRUVhTpd4Aw0lN7WZrOpAQMGqEWLFild133rvvHGG6pHjx7KarWq3r17q6VLlzboN5WVleqBBx5QcXFxyuFwqFtuuUXt3btXEZH6n//5n5b+is2GphR+ggcAAAAAaAn69u1LY8eObfBNxLlSV3R269atPt0RaDvs2LGDLr30UnrnnXdChny3FVpt6BQAAAAAQHvC5XLRpEmTaOLEiee7KeA8U11dHZAM4JVXXiGDwcCSDLV1MNEAAAAAAGgBLBYLPfXUU+e7GaAV8OKLL9J3331Hw4cPJ5PJRGvXrqW1a9fSfffdF5BFrC2DiQYAAAAAAAAtyFVXXUXZ2dk0d+5cqqiooJSUFHr66afpD3/4w/luWliBRgMAAAAAAAAQdlptHQ0AAAAAAABA2wUTDQAAAAAAAEDYwUQDAAAAAAAAEHYw0QAAAAAAAACEHUw0AAAAAAAAAGEHEw0AAAAAAABA2MFEAwAAAAAAABB2MNEAAAAAAAAAhB1MNAAAAAAAAABh5/8DWtwYxL8LGqUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(36):\n",
    "    plt.subplot(6, 6, i + 1)\n",
    "    plt.xticks([]) # making the x and y axis invisible\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i].reshape((28,28)))\n",
    "    label_index = np.argmax(y_train[i])\n",
    "    plt.title(labels[label_index],y=-0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.7380 - loss: 0.7730 - val_accuracy: 0.8278 - val_loss: 0.4741\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.4037 - val_accuracy: 0.8534 - val_loss: 0.4103\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.3558 - val_accuracy: 0.8622 - val_loss: 0.3862\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3322 - val_accuracy: 0.8651 - val_loss: 0.3752\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.3114 - val_accuracy: 0.8718 - val_loss: 0.3547\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2873 - val_accuracy: 0.8768 - val_loss: 0.3505\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2817 - val_accuracy: 0.8806 - val_loss: 0.3320\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.2625 - val_accuracy: 0.8753 - val_loss: 0.3532\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2516 - val_accuracy: 0.8810 - val_loss: 0.3342\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2491 - val_accuracy: 0.8749 - val_loss: 0.3560\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8749 - loss: 0.3560\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_mlp_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 output classes\n",
    "])\n",
    "# fashion_mnist_mlp_model.summary()\n",
    "fashion_mnist_mlp_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "history = fashion_mnist_mlp_model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "test_loss, test_acc = fashion_mnist_mlp_model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN of the fashion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 10, lenght: 28, width: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = (28, 28, 1)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_fashion_mnist_data()\n",
    "X_train = X_train.reshape(X_train.shape[0],*image_shape) # revert to the original shape\n",
    "X_test = X_test.reshape(X_test.shape[0],*image_shape)\n",
    "X_val = X_val.reshape(X_val.shape[0],*image_shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7179 - loss: 0.8059 - val_accuracy: 0.8525 - val_loss: 0.4096\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3857 - val_accuracy: 0.8778 - val_loss: 0.3427\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.3328 - val_accuracy: 0.8792 - val_loss: 0.3348\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.3057 - val_accuracy: 0.9003 - val_loss: 0.2889\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2876 - val_accuracy: 0.8957 - val_loss: 0.2887\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2640 - val_accuracy: 0.9027 - val_loss: 0.2713\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2625 - val_accuracy: 0.9043 - val_loss: 0.2705\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2447 - val_accuracy: 0.9023 - val_loss: 0.2673\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2339 - val_accuracy: 0.9082 - val_loss: 0.2578\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2211 - val_accuracy: 0.9095 - val_loss: 0.2551\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9037 - loss: 0.2697\n",
      "Test accuracy: 0.9036999940872192\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_model_fashion_mnist = Sequential([\n",
    "    Input(shape=image_shape),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu'),\n",
    "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(num_classes,activation = 'softmax')\n",
    "])\n",
    "cnn_model_fashion_mnist.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "# TODO check difference (loss='categorical_crossentropy', and sparse_categorical_crossentropy)\n",
    "# from https://www.kaggle.com/code/pavansanagapati/a-simple-cnn-model-beginner-guide#Define-the-model\n",
    "history = cnn_model_fashion_mnist.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    ")\n",
    "test_loss, test_acc = cnn_model_fashion_mnist.evaluate(X_test, y_test, verbose=2)\t\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "cnn_model_fashion_mnist.save('cnn_model_fahsion_mnist.keras')\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_data():\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    num_classes = np.unique(y_train).__len__()\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    return X_train, y_train, X_test, y_test, num_classes\n",
    "X_train, y_train, X_test, y_test, num_classes = load_cifar10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.3169 - loss: 8.4372 - val_accuracy: 0.4871 - val_loss: 1.4780\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5608 - loss: 1.2400 - val_accuracy: 0.5964 - val_loss: 1.1500\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6423 - loss: 1.0164 - val_accuracy: 0.6344 - val_loss: 1.0695\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.8948 - val_accuracy: 0.6508 - val_loss: 1.0290\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.7883 - val_accuracy: 0.6808 - val_loss: 0.9375\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.7090 - val_accuracy: 0.6746 - val_loss: 0.9752\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.6493 - val_accuracy: 0.6816 - val_loss: 0.9600\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5944 - val_accuracy: 0.6930 - val_loss: 0.9678\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.5244 - val_accuracy: 0.6779 - val_loss: 1.0611\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.4930 - val_accuracy: 0.6932 - val_loss: 1.0218\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_model_cifar10 = Sequential([\n",
    "    Input(shape=X_train[0].shape), # image shape is (32, 32, 3)\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "cnn_model_cifar10.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "history = cnn_model_cifar10.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "# cnn_model_cifar10.summary()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_small(shape,activation='relu', optimizer='adam', \n",
    "                 regularization=None, dropout_rate=0.0, architectures=[32,32]):\n",
    "    model = Sequential([\n",
    "        Input(shape=shape),\n",
    "        Conv2D(filters=architectures[0],kernel_size=3,activation=activation,kernel_regularizer=regularization),\n",
    "        MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
    "        Dropout(dropout_rate),\n",
    "        Flatten(),\n",
    "        Dense(architectures[1],activation=activation),\n",
    "        Dense(num_classes,activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer=optimizer,metrics =['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializations = ['he_normal', 'glorot_uniform']\n",
    "activations = ['relu', 'tanh']\n",
    "optimizers = ['adam', 'sgd']\n",
    "regularizations = [None, l2(0.01), l1(0.01)]\n",
    "dropout_rates = [0.0, 0.25]\n",
    "architectures = [[32,32], [64,64], [128,128]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 10, lenght: 28, width: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = (28, 28, 1)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_fashion_mnist_data()\n",
    "X_train = X_train.reshape(X_train.shape[0],*image_shape) # revert to the original shape\n",
    "X_test = X_test.reshape(X_test.shape[0],*image_shape)\n",
    "X_val = X_val.reshape(X_val.shape[0],*image_shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 0.8141 - val_accuracy: 0.8645 - val_loss: 0.3863\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3685 - val_accuracy: 0.8833 - val_loss: 0.3368\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3203 - val_accuracy: 0.8978 - val_loss: 0.2986\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2799 - val_accuracy: 0.8957 - val_loss: 0.2933\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2644 - val_accuracy: 0.9018 - val_loss: 0.2750\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2398 - val_accuracy: 0.8953 - val_loss: 0.2800\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2229 - val_accuracy: 0.9018 - val_loss: 0.2732\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2131 - val_accuracy: 0.9063 - val_loss: 0.2627\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.2017 - val_accuracy: 0.9027 - val_loss: 0.2690\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.1863 - val_accuracy: 0.9015 - val_loss: 0.2657\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8986 - loss: 0.2781\n",
      "\n",
      "Test accuracy: 0.8985999822616577\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.7967 - val_accuracy: 0.8640 - val_loss: 0.3818\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.3633 - val_accuracy: 0.8877 - val_loss: 0.3236\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3211 - val_accuracy: 0.8875 - val_loss: 0.3077\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2883 - val_accuracy: 0.8995 - val_loss: 0.2814\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2725 - val_accuracy: 0.9052 - val_loss: 0.2752\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2447 - val_accuracy: 0.9037 - val_loss: 0.2683\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2381 - val_accuracy: 0.9075 - val_loss: 0.2657\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2307 - val_accuracy: 0.9012 - val_loss: 0.2732\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2264 - val_accuracy: 0.9088 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2139 - val_accuracy: 0.9117 - val_loss: 0.2478\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9076 - loss: 0.2574\n",
      "\n",
      "Test accuracy: 0.9075999855995178\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.8134 - val_accuracy: 0.8632 - val_loss: 0.4173\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.4009 - val_accuracy: 0.8815 - val_loss: 0.3636\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.3502 - val_accuracy: 0.8850 - val_loss: 0.3511\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.3321 - val_accuracy: 0.8858 - val_loss: 0.3425\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3122 - val_accuracy: 0.8948 - val_loss: 0.3273\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2968 - val_accuracy: 0.8923 - val_loss: 0.3232\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2923 - val_accuracy: 0.8962 - val_loss: 0.3138\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2738 - val_accuracy: 0.9033 - val_loss: 0.2998\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2699 - val_accuracy: 0.8998 - val_loss: 0.3007\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2556 - val_accuracy: 0.8973 - val_loss: 0.3118\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8882 - loss: 0.3241\n",
      "\n",
      "Test accuracy: 0.8881999850273132\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.8087 - val_accuracy: 0.8607 - val_loss: 0.4173\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.4103 - val_accuracy: 0.8633 - val_loss: 0.4019\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3567 - val_accuracy: 0.8882 - val_loss: 0.3378\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3320 - val_accuracy: 0.8915 - val_loss: 0.3371\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.3085 - val_accuracy: 0.8978 - val_loss: 0.3125\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2951 - val_accuracy: 0.8940 - val_loss: 0.3175\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2809 - val_accuracy: 0.9068 - val_loss: 0.2973\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2791 - val_accuracy: 0.8978 - val_loss: 0.2992\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2683 - val_accuracy: 0.9078 - val_loss: 0.2824\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2625 - val_accuracy: 0.9058 - val_loss: 0.2840\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9009 - loss: 0.3018\n",
      "\n",
      "Test accuracy: 0.9009000062942505\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.9870 - val_accuracy: 0.8467 - val_loss: 0.5382\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.5171 - val_accuracy: 0.8662 - val_loss: 0.4670\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.4497 - val_accuracy: 0.8773 - val_loss: 0.4298\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.4199 - val_accuracy: 0.8777 - val_loss: 0.4090\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3906 - val_accuracy: 0.8800 - val_loss: 0.3917\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3713 - val_accuracy: 0.8853 - val_loss: 0.3807\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3603 - val_accuracy: 0.8882 - val_loss: 0.3691\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3490 - val_accuracy: 0.8910 - val_loss: 0.3566\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3398 - val_accuracy: 0.8920 - val_loss: 0.3582\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.3298 - val_accuracy: 0.8948 - val_loss: 0.3528\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8884 - loss: 0.3660\n",
      "\n",
      "Test accuracy: 0.8884000182151794\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7294 - loss: 0.9659 - val_accuracy: 0.8467 - val_loss: 0.5425\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8544 - loss: 0.5266 - val_accuracy: 0.8672 - val_loss: 0.4653\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.4609 - val_accuracy: 0.8680 - val_loss: 0.4581\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.4319 - val_accuracy: 0.8850 - val_loss: 0.4114\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.4070 - val_accuracy: 0.8883 - val_loss: 0.3953\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3953 - val_accuracy: 0.8903 - val_loss: 0.3853\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3797 - val_accuracy: 0.8818 - val_loss: 0.3830\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3704 - val_accuracy: 0.8877 - val_loss: 0.3748\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.3600 - val_accuracy: 0.8935 - val_loss: 0.3625\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.3595 - val_accuracy: 0.8972 - val_loss: 0.3543\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8878 - loss: 0.3692\n",
      "\n",
      "Test accuracy: 0.8877999782562256\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 1.4838 - val_accuracy: 0.7635 - val_loss: 0.6603\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7724 - loss: 0.6506 - val_accuracy: 0.7868 - val_loss: 0.5809\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 0.5742 - val_accuracy: 0.8130 - val_loss: 0.5146\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.5258 - val_accuracy: 0.8167 - val_loss: 0.5158\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.5082 - val_accuracy: 0.8222 - val_loss: 0.4857\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4838 - val_accuracy: 0.7867 - val_loss: 0.5489\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.4779 - val_accuracy: 0.8345 - val_loss: 0.4654\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4625 - val_accuracy: 0.8085 - val_loss: 0.5074\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4600 - val_accuracy: 0.8383 - val_loss: 0.4503\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.4412 - val_accuracy: 0.8458 - val_loss: 0.4338\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8377 - loss: 0.4580\n",
      "\n",
      "Test accuracy: 0.8377000093460083\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3695 - loss: 1.7823 - val_accuracy: 0.7458 - val_loss: 0.7010\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.7063 - val_accuracy: 0.7950 - val_loss: 0.5953\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.6189 - val_accuracy: 0.8062 - val_loss: 0.5458\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.5816 - val_accuracy: 0.8163 - val_loss: 0.5184\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.5436 - val_accuracy: 0.8222 - val_loss: 0.4947\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.5280 - val_accuracy: 0.8303 - val_loss: 0.4773\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5059 - val_accuracy: 0.8322 - val_loss: 0.4683\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4915 - val_accuracy: 0.8223 - val_loss: 0.4757\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4772 - val_accuracy: 0.8428 - val_loss: 0.4401\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4686 - val_accuracy: 0.8435 - val_loss: 0.4370\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8350 - loss: 0.4598\n",
      "\n",
      "Test accuracy: 0.8349999785423279\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4739 - loss: 1.7387 - val_accuracy: 0.7585 - val_loss: 0.7226\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.7029 - val_accuracy: 0.7992 - val_loss: 0.6017\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.6141 - val_accuracy: 0.8092 - val_loss: 0.5747\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.5780 - val_accuracy: 0.8252 - val_loss: 0.5355\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.5490 - val_accuracy: 0.8255 - val_loss: 0.5274\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.5301 - val_accuracy: 0.8343 - val_loss: 0.5061\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.5166 - val_accuracy: 0.8355 - val_loss: 0.4984\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.5042 - val_accuracy: 0.8432 - val_loss: 0.4883\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.4875 - val_accuracy: 0.8440 - val_loss: 0.4801\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4800 - val_accuracy: 0.8452 - val_loss: 0.4733\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8358 - loss: 0.4969\n",
      "\n",
      "Test accuracy: 0.8357999920845032\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5079 - loss: 1.5763 - val_accuracy: 0.7225 - val_loss: 0.7785\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.7257 - val_accuracy: 0.7913 - val_loss: 0.6122\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.6417 - val_accuracy: 0.8082 - val_loss: 0.5719\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.6052 - val_accuracy: 0.8088 - val_loss: 0.5594\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.5836 - val_accuracy: 0.8228 - val_loss: 0.5352\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.5645 - val_accuracy: 0.8262 - val_loss: 0.5180\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5474 - val_accuracy: 0.8250 - val_loss: 0.5278\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.5380 - val_accuracy: 0.8342 - val_loss: 0.5026\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.5267 - val_accuracy: 0.8365 - val_loss: 0.4892\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.5171 - val_accuracy: 0.8380 - val_loss: 0.4823\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8310 - loss: 0.5065\n",
      "\n",
      "Test accuracy: 0.8309999704360962\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3694 - loss: 1.9556 - val_accuracy: 0.7578 - val_loss: 0.9217\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7557 - loss: 0.8926 - val_accuracy: 0.7870 - val_loss: 0.7548\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.7527 - val_accuracy: 0.7995 - val_loss: 0.6886\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.6863 - val_accuracy: 0.8008 - val_loss: 0.6560\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.6512 - val_accuracy: 0.8083 - val_loss: 0.6309\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.6342 - val_accuracy: 0.8197 - val_loss: 0.6023\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.6098 - val_accuracy: 0.8217 - val_loss: 0.5895\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.5916 - val_accuracy: 0.8217 - val_loss: 0.5860\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.5804 - val_accuracy: 0.8277 - val_loss: 0.5636\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.5675 - val_accuracy: 0.8303 - val_loss: 0.5587\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8225 - loss: 0.5836\n",
      "\n",
      "Test accuracy: 0.8224999904632568\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4021 - loss: 1.8894 - val_accuracy: 0.7427 - val_loss: 0.9238\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.9231 - val_accuracy: 0.7755 - val_loss: 0.7690\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.7996 - val_accuracy: 0.7883 - val_loss: 0.7085\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.7339 - val_accuracy: 0.7955 - val_loss: 0.6698\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.7050 - val_accuracy: 0.8003 - val_loss: 0.6436\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.6806 - val_accuracy: 0.8098 - val_loss: 0.6279\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.6661 - val_accuracy: 0.8003 - val_loss: 0.6307\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.6509 - val_accuracy: 0.8157 - val_loss: 0.6007\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.6415 - val_accuracy: 0.8118 - val_loss: 0.6008\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.6294 - val_accuracy: 0.8208 - val_loss: 0.5800\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8109 - loss: 0.6091\n",
      "\n",
      "Test accuracy: 0.8108999729156494\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7675 - loss: 0.7270 - val_accuracy: 0.8640 - val_loss: 0.3828\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3648 - val_accuracy: 0.8828 - val_loss: 0.3344\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.3120 - val_accuracy: 0.8903 - val_loss: 0.3065\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2750 - val_accuracy: 0.8962 - val_loss: 0.3012\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2528 - val_accuracy: 0.8993 - val_loss: 0.2870\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2338 - val_accuracy: 0.9008 - val_loss: 0.2755\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2175 - val_accuracy: 0.9033 - val_loss: 0.2722\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.1930 - val_accuracy: 0.8988 - val_loss: 0.2836\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.1847 - val_accuracy: 0.9067 - val_loss: 0.2686\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.1738 - val_accuracy: 0.9072 - val_loss: 0.2633\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8996 - loss: 0.2796\n",
      "\n",
      "Test accuracy: 0.8996000289916992\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7545 - loss: 0.7250 - val_accuracy: 0.8633 - val_loss: 0.3878\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3689 - val_accuracy: 0.8765 - val_loss: 0.3442\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3167 - val_accuracy: 0.8903 - val_loss: 0.3084\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2896 - val_accuracy: 0.8943 - val_loss: 0.2971\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2744 - val_accuracy: 0.8968 - val_loss: 0.2843\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2565 - val_accuracy: 0.9003 - val_loss: 0.2815\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2377 - val_accuracy: 0.9007 - val_loss: 0.2744\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2256 - val_accuracy: 0.8997 - val_loss: 0.2799\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2155 - val_accuracy: 0.9010 - val_loss: 0.2682\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2092 - val_accuracy: 0.9047 - val_loss: 0.2630\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8987 - loss: 0.2807\n",
      "\n",
      "Test accuracy: 0.8986999988555908\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.7612 - val_accuracy: 0.8652 - val_loss: 0.4152\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4020 - val_accuracy: 0.8753 - val_loss: 0.3702\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.3473 - val_accuracy: 0.8860 - val_loss: 0.3418\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.3145 - val_accuracy: 0.8933 - val_loss: 0.3289\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3009 - val_accuracy: 0.8930 - val_loss: 0.3206\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2812 - val_accuracy: 0.8935 - val_loss: 0.3159\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2633 - val_accuracy: 0.9013 - val_loss: 0.3020\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2534 - val_accuracy: 0.8990 - val_loss: 0.2984\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.2384 - val_accuracy: 0.9015 - val_loss: 0.2985\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2347 - val_accuracy: 0.9070 - val_loss: 0.2881\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8971 - loss: 0.3044\n",
      "\n",
      "Test accuracy: 0.8970999717712402\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7535 - loss: 0.7649 - val_accuracy: 0.8615 - val_loss: 0.4259\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.4064 - val_accuracy: 0.8758 - val_loss: 0.3712\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3469 - val_accuracy: 0.8868 - val_loss: 0.3410\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3278 - val_accuracy: 0.8893 - val_loss: 0.3260\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.3119 - val_accuracy: 0.8963 - val_loss: 0.3113\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2932 - val_accuracy: 0.8982 - val_loss: 0.3034\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2818 - val_accuracy: 0.8993 - val_loss: 0.3054\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2676 - val_accuracy: 0.9013 - val_loss: 0.2936\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2622 - val_accuracy: 0.9028 - val_loss: 0.2889\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2485 - val_accuracy: 0.9053 - val_loss: 0.2861\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8975 - loss: 0.3031\n",
      "\n",
      "Test accuracy: 0.8974999785423279\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 0.9183 - val_accuracy: 0.8423 - val_loss: 0.5176\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.4836 - val_accuracy: 0.8673 - val_loss: 0.4340\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.4167 - val_accuracy: 0.8765 - val_loss: 0.4070\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3859 - val_accuracy: 0.8780 - val_loss: 0.3950\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.3620 - val_accuracy: 0.8810 - val_loss: 0.3849\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.3491 - val_accuracy: 0.8865 - val_loss: 0.3611\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.3371 - val_accuracy: 0.8890 - val_loss: 0.3501\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.3274 - val_accuracy: 0.8860 - val_loss: 0.3559\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3127 - val_accuracy: 0.8952 - val_loss: 0.3410\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3121 - val_accuracy: 0.8923 - val_loss: 0.3401\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8853 - loss: 0.3547\n",
      "\n",
      "Test accuracy: 0.8852999806404114\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7540 - loss: 0.9219 - val_accuracy: 0.8502 - val_loss: 0.5087\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.4815 - val_accuracy: 0.8677 - val_loss: 0.4424\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.4273 - val_accuracy: 0.8733 - val_loss: 0.4046\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.4005 - val_accuracy: 0.8798 - val_loss: 0.3893\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3805 - val_accuracy: 0.8825 - val_loss: 0.3775\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.3706 - val_accuracy: 0.8870 - val_loss: 0.3634\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.3575 - val_accuracy: 0.8895 - val_loss: 0.3555\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3507 - val_accuracy: 0.8902 - val_loss: 0.3499\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.3412 - val_accuracy: 0.8868 - val_loss: 0.3704\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.3370 - val_accuracy: 0.8965 - val_loss: 0.3430\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8875 - loss: 0.3598\n",
      "\n",
      "Test accuracy: 0.887499988079071\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5868 - loss: 1.4705 - val_accuracy: 0.7743 - val_loss: 0.7027\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.6761 - val_accuracy: 0.8028 - val_loss: 0.5776\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.5756 - val_accuracy: 0.8167 - val_loss: 0.5291\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.5198 - val_accuracy: 0.8278 - val_loss: 0.4903\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.4812 - val_accuracy: 0.8350 - val_loss: 0.4681\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4642 - val_accuracy: 0.8342 - val_loss: 0.4565\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.4457 - val_accuracy: 0.8430 - val_loss: 0.4375\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.4272 - val_accuracy: 0.8473 - val_loss: 0.4256\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.4188 - val_accuracy: 0.8555 - val_loss: 0.4120\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.4092 - val_accuracy: 0.8552 - val_loss: 0.4092\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8451 - loss: 0.4296\n",
      "\n",
      "Test accuracy: 0.8450999855995178\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5236 - loss: 1.4918 - val_accuracy: 0.7615 - val_loss: 0.7269\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.7126 - val_accuracy: 0.7908 - val_loss: 0.6025\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.6093 - val_accuracy: 0.8050 - val_loss: 0.5474\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.5635 - val_accuracy: 0.8202 - val_loss: 0.5098\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.5298 - val_accuracy: 0.8307 - val_loss: 0.4827\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.5016 - val_accuracy: 0.8353 - val_loss: 0.4626\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.4754 - val_accuracy: 0.8407 - val_loss: 0.4462\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.4630 - val_accuracy: 0.8427 - val_loss: 0.4352\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4514 - val_accuracy: 0.8478 - val_loss: 0.4235\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4405 - val_accuracy: 0.8492 - val_loss: 0.4149\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8444 - loss: 0.4388\n",
      "\n",
      "Test accuracy: 0.8443999886512756\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5795 - loss: 1.5425 - val_accuracy: 0.7612 - val_loss: 0.7653\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.7309 - val_accuracy: 0.7945 - val_loss: 0.6425\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.6370 - val_accuracy: 0.8100 - val_loss: 0.5908\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.5816 - val_accuracy: 0.8208 - val_loss: 0.5585\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5538 - val_accuracy: 0.8253 - val_loss: 0.5346\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.5313 - val_accuracy: 0.8298 - val_loss: 0.5200\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.5079 - val_accuracy: 0.8363 - val_loss: 0.5008\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.5033 - val_accuracy: 0.8372 - val_loss: 0.4921\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.4791 - val_accuracy: 0.8418 - val_loss: 0.4781\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.4722 - val_accuracy: 0.8420 - val_loss: 0.4758\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8338 - loss: 0.4995\n",
      "\n",
      "Test accuracy: 0.8338000178337097\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5487 - loss: 1.5260 - val_accuracy: 0.7702 - val_loss: 0.7531\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.7426 - val_accuracy: 0.7908 - val_loss: 0.6411\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.6506 - val_accuracy: 0.8033 - val_loss: 0.5914\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.6002 - val_accuracy: 0.8177 - val_loss: 0.5603\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.5728 - val_accuracy: 0.8213 - val_loss: 0.5410\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.5469 - val_accuracy: 0.8278 - val_loss: 0.5216\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.5299 - val_accuracy: 0.8335 - val_loss: 0.5065\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.5163 - val_accuracy: 0.8365 - val_loss: 0.4973\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.5037 - val_accuracy: 0.8403 - val_loss: 0.4858\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.4955 - val_accuracy: 0.8418 - val_loss: 0.4777\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8326 - loss: 0.5000\n",
      "\n",
      "Test accuracy: 0.8325999975204468\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5465 - loss: 1.7458 - val_accuracy: 0.7613 - val_loss: 1.0130\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7606 - loss: 0.9688 - val_accuracy: 0.7762 - val_loss: 0.8438\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.8354 - val_accuracy: 0.7893 - val_loss: 0.7641\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.7560 - val_accuracy: 0.7992 - val_loss: 0.7164\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.7113 - val_accuracy: 0.8065 - val_loss: 0.6795\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.6721 - val_accuracy: 0.8148 - val_loss: 0.6512\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.6431 - val_accuracy: 0.8218 - val_loss: 0.6303\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.6279 - val_accuracy: 0.8275 - val_loss: 0.6066\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.6034 - val_accuracy: 0.8287 - val_loss: 0.5899\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.5860 - val_accuracy: 0.8335 - val_loss: 0.5750\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8223 - loss: 0.5991\n",
      "\n",
      "Test accuracy: 0.8223000168800354\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[32, 32]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5413 - loss: 1.7597 - val_accuracy: 0.7638 - val_loss: 0.9324\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.9080 - val_accuracy: 0.7855 - val_loss: 0.7894\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.7799 - val_accuracy: 0.7982 - val_loss: 0.7212\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.7298 - val_accuracy: 0.8072 - val_loss: 0.6779\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.6841 - val_accuracy: 0.8127 - val_loss: 0.6472\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.6559 - val_accuracy: 0.8185 - val_loss: 0.6236\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.6307 - val_accuracy: 0.8200 - val_loss: 0.6036\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.6122 - val_accuracy: 0.8258 - val_loss: 0.5882\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.5963 - val_accuracy: 0.8297 - val_loss: 0.5758\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.5821 - val_accuracy: 0.8323 - val_loss: 0.5632\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8239 - loss: 0.5852\n",
      "\n",
      "Test accuracy: 0.8238999843597412\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 0.6715 - val_accuracy: 0.8768 - val_loss: 0.3369\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3153 - val_accuracy: 0.8942 - val_loss: 0.2944\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2688 - val_accuracy: 0.9008 - val_loss: 0.2777\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2443 - val_accuracy: 0.9057 - val_loss: 0.2651\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2185 - val_accuracy: 0.9118 - val_loss: 0.2485\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1930 - val_accuracy: 0.9115 - val_loss: 0.2477\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.1852 - val_accuracy: 0.9118 - val_loss: 0.2493\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1653 - val_accuracy: 0.9085 - val_loss: 0.2526\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1516 - val_accuracy: 0.9127 - val_loss: 0.2501\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1354 - val_accuracy: 0.9157 - val_loss: 0.2446\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9126 - loss: 0.2560\n",
      "\n",
      "Test accuracy: 0.9125999808311462\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7531 - loss: 0.6934 - val_accuracy: 0.8807 - val_loss: 0.3459\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.3405 - val_accuracy: 0.8933 - val_loss: 0.3044\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2919 - val_accuracy: 0.9002 - val_loss: 0.2833\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2597 - val_accuracy: 0.9065 - val_loss: 0.2671\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2388 - val_accuracy: 0.9085 - val_loss: 0.2608\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2254 - val_accuracy: 0.9088 - val_loss: 0.2581\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2044 - val_accuracy: 0.9152 - val_loss: 0.2446\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.1915 - val_accuracy: 0.9125 - val_loss: 0.2415\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.1778 - val_accuracy: 0.9133 - val_loss: 0.2400\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.1676 - val_accuracy: 0.9142 - val_loss: 0.2494\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9126 - loss: 0.2593\n",
      "\n",
      "Test accuracy: 0.9125999808311462\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7686 - loss: 0.7068 - val_accuracy: 0.8740 - val_loss: 0.3782\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.3585 - val_accuracy: 0.8903 - val_loss: 0.3290\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.3103 - val_accuracy: 0.8998 - val_loss: 0.3044\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2829 - val_accuracy: 0.8963 - val_loss: 0.3118\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2612 - val_accuracy: 0.9042 - val_loss: 0.2875\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2436 - val_accuracy: 0.9082 - val_loss: 0.2804\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2276 - val_accuracy: 0.9030 - val_loss: 0.2867\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2181 - val_accuracy: 0.9107 - val_loss: 0.2719\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.2031 - val_accuracy: 0.9132 - val_loss: 0.2675\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1912 - val_accuracy: 0.9135 - val_loss: 0.2654\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9100 - loss: 0.2765\n",
      "\n",
      "Test accuracy: 0.9100000262260437\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.6831 - val_accuracy: 0.8837 - val_loss: 0.3707\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.3591 - val_accuracy: 0.8927 - val_loss: 0.3347\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.3198 - val_accuracy: 0.8967 - val_loss: 0.3102\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2985 - val_accuracy: 0.8990 - val_loss: 0.3059\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2762 - val_accuracy: 0.9052 - val_loss: 0.2868\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2612 - val_accuracy: 0.9060 - val_loss: 0.2819\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2538 - val_accuracy: 0.9060 - val_loss: 0.2822\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2390 - val_accuracy: 0.9113 - val_loss: 0.2698\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2311 - val_accuracy: 0.9085 - val_loss: 0.2789\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2203 - val_accuracy: 0.9117 - val_loss: 0.2700\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9060 - loss: 0.2780\n",
      "\n",
      "Test accuracy: 0.906000018119812\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7629 - loss: 0.9044 - val_accuracy: 0.8678 - val_loss: 0.4793\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.4616 - val_accuracy: 0.8842 - val_loss: 0.4190\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.4084 - val_accuracy: 0.8923 - val_loss: 0.3880\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3747 - val_accuracy: 0.8950 - val_loss: 0.3682\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.3464 - val_accuracy: 0.8925 - val_loss: 0.3668\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3273 - val_accuracy: 0.9002 - val_loss: 0.3414\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.3144 - val_accuracy: 0.8998 - val_loss: 0.3387\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.3022 - val_accuracy: 0.9025 - val_loss: 0.3276\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2936 - val_accuracy: 0.9013 - val_loss: 0.3302\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2834 - val_accuracy: 0.8995 - val_loss: 0.3277\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8927 - loss: 0.3451\n",
      "\n",
      "Test accuracy: 0.8927000164985657\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.9089 - val_accuracy: 0.8617 - val_loss: 0.5003\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.4826 - val_accuracy: 0.8788 - val_loss: 0.4339\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.4221 - val_accuracy: 0.8780 - val_loss: 0.4080\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3912 - val_accuracy: 0.8862 - val_loss: 0.3904\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.3764 - val_accuracy: 0.8967 - val_loss: 0.3645\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.3576 - val_accuracy: 0.8993 - val_loss: 0.3481\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.3423 - val_accuracy: 0.8983 - val_loss: 0.3454\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.3369 - val_accuracy: 0.9045 - val_loss: 0.3299\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3271 - val_accuracy: 0.8967 - val_loss: 0.3422\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.3200 - val_accuracy: 0.9038 - val_loss: 0.3239\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8955 - loss: 0.3398\n",
      "\n",
      "Test accuracy: 0.8955000042915344\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5254 - loss: 1.5487 - val_accuracy: 0.7717 - val_loss: 0.6502\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.6410 - val_accuracy: 0.7878 - val_loss: 0.5770\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5648 - val_accuracy: 0.8177 - val_loss: 0.5137\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.5246 - val_accuracy: 0.8148 - val_loss: 0.5112\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.5024 - val_accuracy: 0.7907 - val_loss: 0.5409\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4841 - val_accuracy: 0.8258 - val_loss: 0.4839\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.4643 - val_accuracy: 0.8375 - val_loss: 0.4521\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4558 - val_accuracy: 0.8338 - val_loss: 0.4610\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.4390 - val_accuracy: 0.8365 - val_loss: 0.4574\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.4302 - val_accuracy: 0.8303 - val_loss: 0.4585\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8258 - loss: 0.4771\n",
      "\n",
      "Test accuracy: 0.8258000016212463\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5135 - loss: 1.5723 - val_accuracy: 0.7340 - val_loss: 0.6967\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.6502 - val_accuracy: 0.7993 - val_loss: 0.5589\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.5768 - val_accuracy: 0.8147 - val_loss: 0.5124\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.5421 - val_accuracy: 0.8262 - val_loss: 0.4817\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.5131 - val_accuracy: 0.8313 - val_loss: 0.4729\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4927 - val_accuracy: 0.8368 - val_loss: 0.4655\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4799 - val_accuracy: 0.8293 - val_loss: 0.4671\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.4618 - val_accuracy: 0.8443 - val_loss: 0.4315\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4546 - val_accuracy: 0.8528 - val_loss: 0.4238\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4404 - val_accuracy: 0.8513 - val_loss: 0.4143\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8482 - loss: 0.4341\n",
      "\n",
      "Test accuracy: 0.8482000231742859\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5704 - loss: 1.5417 - val_accuracy: 0.7502 - val_loss: 0.7056\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.6926 - val_accuracy: 0.7970 - val_loss: 0.6294\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.6146 - val_accuracy: 0.8152 - val_loss: 0.5606\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.5751 - val_accuracy: 0.8153 - val_loss: 0.5467\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.5512 - val_accuracy: 0.8250 - val_loss: 0.5283\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.5241 - val_accuracy: 0.8102 - val_loss: 0.5474\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.5198 - val_accuracy: 0.8353 - val_loss: 0.4965\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.4985 - val_accuracy: 0.8375 - val_loss: 0.4928\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4960 - val_accuracy: 0.8417 - val_loss: 0.4808\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.4780 - val_accuracy: 0.8467 - val_loss: 0.4812\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8337 - loss: 0.5022\n",
      "\n",
      "Test accuracy: 0.8337000012397766\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4528 - loss: 1.6771 - val_accuracy: 0.7618 - val_loss: 0.7034\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.7115 - val_accuracy: 0.8003 - val_loss: 0.6090\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.6348 - val_accuracy: 0.8047 - val_loss: 0.5790\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.6002 - val_accuracy: 0.8195 - val_loss: 0.5524\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.5771 - val_accuracy: 0.8097 - val_loss: 0.5542\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.5558 - val_accuracy: 0.8277 - val_loss: 0.5198\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.5438 - val_accuracy: 0.8300 - val_loss: 0.5102\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.5241 - val_accuracy: 0.8388 - val_loss: 0.4976\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.5109 - val_accuracy: 0.8368 - val_loss: 0.4933\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.5019 - val_accuracy: 0.8427 - val_loss: 0.4778\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8370 - loss: 0.4995\n",
      "\n",
      "Test accuracy: 0.8370000123977661\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5115 - loss: 1.9295 - val_accuracy: 0.7638 - val_loss: 0.9322\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.9012 - val_accuracy: 0.7878 - val_loss: 0.7760\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.7741 - val_accuracy: 0.7868 - val_loss: 0.7213\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.7117 - val_accuracy: 0.8062 - val_loss: 0.6654\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8040 - loss: 0.6739 - val_accuracy: 0.8120 - val_loss: 0.6404\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.6391 - val_accuracy: 0.8098 - val_loss: 0.6279\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.6162 - val_accuracy: 0.8107 - val_loss: 0.6118\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.5999 - val_accuracy: 0.8128 - val_loss: 0.6003\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.5831 - val_accuracy: 0.8212 - val_loss: 0.5806\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.5802 - val_accuracy: 0.8298 - val_loss: 0.5595\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8227 - loss: 0.5884\n",
      "\n",
      "Test accuracy: 0.822700023651123\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4735 - loss: 1.9341 - val_accuracy: 0.7622 - val_loss: 0.9156\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.9002 - val_accuracy: 0.7810 - val_loss: 0.7730\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.7727 - val_accuracy: 0.7960 - val_loss: 0.7024\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.7203 - val_accuracy: 0.7955 - val_loss: 0.6763\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.6984 - val_accuracy: 0.8112 - val_loss: 0.6405\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.6743 - val_accuracy: 0.8135 - val_loss: 0.6237\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.6446 - val_accuracy: 0.8137 - val_loss: 0.6150\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.6430 - val_accuracy: 0.8170 - val_loss: 0.5975\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.6290 - val_accuracy: 0.8180 - val_loss: 0.5916\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.6148 - val_accuracy: 0.8215 - val_loss: 0.5887\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8089 - loss: 0.6205\n",
      "\n",
      "Test accuracy: 0.808899998664856\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7850 - loss: 0.6160 - val_accuracy: 0.8817 - val_loss: 0.3326\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3088 - val_accuracy: 0.8950 - val_loss: 0.2937\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2585 - val_accuracy: 0.8955 - val_loss: 0.2954\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2279 - val_accuracy: 0.9052 - val_loss: 0.2676\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.1951 - val_accuracy: 0.9073 - val_loss: 0.2575\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.1711 - val_accuracy: 0.9068 - val_loss: 0.2704\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1509 - val_accuracy: 0.9068 - val_loss: 0.2596\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1335 - val_accuracy: 0.9088 - val_loss: 0.2580\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1172 - val_accuracy: 0.9140 - val_loss: 0.2514\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.1013 - val_accuracy: 0.9138 - val_loss: 0.2616\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9072 - loss: 0.2719\n",
      "\n",
      "Test accuracy: 0.9071999788284302\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7800 - loss: 0.6320 - val_accuracy: 0.8753 - val_loss: 0.3476\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.3191 - val_accuracy: 0.8938 - val_loss: 0.2999\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2703 - val_accuracy: 0.8985 - val_loss: 0.2812\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2392 - val_accuracy: 0.9048 - val_loss: 0.2656\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2103 - val_accuracy: 0.9087 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.1894 - val_accuracy: 0.9140 - val_loss: 0.2451\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1697 - val_accuracy: 0.9177 - val_loss: 0.2478\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1575 - val_accuracy: 0.9112 - val_loss: 0.2483\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1448 - val_accuracy: 0.9123 - val_loss: 0.2457\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1267 - val_accuracy: 0.9115 - val_loss: 0.2613\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.9050 - loss: 0.2752\n",
      "\n",
      "Test accuracy: 0.9049999713897705\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7851 - loss: 0.6322 - val_accuracy: 0.8680 - val_loss: 0.3890\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3488 - val_accuracy: 0.8927 - val_loss: 0.3246\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.3016 - val_accuracy: 0.8968 - val_loss: 0.3072\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2708 - val_accuracy: 0.9018 - val_loss: 0.2980\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2479 - val_accuracy: 0.9018 - val_loss: 0.2910\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2284 - val_accuracy: 0.9028 - val_loss: 0.2800\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.2072 - val_accuracy: 0.9105 - val_loss: 0.2735\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1960 - val_accuracy: 0.9108 - val_loss: 0.2729\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.1889 - val_accuracy: 0.9083 - val_loss: 0.2818\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1763 - val_accuracy: 0.9097 - val_loss: 0.2739\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9048 - loss: 0.2899\n",
      "\n",
      "Test accuracy: 0.9047999978065491\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7840 - loss: 0.6438 - val_accuracy: 0.8755 - val_loss: 0.3770\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.3532 - val_accuracy: 0.8882 - val_loss: 0.3374\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.3110 - val_accuracy: 0.8975 - val_loss: 0.3133\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2856 - val_accuracy: 0.9018 - val_loss: 0.2947\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2611 - val_accuracy: 0.9052 - val_loss: 0.2872\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2460 - val_accuracy: 0.9102 - val_loss: 0.2768\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2310 - val_accuracy: 0.9125 - val_loss: 0.2734\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2149 - val_accuracy: 0.9082 - val_loss: 0.2807\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2052 - val_accuracy: 0.9097 - val_loss: 0.2818\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1941 - val_accuracy: 0.9090 - val_loss: 0.2789\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9035 - loss: 0.2943\n",
      "\n",
      "Test accuracy: 0.9035000205039978\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7795 - loss: 0.8322 - val_accuracy: 0.8658 - val_loss: 0.4588\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.4344 - val_accuracy: 0.8717 - val_loss: 0.4147\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3940 - val_accuracy: 0.8813 - val_loss: 0.3825\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.3594 - val_accuracy: 0.8920 - val_loss: 0.3581\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3409 - val_accuracy: 0.8932 - val_loss: 0.3510\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3257 - val_accuracy: 0.8858 - val_loss: 0.3652\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.3115 - val_accuracy: 0.8943 - val_loss: 0.3521\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.3001 - val_accuracy: 0.8985 - val_loss: 0.3350\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2925 - val_accuracy: 0.9028 - val_loss: 0.3244\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2800 - val_accuracy: 0.8972 - val_loss: 0.3333\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8934 - loss: 0.3451\n",
      "\n",
      "Test accuracy: 0.8934000134468079\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7682 - loss: 0.8808 - val_accuracy: 0.8592 - val_loss: 0.4738\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.4530 - val_accuracy: 0.8778 - val_loss: 0.4149\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.4032 - val_accuracy: 0.8858 - val_loss: 0.3804\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3719 - val_accuracy: 0.8890 - val_loss: 0.3717\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3586 - val_accuracy: 0.8933 - val_loss: 0.3572\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.3364 - val_accuracy: 0.8950 - val_loss: 0.3510\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.3257 - val_accuracy: 0.8965 - val_loss: 0.3525\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.3195 - val_accuracy: 0.8987 - val_loss: 0.3387\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3062 - val_accuracy: 0.8977 - val_loss: 0.3368\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.3032 - val_accuracy: 0.8945 - val_loss: 0.3458\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8921 - loss: 0.3584\n",
      "\n",
      "Test accuracy: 0.8920999765396118\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6167 - loss: 1.3078 - val_accuracy: 0.7818 - val_loss: 0.6218\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.6024 - val_accuracy: 0.8100 - val_loss: 0.5324\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.5341 - val_accuracy: 0.8188 - val_loss: 0.5005\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4868 - val_accuracy: 0.8270 - val_loss: 0.4693\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4666 - val_accuracy: 0.8303 - val_loss: 0.4648\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4404 - val_accuracy: 0.8388 - val_loss: 0.4405\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4287 - val_accuracy: 0.8450 - val_loss: 0.4264\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.4101 - val_accuracy: 0.8537 - val_loss: 0.4053\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.4051 - val_accuracy: 0.8538 - val_loss: 0.3969\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3956 - val_accuracy: 0.8552 - val_loss: 0.4042\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8473 - loss: 0.4260\n",
      "\n",
      "Test accuracy: 0.8472999930381775\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5888 - loss: 1.3519 - val_accuracy: 0.7792 - val_loss: 0.6333\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.6291 - val_accuracy: 0.8075 - val_loss: 0.5389\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.5459 - val_accuracy: 0.8217 - val_loss: 0.4989\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.5136 - val_accuracy: 0.8327 - val_loss: 0.4700\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.4841 - val_accuracy: 0.8362 - val_loss: 0.4510\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8373 - loss: 0.4592 - val_accuracy: 0.8423 - val_loss: 0.4357\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.4387 - val_accuracy: 0.8448 - val_loss: 0.4216\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.4251 - val_accuracy: 0.8502 - val_loss: 0.4118\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.4222 - val_accuracy: 0.8525 - val_loss: 0.4066\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.4106 - val_accuracy: 0.8562 - val_loss: 0.3959\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8518 - loss: 0.4185\n",
      "\n",
      "Test accuracy: 0.8518000245094299\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6043 - loss: 1.3904 - val_accuracy: 0.7730 - val_loss: 0.6820\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.6602 - val_accuracy: 0.8030 - val_loss: 0.5920\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.5893 - val_accuracy: 0.8158 - val_loss: 0.5511\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5448 - val_accuracy: 0.8277 - val_loss: 0.5251\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.5216 - val_accuracy: 0.8322 - val_loss: 0.5119\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.5000 - val_accuracy: 0.8362 - val_loss: 0.4922\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4855 - val_accuracy: 0.8437 - val_loss: 0.4762\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.4769 - val_accuracy: 0.8452 - val_loss: 0.4670\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.4681 - val_accuracy: 0.8487 - val_loss: 0.4615\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.4518 - val_accuracy: 0.8497 - val_loss: 0.4534\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8467 - loss: 0.4754\n",
      "\n",
      "Test accuracy: 0.8467000126838684\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5811 - loss: 1.4145 - val_accuracy: 0.7828 - val_loss: 0.6780\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7818 - loss: 0.6711 - val_accuracy: 0.8040 - val_loss: 0.5888\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.5938 - val_accuracy: 0.8198 - val_loss: 0.5494\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.5548 - val_accuracy: 0.8278 - val_loss: 0.5250\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8263 - loss: 0.5280 - val_accuracy: 0.8268 - val_loss: 0.5147\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.5143 - val_accuracy: 0.8370 - val_loss: 0.4901\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.4995 - val_accuracy: 0.8413 - val_loss: 0.4776\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.4870 - val_accuracy: 0.8452 - val_loss: 0.4711\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.4735 - val_accuracy: 0.8453 - val_loss: 0.4641\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4704 - val_accuracy: 0.8463 - val_loss: 0.4553\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8438 - loss: 0.4777\n",
      "\n",
      "Test accuracy: 0.8438000082969666\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6102 - loss: 1.6530 - val_accuracy: 0.7748 - val_loss: 0.9260\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.8932 - val_accuracy: 0.7950 - val_loss: 0.7960\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.7860 - val_accuracy: 0.8023 - val_loss: 0.7252\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.7208 - val_accuracy: 0.8112 - val_loss: 0.6828\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.6710 - val_accuracy: 0.8200 - val_loss: 0.6483\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.6386 - val_accuracy: 0.8232 - val_loss: 0.6252\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.6198 - val_accuracy: 0.8290 - val_loss: 0.6021\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.5968 - val_accuracy: 0.8325 - val_loss: 0.5823\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.5803 - val_accuracy: 0.8333 - val_loss: 0.5703\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.5664 - val_accuracy: 0.8367 - val_loss: 0.5556\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8293 - loss: 0.5796\n",
      "\n",
      "Test accuracy: 0.8292999863624573\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[64, 64]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5929 - loss: 1.6370 - val_accuracy: 0.7585 - val_loss: 0.9345\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.9006 - val_accuracy: 0.7895 - val_loss: 0.7942\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.7899 - val_accuracy: 0.8010 - val_loss: 0.7288\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.7307 - val_accuracy: 0.8093 - val_loss: 0.6851\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.6831 - val_accuracy: 0.8167 - val_loss: 0.6520\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.6561 - val_accuracy: 0.8205 - val_loss: 0.6287\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.6349 - val_accuracy: 0.8238 - val_loss: 0.6089\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.6110 - val_accuracy: 0.8270 - val_loss: 0.5920\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.5938 - val_accuracy: 0.8317 - val_loss: 0.5779\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.5833 - val_accuracy: 0.8323 - val_loss: 0.5661\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8291 - loss: 0.5868\n",
      "\n",
      "Test accuracy: 0.8291000127792358\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7876 - loss: 0.5954 - val_accuracy: 0.8948 - val_loss: 0.3043\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.2825 - val_accuracy: 0.9027 - val_loss: 0.2764\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2316 - val_accuracy: 0.9080 - val_loss: 0.2525\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.2062 - val_accuracy: 0.9125 - val_loss: 0.2408\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1778 - val_accuracy: 0.9148 - val_loss: 0.2375\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1515 - val_accuracy: 0.9162 - val_loss: 0.2434\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1343 - val_accuracy: 0.9167 - val_loss: 0.2456\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1128 - val_accuracy: 0.9168 - val_loss: 0.2498\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1034 - val_accuracy: 0.9158 - val_loss: 0.2749\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0866 - val_accuracy: 0.9185 - val_loss: 0.2615\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9148 - loss: 0.2716\n",
      "\n",
      "Test accuracy: 0.9147999882698059\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7836 - loss: 0.6081 - val_accuracy: 0.8940 - val_loss: 0.2967\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2879 - val_accuracy: 0.9033 - val_loss: 0.2759\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2473 - val_accuracy: 0.9012 - val_loss: 0.2692\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2139 - val_accuracy: 0.9052 - val_loss: 0.2641\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1874 - val_accuracy: 0.9053 - val_loss: 0.2658\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.1687 - val_accuracy: 0.9197 - val_loss: 0.2383\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1515 - val_accuracy: 0.9173 - val_loss: 0.2388\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1378 - val_accuracy: 0.9127 - val_loss: 0.2498\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1237 - val_accuracy: 0.9158 - val_loss: 0.2574\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1098 - val_accuracy: 0.9152 - val_loss: 0.2532\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9134 - loss: 0.2666\n",
      "\n",
      "Test accuracy: 0.9133999943733215\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7957 - loss: 0.6120 - val_accuracy: 0.8860 - val_loss: 0.3488\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.3169 - val_accuracy: 0.9010 - val_loss: 0.2969\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2719 - val_accuracy: 0.9030 - val_loss: 0.2991\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2490 - val_accuracy: 0.9097 - val_loss: 0.2748\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2218 - val_accuracy: 0.9117 - val_loss: 0.2710\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.2024 - val_accuracy: 0.9137 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1910 - val_accuracy: 0.9152 - val_loss: 0.2688\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1726 - val_accuracy: 0.9150 - val_loss: 0.2638\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1621 - val_accuracy: 0.9143 - val_loss: 0.2668\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1500 - val_accuracy: 0.9150 - val_loss: 0.2737\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9121 - loss: 0.2784\n",
      "\n",
      "Test accuracy: 0.9121000170707703\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7872 - loss: 0.6143 - val_accuracy: 0.8763 - val_loss: 0.3650\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3398 - val_accuracy: 0.8987 - val_loss: 0.3070\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2918 - val_accuracy: 0.9055 - val_loss: 0.2904\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2643 - val_accuracy: 0.9063 - val_loss: 0.2819\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2453 - val_accuracy: 0.9132 - val_loss: 0.2667\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.2201 - val_accuracy: 0.9048 - val_loss: 0.2821\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2115 - val_accuracy: 0.9128 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2003 - val_accuracy: 0.9122 - val_loss: 0.2649\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9394 - loss: 0.1877 - val_accuracy: 0.9150 - val_loss: 0.2680\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1709 - val_accuracy: 0.9188 - val_loss: 0.2528\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9150 - loss: 0.2634\n",
      "\n",
      "Test accuracy: 0.9150000214576721\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7741 - loss: 0.8690 - val_accuracy: 0.8622 - val_loss: 0.4819\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.4481 - val_accuracy: 0.8798 - val_loss: 0.4150\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.3868 - val_accuracy: 0.8870 - val_loss: 0.3778\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.3499 - val_accuracy: 0.8977 - val_loss: 0.3524\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3288 - val_accuracy: 0.8943 - val_loss: 0.3559\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.3072 - val_accuracy: 0.8927 - val_loss: 0.3461\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2935 - val_accuracy: 0.9033 - val_loss: 0.3260\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2802 - val_accuracy: 0.9088 - val_loss: 0.3098\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2690 - val_accuracy: 0.9090 - val_loss: 0.3026\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.2536 - val_accuracy: 0.9035 - val_loss: 0.3113\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8992 - loss: 0.3291\n",
      "\n",
      "Test accuracy: 0.8992000222206116\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7690 - loss: 0.8823 - val_accuracy: 0.8637 - val_loss: 0.4851\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.4565 - val_accuracy: 0.8868 - val_loss: 0.4080\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3991 - val_accuracy: 0.8955 - val_loss: 0.3695\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3651 - val_accuracy: 0.8957 - val_loss: 0.3528\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.3469 - val_accuracy: 0.8998 - val_loss: 0.3390\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.3297 - val_accuracy: 0.9042 - val_loss: 0.3302\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.3143 - val_accuracy: 0.9078 - val_loss: 0.3215\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.3071 - val_accuracy: 0.9085 - val_loss: 0.3166\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2898 - val_accuracy: 0.8977 - val_loss: 0.3296\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2920 - val_accuracy: 0.9092 - val_loss: 0.3082\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9021 - loss: 0.3283\n",
      "\n",
      "Test accuracy: 0.9021000266075134\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5858 - loss: 1.4329 - val_accuracy: 0.7827 - val_loss: 0.6324\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.6279 - val_accuracy: 0.7867 - val_loss: 0.5712\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.5524 - val_accuracy: 0.8057 - val_loss: 0.5451\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.5193 - val_accuracy: 0.8283 - val_loss: 0.4774\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.4949 - val_accuracy: 0.8350 - val_loss: 0.4721\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4730 - val_accuracy: 0.8270 - val_loss: 0.4919\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4603 - val_accuracy: 0.8315 - val_loss: 0.4658\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.4453 - val_accuracy: 0.8342 - val_loss: 0.4535\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.4368 - val_accuracy: 0.8448 - val_loss: 0.4453\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.4309 - val_accuracy: 0.8342 - val_loss: 0.4579\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8254 - loss: 0.4792\n",
      "\n",
      "Test accuracy: 0.8253999948501587\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5421 - loss: 1.5045 - val_accuracy: 0.7615 - val_loss: 0.6705\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.6454 - val_accuracy: 0.7313 - val_loss: 0.7569\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5738 - val_accuracy: 0.8163 - val_loss: 0.5111\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.5381 - val_accuracy: 0.8170 - val_loss: 0.5239\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.5136 - val_accuracy: 0.7798 - val_loss: 0.5604\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4978 - val_accuracy: 0.8307 - val_loss: 0.4680\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4812 - val_accuracy: 0.8387 - val_loss: 0.4591\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.4632 - val_accuracy: 0.8465 - val_loss: 0.4357\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.4451 - val_accuracy: 0.8462 - val_loss: 0.4281\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.4328 - val_accuracy: 0.8452 - val_loss: 0.4217\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8386 - loss: 0.4477\n",
      "\n",
      "Test accuracy: 0.8385999798774719\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5273 - loss: 1.5857 - val_accuracy: 0.7757 - val_loss: 0.6902\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.6773 - val_accuracy: 0.8020 - val_loss: 0.5998\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.6018 - val_accuracy: 0.8147 - val_loss: 0.5643\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5698 - val_accuracy: 0.8112 - val_loss: 0.5597\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.5475 - val_accuracy: 0.8272 - val_loss: 0.5262\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.5326 - val_accuracy: 0.8340 - val_loss: 0.5143\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.5147 - val_accuracy: 0.8307 - val_loss: 0.5077\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.4968 - val_accuracy: 0.8420 - val_loss: 0.4847\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.4919 - val_accuracy: 0.8420 - val_loss: 0.4868\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.4806 - val_accuracy: 0.8343 - val_loss: 0.4968\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8243 - loss: 0.5191\n",
      "\n",
      "Test accuracy: 0.8242999911308289\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5131 - loss: 1.5560 - val_accuracy: 0.7735 - val_loss: 0.6796\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 0.6832 - val_accuracy: 0.7572 - val_loss: 0.7012\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.6129 - val_accuracy: 0.7892 - val_loss: 0.5981\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.5756 - val_accuracy: 0.8220 - val_loss: 0.5344\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.5536 - val_accuracy: 0.8267 - val_loss: 0.5214\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.5320 - val_accuracy: 0.8312 - val_loss: 0.5084\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.5240 - val_accuracy: 0.8313 - val_loss: 0.5183\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.5118 - val_accuracy: 0.8398 - val_loss: 0.4855\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.5000 - val_accuracy: 0.8457 - val_loss: 0.4780\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.4850 - val_accuracy: 0.8400 - val_loss: 0.4876\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8302 - loss: 0.5120\n",
      "\n",
      "Test accuracy: 0.8302000164985657\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5619 - loss: 1.8925 - val_accuracy: 0.7625 - val_loss: 0.9599\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.9062 - val_accuracy: 0.7895 - val_loss: 0.7772\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.7696 - val_accuracy: 0.7998 - val_loss: 0.7149\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.7103 - val_accuracy: 0.8047 - val_loss: 0.6632\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8080 - loss: 0.6656 - val_accuracy: 0.8135 - val_loss: 0.6343\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.6419 - val_accuracy: 0.8082 - val_loss: 0.6212\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.6234 - val_accuracy: 0.8173 - val_loss: 0.5989\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.6080 - val_accuracy: 0.8200 - val_loss: 0.5816\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5866 - val_accuracy: 0.8250 - val_loss: 0.5714\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.5819 - val_accuracy: 0.8255 - val_loss: 0.5619\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8151 - loss: 0.5945\n",
      "\n",
      "Test accuracy: 0.8151000142097473\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4864 - loss: 1.9673 - val_accuracy: 0.7697 - val_loss: 0.9349\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.9001 - val_accuracy: 0.7860 - val_loss: 0.7647\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.7733 - val_accuracy: 0.7963 - val_loss: 0.7007\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.7271 - val_accuracy: 0.8067 - val_loss: 0.6674\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.6873 - val_accuracy: 0.8085 - val_loss: 0.6431\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.6608 - val_accuracy: 0.8088 - val_loss: 0.6286\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.6437 - val_accuracy: 0.8092 - val_loss: 0.6268\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.6355 - val_accuracy: 0.8190 - val_loss: 0.5968\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.6211 - val_accuracy: 0.8255 - val_loss: 0.5859\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.6116 - val_accuracy: 0.8228 - val_loss: 0.5773\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8140 - loss: 0.6101\n",
      "\n",
      "Test accuracy: 0.8140000104904175\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m413/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.6333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 15:12:13.091770: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_204', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.7815 - loss: 0.6288 - val_accuracy: 0.8857 - val_loss: 0.3183\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.2933 - val_accuracy: 0.8970 - val_loss: 0.2759\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2392 - val_accuracy: 0.9073 - val_loss: 0.2566\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1983 - val_accuracy: 0.9100 - val_loss: 0.2527\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1632 - val_accuracy: 0.9082 - val_loss: 0.2563\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1404 - val_accuracy: 0.9155 - val_loss: 0.2406\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1112 - val_accuracy: 0.9163 - val_loss: 0.2350\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0970 - val_accuracy: 0.9142 - val_loss: 0.2518\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0792 - val_accuracy: 0.9187 - val_loss: 0.2472\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0602 - val_accuracy: 0.9190 - val_loss: 0.2503\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.9149 - loss: 0.2657\n",
      "\n",
      "Test accuracy: 0.914900004863739\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7841 - loss: 0.6037 - val_accuracy: 0.8832 - val_loss: 0.3239\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2993 - val_accuracy: 0.9000 - val_loss: 0.2896\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2421 - val_accuracy: 0.9058 - val_loss: 0.2630\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.2026 - val_accuracy: 0.9027 - val_loss: 0.2651\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1794 - val_accuracy: 0.9132 - val_loss: 0.2430\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1515 - val_accuracy: 0.9138 - val_loss: 0.2401\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1276 - val_accuracy: 0.9168 - val_loss: 0.2424\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1113 - val_accuracy: 0.9145 - val_loss: 0.2444\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0953 - val_accuracy: 0.9153 - val_loss: 0.2516\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0825 - val_accuracy: 0.9145 - val_loss: 0.2508\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9116 - loss: 0.2670\n",
      "\n",
      "Test accuracy: 0.9115999937057495\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7814 - loss: 0.6696 - val_accuracy: 0.8752 - val_loss: 0.3660\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.3294 - val_accuracy: 0.8943 - val_loss: 0.3106\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2737 - val_accuracy: 0.8938 - val_loss: 0.3120\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2440 - val_accuracy: 0.9075 - val_loss: 0.2799\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2237 - val_accuracy: 0.9065 - val_loss: 0.2789\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1961 - val_accuracy: 0.9105 - val_loss: 0.2731\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1765 - val_accuracy: 0.9120 - val_loss: 0.2671\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1594 - val_accuracy: 0.9135 - val_loss: 0.2713\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1474 - val_accuracy: 0.9118 - val_loss: 0.2711\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1330 - val_accuracy: 0.9175 - val_loss: 0.2700\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9080 - loss: 0.2913\n",
      "\n",
      "Test accuracy: 0.9079999923706055\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7861 - loss: 0.6185 - val_accuracy: 0.8833 - val_loss: 0.3549\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.3292 - val_accuracy: 0.8877 - val_loss: 0.3233\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2867 - val_accuracy: 0.9043 - val_loss: 0.2870\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2581 - val_accuracy: 0.9055 - val_loss: 0.2871\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2310 - val_accuracy: 0.8977 - val_loss: 0.3004\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.2069 - val_accuracy: 0.9100 - val_loss: 0.2815\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1961 - val_accuracy: 0.9113 - val_loss: 0.2802\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1766 - val_accuracy: 0.9112 - val_loss: 0.2728\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1677 - val_accuracy: 0.9122 - val_loss: 0.2748\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1518 - val_accuracy: 0.9085 - val_loss: 0.2856\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9060 - loss: 0.3003\n",
      "\n",
      "Test accuracy: 0.906000018119812\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7885 - loss: 0.8498 - val_accuracy: 0.8687 - val_loss: 0.4545\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.4302 - val_accuracy: 0.8833 - val_loss: 0.4011\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.3839 - val_accuracy: 0.8853 - val_loss: 0.3854\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.3473 - val_accuracy: 0.8925 - val_loss: 0.3552\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.3262 - val_accuracy: 0.9012 - val_loss: 0.3443\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3106 - val_accuracy: 0.9003 - val_loss: 0.3448\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2953 - val_accuracy: 0.8832 - val_loss: 0.3829\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2815 - val_accuracy: 0.9018 - val_loss: 0.3293\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2648 - val_accuracy: 0.9055 - val_loss: 0.3250\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.2570 - val_accuracy: 0.9060 - val_loss: 0.3217\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9013 - loss: 0.3328\n",
      "\n",
      "Test accuracy: 0.9013000130653381\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7737 - loss: 0.9386 - val_accuracy: 0.8578 - val_loss: 0.4788\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.4604 - val_accuracy: 0.8808 - val_loss: 0.4056\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.3958 - val_accuracy: 0.8800 - val_loss: 0.3893\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3692 - val_accuracy: 0.8837 - val_loss: 0.3881\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.3495 - val_accuracy: 0.8805 - val_loss: 0.3794\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.3416 - val_accuracy: 0.8918 - val_loss: 0.3687\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.3245 - val_accuracy: 0.9027 - val_loss: 0.3418\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.3140 - val_accuracy: 0.9007 - val_loss: 0.3386\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.3049 - val_accuracy: 0.9015 - val_loss: 0.3350\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2980 - val_accuracy: 0.9052 - val_loss: 0.3339\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9001 - loss: 0.3434\n",
      "\n",
      "Test accuracy: 0.9000999927520752\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6311 - loss: 1.3149 - val_accuracy: 0.7892 - val_loss: 0.6054\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5775 - val_accuracy: 0.8027 - val_loss: 0.5321\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.5110 - val_accuracy: 0.8328 - val_loss: 0.4767\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4732 - val_accuracy: 0.8315 - val_loss: 0.4623\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.4564 - val_accuracy: 0.8425 - val_loss: 0.4411\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.4350 - val_accuracy: 0.8370 - val_loss: 0.4375\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.4099 - val_accuracy: 0.8518 - val_loss: 0.4083\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.4091 - val_accuracy: 0.8565 - val_loss: 0.4031\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3947 - val_accuracy: 0.8575 - val_loss: 0.3912\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3859 - val_accuracy: 0.8600 - val_loss: 0.3892\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8519 - loss: 0.4116\n",
      "\n",
      "Test accuracy: 0.8518999814987183\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 1.3045 - val_accuracy: 0.7835 - val_loss: 0.6048\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5951 - val_accuracy: 0.8140 - val_loss: 0.5171\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5167 - val_accuracy: 0.8238 - val_loss: 0.4825\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4836 - val_accuracy: 0.8355 - val_loss: 0.4540\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4571 - val_accuracy: 0.8427 - val_loss: 0.4335\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4342 - val_accuracy: 0.8427 - val_loss: 0.4276\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.4242 - val_accuracy: 0.8490 - val_loss: 0.4166\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.4148 - val_accuracy: 0.8528 - val_loss: 0.4013\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.4015 - val_accuracy: 0.8530 - val_loss: 0.3985\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.3907 - val_accuracy: 0.8600 - val_loss: 0.3864\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8561 - loss: 0.4067\n",
      "\n",
      "Test accuracy: 0.8561000227928162\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 1.3837 - val_accuracy: 0.7895 - val_loss: 0.6487\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.6335 - val_accuracy: 0.7950 - val_loss: 0.5951\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8201 - loss: 0.5643 - val_accuracy: 0.8220 - val_loss: 0.5339\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.5381 - val_accuracy: 0.8310 - val_loss: 0.5106\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.5022 - val_accuracy: 0.8360 - val_loss: 0.4966\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4869 - val_accuracy: 0.8325 - val_loss: 0.5017\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4851 - val_accuracy: 0.8483 - val_loss: 0.4710\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.4688 - val_accuracy: 0.8462 - val_loss: 0.4648\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8540 - loss: 0.4588 - val_accuracy: 0.8522 - val_loss: 0.4522\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.4481 - val_accuracy: 0.8552 - val_loss: 0.4451\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8474 - loss: 0.4681\n",
      "\n",
      "Test accuracy: 0.8474000096321106\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6153 - loss: 1.3534 - val_accuracy: 0.7837 - val_loss: 0.6460\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.6366 - val_accuracy: 0.8068 - val_loss: 0.5727\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.5731 - val_accuracy: 0.8233 - val_loss: 0.5354\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.5350 - val_accuracy: 0.8290 - val_loss: 0.5159\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.5171 - val_accuracy: 0.8333 - val_loss: 0.5040\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.5003 - val_accuracy: 0.8383 - val_loss: 0.4847\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.4831 - val_accuracy: 0.8428 - val_loss: 0.4726\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4763 - val_accuracy: 0.8447 - val_loss: 0.4665\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.4643 - val_accuracy: 0.8453 - val_loss: 0.4610\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.4612 - val_accuracy: 0.8510 - val_loss: 0.4529\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8426 - loss: 0.4745\n",
      "\n",
      "Test accuracy: 0.8425999879837036\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6129 - loss: 1.7290 - val_accuracy: 0.7745 - val_loss: 0.9411\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.9111 - val_accuracy: 0.7927 - val_loss: 0.7999\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.7940 - val_accuracy: 0.8035 - val_loss: 0.7291\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.7273 - val_accuracy: 0.8123 - val_loss: 0.6862\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.6816 - val_accuracy: 0.8178 - val_loss: 0.6508\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.6499 - val_accuracy: 0.8223 - val_loss: 0.6284\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.6272 - val_accuracy: 0.8260 - val_loss: 0.6094\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.6039 - val_accuracy: 0.8327 - val_loss: 0.5910\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.5857 - val_accuracy: 0.8333 - val_loss: 0.5735\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.5737 - val_accuracy: 0.8363 - val_loss: 0.5604\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8300 - loss: 0.5841\n",
      "\n",
      "Test accuracy: 0.8299999833106995\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25, architecture=[128, 128]\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 1.7291 - val_accuracy: 0.7733 - val_loss: 0.9343\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.9058 - val_accuracy: 0.7928 - val_loss: 0.7871\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.7836 - val_accuracy: 0.8005 - val_loss: 0.7195\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.7181 - val_accuracy: 0.8100 - val_loss: 0.6744\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.6706 - val_accuracy: 0.8178 - val_loss: 0.6426\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.6504 - val_accuracy: 0.8220 - val_loss: 0.6170\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.6260 - val_accuracy: 0.8263 - val_loss: 0.5970\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.5965 - val_accuracy: 0.8322 - val_loss: 0.5811\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.5889 - val_accuracy: 0.8325 - val_loss: 0.5682\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.5726 - val_accuracy: 0.8342 - val_loss: 0.5572\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8265 - loss: 0.5820\n",
      "\n",
      "Test accuracy: 0.8264999985694885\n"
     ]
    }
   ],
   "source": [
    "combinations_small = {}\n",
    "for architecture in architectures:\n",
    "    for activation in activations:\n",
    "        for opt in optimizers:\n",
    "            for reg in regularizations:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    print(f\"Training model with activation={activation}, optimizer={opt}, \"\n",
    "                            f\"reg={reg}, dropout_rate={dropout_rate}, architecture={architecture}\")\n",
    "                    model = create_model_small(shape=X_train[0].shape, activation=activation, optimizer=opt, \n",
    "                                            regularization=reg, dropout_rate=dropout_rate,architectures=architecture)\n",
    "                    history = model.fit(\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                        )\n",
    "                    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\t\n",
    "                    print(\"\\nTest accuracy:\", test_acc)\n",
    "                    combinations_small[(*architecture, activation, opt, reg, dropout_rate)] = {'test_acc': test_acc, 'history': history}\n",
    "with open(f'combinations_small_{epochs}_epochs.pkl', 'wb') as f:\n",
    "    pickle.dump(combinations_small, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(128,\n",
       "  128,\n",
       "  'relu',\n",
       "  'adam',\n",
       "  <keras.src.regularizers.regularizers.L2 at 0x7f839881b1d0>,\n",
       "  0.25): {'test_acc': 0.9150000214576721,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f8337347390>},\n",
       " (128, 128, 'tanh', 'adam', None, 0.0): {'test_acc': 0.914900004863739,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f83382d0d90>},\n",
       " (128, 128, 'relu', 'adam', None, 0.0): {'test_acc': 0.9147999882698059,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f83361d0d90>}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top K highest accuracy\n",
    "combinations_small = {k: v for k, v in sorted(combinations_small.items(), key=lambda item: item[1]['test_acc'], reverse=True)}\n",
    "top_k = 3\n",
    "top_k_combinations_small = dict(list(combinations_small.items())[:top_k])\n",
    "top_k_combinations_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(128, 128, 'relu', 'adam', <keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, 0.25), (128, 128, 'tanh', 'adam', None, 0.0), (128, 128, 'relu', 'adam', None, 0.0)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_combinations_small.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2834 - loss: 36.2150\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5157 - loss: 1.4233\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 1.2180\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 1.0502\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6900 - loss: 0.9347\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.8678\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7386 - loss: 0.8093\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.6985\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7996 - loss: 0.6270\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8186 - loss: 0.5740\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.5638 - loss: 1.6785\n",
      "\n",
      "Test accuracy: 0.5637999773025513\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m378/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0977 - loss: 2.8290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 15:19:37.120452: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_205', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.0977 - loss: 2.8167\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3101\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3117\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3091\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1013 - loss: 2.3099\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1051 - loss: 2.3086\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0956 - loss: 2.3103\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3106\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1022 - loss: 2.3095\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3106\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.1000 - loss: 2.3056\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2541 - loss: 45.6148\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 1.3792\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 1.1794\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6456 - loss: 1.0020\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7054 - loss: 0.8456\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7486 - loss: 0.7137\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.6187\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.5107\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4526\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.3707\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.5517 - loss: 2.0870\n",
      "\n",
      "Test accuracy: 0.5516999959945679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(128,\n",
       "  128,\n",
       "  'relu',\n",
       "  'adam',\n",
       "  <keras.src.regularizers.regularizers.L2 at 0x7f839881b1d0>,\n",
       "  0.25): {'test_acc': 0.5637999773025513,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f8330b21d90>},\n",
       " (128, 128, 'tanh', 'adam', None, 0.0): {'test_acc': 0.10000000149011612,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f832c1970d0>},\n",
       " (128, 128, 'relu', 'adam', None, 0.0): {'test_acc': 0.5516999959945679,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f831413a210>}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, num_classes = load_cifar10_data()\n",
    "shape = X_train[1:].shape\n",
    "# train models with the top k combinations\n",
    "cifar10_top_k_results_small = {}\n",
    "for (layer1_arch, layer2_arch, activation, opt, reg, dropout_rate) in top_k_combinations_small.keys():\n",
    "    print(f\"Training model with activation={activation}, optimizer={opt}, \"\n",
    "            f\"reg={reg}, dropout_rate={dropout_rate}\")\n",
    "    architectures = [layer1_arch, layer2_arch]\n",
    "    model = create_model_small(shape=X_train[0].shape,activation=activation, optimizer=opt, \n",
    "                            regularization=reg, dropout_rate=dropout_rate, architectures=architectures)\n",
    "    history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            # validation_data=(X_test, y_test),\n",
    "        )\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\t\n",
    "    print(\"\\nTest accuracy:\", test_acc)\n",
    "    cifar10_top_k_results_small[(*architectures,activation, opt, reg, dropout_rate)] = {'test_acc': test_acc, 'history': history}\n",
    "cifar10_top_k_results_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cifar10_top_k_small_results_{epochs}_epochs.pkl', 'wb') as f:\n",
    "    pickle.dump(cifar10_top_k_results_small, f)\n",
    "# load \n",
    "# with open(f'cifar10_top_k_small_results_{epochs}_epochs.pkl', 'rb') as f:\n",
    "#     cifar10_top_k_results_small = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_big(shape,activation='relu', optimizer='adam', \n",
    "                 regularization=None, dropout_rate=0.0, architectures=[128,64,32]):\n",
    "    model = Sequential([\n",
    "        Input(shape=shape), # image shape is (32, 32, 3)\n",
    "        Conv2D(architectures[0], (3, 3), activation=activation, padding='same', kernel_regularizer=regularization),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(architectures[1], (3, 3), activation=activation, padding='same', kernel_regularizer=regularization),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(dropout_rate),\n",
    "        Conv2D(architectures[1], (3, 3), activation=activation, padding='same', kernel_regularizer=regularization),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(architectures[2], activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss ='categorical_crossentropy', optimizer=optimizer,metrics =['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 10, lenght: 28, width: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = (28, 28, 1)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, num_classes = load_fashion_mnist_data()\n",
    "X_train = X_train.reshape(X_train.shape[0],*image_shape) # revert to the original shape\n",
    "X_test = X_test.reshape(X_test.shape[0],*image_shape)\n",
    "X_val = X_val.reshape(X_val.shape[0],*image_shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6744 - loss: 0.9021 - val_accuracy: 0.8552 - val_loss: 0.3930\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8703 - loss: 0.3604 - val_accuracy: 0.8843 - val_loss: 0.3279\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.3028 - val_accuracy: 0.8915 - val_loss: 0.3034\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.2702 - val_accuracy: 0.9023 - val_loss: 0.2709\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2486 - val_accuracy: 0.9020 - val_loss: 0.2731\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.2246 - val_accuracy: 0.9040 - val_loss: 0.2621\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.2084 - val_accuracy: 0.9120 - val_loss: 0.2442\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9275 - loss: 0.1970 - val_accuracy: 0.9087 - val_loss: 0.2508\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9318 - loss: 0.1849 - val_accuracy: 0.9147 - val_loss: 0.2397\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.1651 - val_accuracy: 0.9193 - val_loss: 0.2273\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9131 - loss: 0.2470\n",
      "\n",
      "Test accuracy: 0.913100004196167\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6677 - loss: 0.9234 - val_accuracy: 0.8462 - val_loss: 0.4154\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.4084 - val_accuracy: 0.8772 - val_loss: 0.3302\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3370 - val_accuracy: 0.8853 - val_loss: 0.3120\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3004 - val_accuracy: 0.8947 - val_loss: 0.2798\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.2804 - val_accuracy: 0.9018 - val_loss: 0.2670\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2492 - val_accuracy: 0.9030 - val_loss: 0.2578\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2404 - val_accuracy: 0.9105 - val_loss: 0.2501\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2352 - val_accuracy: 0.9093 - val_loss: 0.2531\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2215 - val_accuracy: 0.9120 - val_loss: 0.2360\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2103 - val_accuracy: 0.9170 - val_loss: 0.2280\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9111 - loss: 0.2420\n",
      "\n",
      "Test accuracy: 0.9110999703407288\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6300 - loss: 1.5330 - val_accuracy: 0.8257 - val_loss: 0.6971\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.6795 - val_accuracy: 0.8285 - val_loss: 0.6420\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.6028 - val_accuracy: 0.8500 - val_loss: 0.5510\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.5511 - val_accuracy: 0.8422 - val_loss: 0.5498\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 0.5264 - val_accuracy: 0.8577 - val_loss: 0.5151\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.5200 - val_accuracy: 0.8598 - val_loss: 0.5123\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.4994 - val_accuracy: 0.8600 - val_loss: 0.4911\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.4836 - val_accuracy: 0.8603 - val_loss: 0.4949\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.4757 - val_accuracy: 0.8638 - val_loss: 0.4762\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.4710 - val_accuracy: 0.8633 - val_loss: 0.4803\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8596 - loss: 0.4968\n",
      "\n",
      "Test accuracy: 0.8596000075340271\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6177 - loss: 1.5929 - val_accuracy: 0.8065 - val_loss: 0.7166\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.7172 - val_accuracy: 0.8202 - val_loss: 0.6527\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.6405 - val_accuracy: 0.8422 - val_loss: 0.5778\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.5921 - val_accuracy: 0.8520 - val_loss: 0.5540\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.5705 - val_accuracy: 0.8530 - val_loss: 0.5433\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.5514 - val_accuracy: 0.8563 - val_loss: 0.5202\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.5464 - val_accuracy: 0.8592 - val_loss: 0.5165\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.5325 - val_accuracy: 0.8545 - val_loss: 0.5265\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.5318 - val_accuracy: 0.8627 - val_loss: 0.4967\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.5050 - val_accuracy: 0.8653 - val_loss: 0.4884\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8595 - loss: 0.5042\n",
      "\n",
      "Test accuracy: 0.859499990940094\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1288 - loss: 9.3497 - val_accuracy: 0.0985 - val_loss: 2.4388\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0963 - loss: 2.4383 - val_accuracy: 0.0973 - val_loss: 2.4376\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.4380 - val_accuracy: 0.0925 - val_loss: 2.4381\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.4379 - val_accuracy: 0.1008 - val_loss: 2.4382\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.4380 - val_accuracy: 0.0942 - val_loss: 2.4386\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0998 - loss: 2.4380 - val_accuracy: 0.0925 - val_loss: 2.4384\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0958 - loss: 2.4380 - val_accuracy: 0.0925 - val_loss: 2.4389\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.4379 - val_accuracy: 0.0925 - val_loss: 2.4376\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 2.4379 - val_accuracy: 0.0985 - val_loss: 2.4388\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0983 - loss: 2.4379 - val_accuracy: 0.0985 - val_loss: 2.4375\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.1000 - loss: 2.4373\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4098 - loss: 8.8225 - val_accuracy: 0.7052 - val_loss: 1.1547\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6877 - loss: 1.1395 - val_accuracy: 0.7132 - val_loss: 1.1024\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 1.0796 - val_accuracy: 0.7230 - val_loss: 1.0802\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 1.0470 - val_accuracy: 0.7250 - val_loss: 1.0526\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 1.0271 - val_accuracy: 0.7430 - val_loss: 1.0065\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 1.0034 - val_accuracy: 0.6958 - val_loss: 1.0490\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.9766 - val_accuracy: 0.7430 - val_loss: 0.9665\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.9644 - val_accuracy: 0.6867 - val_loss: 1.0659\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7481 - loss: 0.9525 - val_accuracy: 0.7490 - val_loss: 0.9785\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7460 - loss: 0.9556 - val_accuracy: 0.7408 - val_loss: 0.9735\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7330 - loss: 0.9943\n",
      "\n",
      "Test accuracy: 0.7329999804496765\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2618 - loss: 2.0542 - val_accuracy: 0.6325 - val_loss: 0.9301\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6757 - loss: 0.8730 - val_accuracy: 0.6573 - val_loss: 0.8024\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.7134 - val_accuracy: 0.7458 - val_loss: 0.6509\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7592 - loss: 0.6457 - val_accuracy: 0.7852 - val_loss: 0.5827\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.5874 - val_accuracy: 0.7957 - val_loss: 0.5522\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.5351 - val_accuracy: 0.8038 - val_loss: 0.5388\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.5102 - val_accuracy: 0.8287 - val_loss: 0.4733\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4880 - val_accuracy: 0.8005 - val_loss: 0.5139\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.4685 - val_accuracy: 0.8395 - val_loss: 0.4461\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.4507 - val_accuracy: 0.8423 - val_loss: 0.4403\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8361 - loss: 0.4577\n",
      "\n",
      "Test accuracy: 0.8360999822616577\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2574 - loss: 2.1499 - val_accuracy: 0.5670 - val_loss: 1.0643\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 0.9831 - val_accuracy: 0.6847 - val_loss: 0.7900\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.8078 - val_accuracy: 0.7532 - val_loss: 0.6750\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7273 - loss: 0.7230 - val_accuracy: 0.7547 - val_loss: 0.6403\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7466 - loss: 0.6792 - val_accuracy: 0.7673 - val_loss: 0.6159\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.6371 - val_accuracy: 0.7878 - val_loss: 0.5821\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7771 - loss: 0.5974 - val_accuracy: 0.7907 - val_loss: 0.5395\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 0.5746 - val_accuracy: 0.7988 - val_loss: 0.5137\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.5529 - val_accuracy: 0.7887 - val_loss: 0.5336\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5303 - val_accuracy: 0.7962 - val_loss: 0.5182\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7953 - loss: 0.5372\n",
      "\n",
      "Test accuracy: 0.7953000068664551\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2301 - loss: 3.6392 - val_accuracy: 0.6303 - val_loss: 2.3258\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 2.1802 - val_accuracy: 0.7340 - val_loss: 1.8728\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7199 - loss: 1.8451 - val_accuracy: 0.7545 - val_loss: 1.6411\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7452 - loss: 1.6264 - val_accuracy: 0.7750 - val_loss: 1.4674\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 1.4568 - val_accuracy: 0.7670 - val_loss: 1.3367\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 1.3036 - val_accuracy: 0.7752 - val_loss: 1.2603\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 1.1973 - val_accuracy: 0.7808 - val_loss: 1.1273\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 1.0920 - val_accuracy: 0.7873 - val_loss: 1.0415\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.9997 - val_accuracy: 0.8082 - val_loss: 0.9371\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.9307 - val_accuracy: 0.8120 - val_loss: 0.8912\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8063 - loss: 0.9145\n",
      "\n",
      "Test accuracy: 0.8062999844551086\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2625 - loss: 3.4834 - val_accuracy: 0.6247 - val_loss: 2.2650\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 2.1867 - val_accuracy: 0.7248 - val_loss: 1.8673\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 1.8767 - val_accuracy: 0.7502 - val_loss: 1.6553\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 1.6669 - val_accuracy: 0.7588 - val_loss: 1.4959\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 1.4949 - val_accuracy: 0.7530 - val_loss: 1.3492\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 1.3533 - val_accuracy: 0.7675 - val_loss: 1.2327\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7628 - loss: 1.2337 - val_accuracy: 0.7867 - val_loss: 1.1096\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 1.1355 - val_accuracy: 0.7915 - val_loss: 1.0270\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 1.0538 - val_accuracy: 0.7942 - val_loss: 0.9707\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7888 - loss: 0.9752 - val_accuracy: 0.8013 - val_loss: 0.9055\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7874 - loss: 0.9358\n",
      "\n",
      "Test accuracy: 0.7874000072479248\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1914 - loss: 27.7761 - val_accuracy: 0.2862 - val_loss: 6.5340\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2143 - loss: 4.2725 - val_accuracy: 0.0925 - val_loss: 2.3618\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3597 - val_accuracy: 0.0985 - val_loss: 2.3586\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0974 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.3586 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3586\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1028 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3585 - val_accuracy: 0.0973 - val_loss: 2.3586\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3586\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1014 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.1000 - loss: 2.3584\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1795 - loss: 27.7421 - val_accuracy: 0.5295 - val_loss: 6.1999\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 3.7375 - val_accuracy: 0.6397 - val_loss: 1.4162\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 1.4094 - val_accuracy: 0.6677 - val_loss: 1.2641\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6465 - loss: 1.2652 - val_accuracy: 0.6815 - val_loss: 1.1973\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6671 - loss: 1.1831 - val_accuracy: 0.6823 - val_loss: 1.1502\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6824 - loss: 1.1291 - val_accuracy: 0.7132 - val_loss: 1.0852\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 1.0853 - val_accuracy: 0.6830 - val_loss: 1.0916\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 1.0560 - val_accuracy: 0.6927 - val_loss: 1.0578\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 1.0359 - val_accuracy: 0.7050 - val_loss: 1.0161\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7074 - loss: 0.9982 - val_accuracy: 0.7170 - val_loss: 0.9847\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7059 - loss: 1.0091\n",
      "\n",
      "Test accuracy: 0.7059000134468079\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7155 - loss: 0.8032 - val_accuracy: 0.8632 - val_loss: 0.3769\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.3493 - val_accuracy: 0.8852 - val_loss: 0.3082\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.2866 - val_accuracy: 0.8953 - val_loss: 0.2833\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2630 - val_accuracy: 0.9058 - val_loss: 0.2584\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2393 - val_accuracy: 0.9062 - val_loss: 0.2539\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2245 - val_accuracy: 0.9072 - val_loss: 0.2659\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.2050 - val_accuracy: 0.9090 - val_loss: 0.2471\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.1842 - val_accuracy: 0.9162 - val_loss: 0.2335\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.1770 - val_accuracy: 0.9130 - val_loss: 0.2415\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.1604 - val_accuracy: 0.9205 - val_loss: 0.2243\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9106 - loss: 0.2473\n",
      "\n",
      "Test accuracy: 0.9106000065803528\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.6803 - loss: 0.8819 - val_accuracy: 0.8573 - val_loss: 0.3799\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8626 - loss: 0.3758 - val_accuracy: 0.8738 - val_loss: 0.3430\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3287 - val_accuracy: 0.8863 - val_loss: 0.2947\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2910 - val_accuracy: 0.8933 - val_loss: 0.2805\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8992 - loss: 0.2736 - val_accuracy: 0.9033 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9052 - loss: 0.2611 - val_accuracy: 0.9052 - val_loss: 0.2583\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2399 - val_accuracy: 0.9070 - val_loss: 0.2489\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2243 - val_accuracy: 0.9112 - val_loss: 0.2436\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.2221 - val_accuracy: 0.9085 - val_loss: 0.2490\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.2096 - val_accuracy: 0.9100 - val_loss: 0.2373\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9080 - loss: 0.2565\n",
      "\n",
      "Test accuracy: 0.9079999923706055\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6902 - loss: 1.4184 - val_accuracy: 0.8355 - val_loss: 0.5970\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.5813 - val_accuracy: 0.8467 - val_loss: 0.5397\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.5337 - val_accuracy: 0.8527 - val_loss: 0.5089\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8596 - loss: 0.5040 - val_accuracy: 0.8512 - val_loss: 0.5094\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.4829 - val_accuracy: 0.8615 - val_loss: 0.4764\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.4686 - val_accuracy: 0.8700 - val_loss: 0.4523\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.4503 - val_accuracy: 0.8763 - val_loss: 0.4431\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.4440 - val_accuracy: 0.8743 - val_loss: 0.4396\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.4312 - val_accuracy: 0.8720 - val_loss: 0.4419\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.4287 - val_accuracy: 0.8783 - val_loss: 0.4281\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8759 - loss: 0.4397\n",
      "\n",
      "Test accuracy: 0.8758999705314636\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6718 - loss: 1.4711 - val_accuracy: 0.8228 - val_loss: 0.6178\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.6056 - val_accuracy: 0.8408 - val_loss: 0.5632\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 0.5622 - val_accuracy: 0.8505 - val_loss: 0.5267\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.5279 - val_accuracy: 0.8580 - val_loss: 0.5009\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8559 - loss: 0.5114 - val_accuracy: 0.8547 - val_loss: 0.5108\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.4899 - val_accuracy: 0.8583 - val_loss: 0.4945\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.4848 - val_accuracy: 0.8635 - val_loss: 0.4783\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8675 - loss: 0.4631 - val_accuracy: 0.8700 - val_loss: 0.4728\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.4675 - val_accuracy: 0.8673 - val_loss: 0.4576\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.4510 - val_accuracy: 0.8705 - val_loss: 0.4527\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8674 - loss: 0.4661\n",
      "\n",
      "Test accuracy: 0.8673999905586243\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5287 - loss: 8.7370 - val_accuracy: 0.7623 - val_loss: 1.0173\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7597 - loss: 1.0022 - val_accuracy: 0.7795 - val_loss: 0.9089\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.9186 - val_accuracy: 0.7917 - val_loss: 0.8578\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.8685 - val_accuracy: 0.7982 - val_loss: 0.8206\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.8258 - val_accuracy: 0.8002 - val_loss: 0.8083\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.8030 - val_accuracy: 0.8052 - val_loss: 0.7765\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.7757 - val_accuracy: 0.8128 - val_loss: 0.7540\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.7700 - val_accuracy: 0.8107 - val_loss: 0.7454\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.7462 - val_accuracy: 0.8165 - val_loss: 0.7346\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.7365 - val_accuracy: 0.8193 - val_loss: 0.7336\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8083 - loss: 0.7650\n",
      "\n",
      "Test accuracy: 0.8083000183105469\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1156 - loss: 9.3620 - val_accuracy: 0.0942 - val_loss: 2.4365\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0993 - loss: 2.4369 - val_accuracy: 0.1008 - val_loss: 2.4365\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.4362 - val_accuracy: 0.0925 - val_loss: 2.4358\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0973 - loss: 2.4356 - val_accuracy: 0.0925 - val_loss: 2.4355\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0961 - loss: 2.4356 - val_accuracy: 0.0925 - val_loss: 2.4358\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0997 - loss: 2.4356 - val_accuracy: 0.0985 - val_loss: 2.4361\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.4356 - val_accuracy: 0.0942 - val_loss: 2.4363\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1005 - loss: 2.4356 - val_accuracy: 0.0925 - val_loss: 2.4361\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1013 - loss: 2.4356 - val_accuracy: 0.0925 - val_loss: 2.4358\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 2.4356 - val_accuracy: 0.0942 - val_loss: 2.4361\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.1000 - loss: 2.4359\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3606 - loss: 1.9232 - val_accuracy: 0.7175 - val_loss: 0.8575\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.8138 - val_accuracy: 0.7577 - val_loss: 0.6689\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7621 - loss: 0.6692 - val_accuracy: 0.7833 - val_loss: 0.5965\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.6021 - val_accuracy: 0.7970 - val_loss: 0.5478\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.5562 - val_accuracy: 0.8110 - val_loss: 0.5181\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.5255 - val_accuracy: 0.8177 - val_loss: 0.4935\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4911 - val_accuracy: 0.8255 - val_loss: 0.4744\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.4731 - val_accuracy: 0.8330 - val_loss: 0.4568\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8368 - loss: 0.4566 - val_accuracy: 0.8343 - val_loss: 0.4400\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.4378 - val_accuracy: 0.8432 - val_loss: 0.4203\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8401 - loss: 0.4452\n",
      "\n",
      "Test accuracy: 0.8400999903678894\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2978 - loss: 2.1540 - val_accuracy: 0.6795 - val_loss: 1.0041\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.9078 - val_accuracy: 0.7465 - val_loss: 0.6945\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6956 - val_accuracy: 0.7750 - val_loss: 0.6151\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 0.6287 - val_accuracy: 0.7902 - val_loss: 0.5602\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.5851 - val_accuracy: 0.8047 - val_loss: 0.5212\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.5458 - val_accuracy: 0.8172 - val_loss: 0.4980\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.5212 - val_accuracy: 0.8167 - val_loss: 0.4903\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8218 - loss: 0.4885 - val_accuracy: 0.8275 - val_loss: 0.4692\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4792 - val_accuracy: 0.8380 - val_loss: 0.4461\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.4552 - val_accuracy: 0.8370 - val_loss: 0.4439\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8279 - loss: 0.4687\n",
      "\n",
      "Test accuracy: 0.8278999924659729\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3278 - loss: 3.4437 - val_accuracy: 0.6935 - val_loss: 2.2469\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7069 - loss: 2.1417 - val_accuracy: 0.7455 - val_loss: 1.8597\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 1.8170 - val_accuracy: 0.7702 - val_loss: 1.6237\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 1.5969 - val_accuracy: 0.7770 - val_loss: 1.4514\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 1.4180 - val_accuracy: 0.7895 - val_loss: 1.2929\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 1.2812 - val_accuracy: 0.7973 - val_loss: 1.1687\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 1.1502 - val_accuracy: 0.8070 - val_loss: 1.0691\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 1.0633 - val_accuracy: 0.8070 - val_loss: 0.9888\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.9734 - val_accuracy: 0.8185 - val_loss: 0.9107\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.9007 - val_accuracy: 0.8230 - val_loss: 0.8489\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8217 - loss: 0.8750\n",
      "\n",
      "Test accuracy: 0.8216999769210815\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3159 - loss: 3.5567 - val_accuracy: 0.6432 - val_loss: 2.3651\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6634 - loss: 2.2361 - val_accuracy: 0.7203 - val_loss: 1.8876\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 1.8419 - val_accuracy: 0.7638 - val_loss: 1.6312\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7498 - loss: 1.6224 - val_accuracy: 0.7750 - val_loss: 1.4451\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 1.4372 - val_accuracy: 0.7895 - val_loss: 1.3016\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 1.2936 - val_accuracy: 0.7917 - val_loss: 1.1910\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7913 - loss: 1.1817 - val_accuracy: 0.7987 - val_loss: 1.0833\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 1.0833 - val_accuracy: 0.8063 - val_loss: 0.9905\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.9967 - val_accuracy: 0.8135 - val_loss: 0.9230\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.9273 - val_accuracy: 0.8183 - val_loss: 0.8617\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8128 - loss: 0.8857\n",
      "\n",
      "Test accuracy: 0.8127999901771545\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2341 - loss: 27.6189 - val_accuracy: 0.4913 - val_loss: 6.4403\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5510 - loss: 4.1912 - val_accuracy: 0.6060 - val_loss: 1.7665\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 1.6585 - val_accuracy: 0.6358 - val_loss: 1.4152\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6381 - loss: 1.3813 - val_accuracy: 0.6670 - val_loss: 1.2684\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6688 - loss: 1.2551 - val_accuracy: 0.6878 - val_loss: 1.1764\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 1.1772 - val_accuracy: 0.7065 - val_loss: 1.1128\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7008 - loss: 1.1180 - val_accuracy: 0.7193 - val_loss: 1.0655\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7106 - loss: 1.0787 - val_accuracy: 0.7288 - val_loss: 1.0275\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 1.0392 - val_accuracy: 0.7320 - val_loss: 1.0009\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 1.0140 - val_accuracy: 0.7362 - val_loss: 0.9778\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7257 - loss: 1.0108\n",
      "\n",
      "Test accuracy: 0.7257000207901001\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2274 - loss: 27.6574 - val_accuracy: 0.3333 - val_loss: 6.5434\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3458 - loss: 4.3480 - val_accuracy: 0.5290 - val_loss: 1.8954\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5566 - loss: 1.7472 - val_accuracy: 0.6142 - val_loss: 1.4554\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 1.4412 - val_accuracy: 0.6388 - val_loss: 1.3138\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6352 - loss: 1.3171 - val_accuracy: 0.6622 - val_loss: 1.2193\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6549 - loss: 1.2419 - val_accuracy: 0.6872 - val_loss: 1.1585\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 1.1843 - val_accuracy: 0.6897 - val_loss: 1.1177\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6792 - loss: 1.1441 - val_accuracy: 0.6985 - val_loss: 1.0806\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 1.1187 - val_accuracy: 0.7040 - val_loss: 1.0487\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 1.0882 - val_accuracy: 0.7140 - val_loss: 1.0234\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.6949 - loss: 1.0589\n",
      "\n",
      "Test accuracy: 0.6948999762535095\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6798 - loss: 0.8829 - val_accuracy: 0.8655 - val_loss: 0.3781\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.3603 - val_accuracy: 0.8880 - val_loss: 0.3152\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.2998 - val_accuracy: 0.8932 - val_loss: 0.2990\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.2689 - val_accuracy: 0.9000 - val_loss: 0.2834\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2456 - val_accuracy: 0.9045 - val_loss: 0.2670\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9196 - loss: 0.2241 - val_accuracy: 0.9075 - val_loss: 0.2630\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2101 - val_accuracy: 0.9127 - val_loss: 0.2531\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.1954 - val_accuracy: 0.9135 - val_loss: 0.2425\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9340 - loss: 0.1803 - val_accuracy: 0.9205 - val_loss: 0.2287\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.1646 - val_accuracy: 0.9200 - val_loss: 0.2265\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9131 - loss: 0.2433\n",
      "\n",
      "Test accuracy: 0.913100004196167\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6660 - loss: 0.9051 - val_accuracy: 0.8568 - val_loss: 0.3901\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.3878 - val_accuracy: 0.8788 - val_loss: 0.3184\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8819 - loss: 0.3268 - val_accuracy: 0.8813 - val_loss: 0.3099\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.2945 - val_accuracy: 0.8988 - val_loss: 0.2682\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.2644 - val_accuracy: 0.9100 - val_loss: 0.2518\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.2459 - val_accuracy: 0.9042 - val_loss: 0.2610\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2386 - val_accuracy: 0.9110 - val_loss: 0.2437\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2197 - val_accuracy: 0.9112 - val_loss: 0.2363\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2082 - val_accuracy: 0.9153 - val_loss: 0.2335\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9286 - loss: 0.1945 - val_accuracy: 0.9197 - val_loss: 0.2232\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9140 - loss: 0.2380\n",
      "\n",
      "Test accuracy: 0.9139999747276306\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6164 - loss: 1.5425 - val_accuracy: 0.8133 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.6950 - val_accuracy: 0.8175 - val_loss: 0.6535\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.6261 - val_accuracy: 0.8263 - val_loss: 0.6065\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 0.5797 - val_accuracy: 0.8408 - val_loss: 0.5513\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 0.5497 - val_accuracy: 0.8460 - val_loss: 0.5401\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.5319 - val_accuracy: 0.8437 - val_loss: 0.5306\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8541 - loss: 0.5143 - val_accuracy: 0.8532 - val_loss: 0.5217\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.5058 - val_accuracy: 0.8547 - val_loss: 0.5033\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.4975 - val_accuracy: 0.8588 - val_loss: 0.4935\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.4889 - val_accuracy: 0.8573 - val_loss: 0.5038\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8529 - loss: 0.5185\n",
      "\n",
      "Test accuracy: 0.8529000282287598\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6024 - loss: 1.5686 - val_accuracy: 0.7910 - val_loss: 0.7440\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8000 - loss: 0.7195 - val_accuracy: 0.8280 - val_loss: 0.6324\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.6311 - val_accuracy: 0.8443 - val_loss: 0.5777\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.6011 - val_accuracy: 0.8422 - val_loss: 0.5764\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 0.5799 - val_accuracy: 0.8478 - val_loss: 0.5530\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.5636 - val_accuracy: 0.8452 - val_loss: 0.5537\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.5520 - val_accuracy: 0.8555 - val_loss: 0.5234\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.5319 - val_accuracy: 0.8605 - val_loss: 0.5186\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.5304 - val_accuracy: 0.8557 - val_loss: 0.5228\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.5188 - val_accuracy: 0.8573 - val_loss: 0.5042\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8528 - loss: 0.5258\n",
      "\n",
      "Test accuracy: 0.8528000116348267\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4734 - loss: 8.7594 - val_accuracy: 0.7308 - val_loss: 1.0513\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 1.0332 - val_accuracy: 0.7702 - val_loss: 0.9457\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.9413 - val_accuracy: 0.7907 - val_loss: 0.8867\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.8813 - val_accuracy: 0.7967 - val_loss: 0.8404\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.8377 - val_accuracy: 0.7987 - val_loss: 0.8208\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.7966 - val_accuracy: 0.8147 - val_loss: 0.7756\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.7677 - val_accuracy: 0.8180 - val_loss: 0.7642\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.7469 - val_accuracy: 0.8227 - val_loss: 0.7603\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.7403 - val_accuracy: 0.8295 - val_loss: 0.7327\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.7297 - val_accuracy: 0.8253 - val_loss: 0.7302\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8229 - loss: 0.7493\n",
      "\n",
      "Test accuracy: 0.8228999972343445\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.4581 - loss: 8.9429 - val_accuracy: 0.6730 - val_loss: 1.2087\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6815 - loss: 1.1609 - val_accuracy: 0.7275 - val_loss: 1.0809\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 1.0902 - val_accuracy: 0.7272 - val_loss: 1.0475\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 1.0519 - val_accuracy: 0.7000 - val_loss: 1.0833\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 1.0376 - val_accuracy: 0.7052 - val_loss: 1.0683\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 1.0188 - val_accuracy: 0.6955 - val_loss: 1.0690\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 0.9937 - val_accuracy: 0.7028 - val_loss: 1.0391\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.9811 - val_accuracy: 0.7348 - val_loss: 0.9852\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7291 - loss: 0.9708 - val_accuracy: 0.7038 - val_loss: 1.0184\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.9550 - val_accuracy: 0.7187 - val_loss: 1.0142\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7093 - loss: 1.0321\n",
      "\n",
      "Test accuracy: 0.7092999815940857\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.1995 - loss: 2.1553 - val_accuracy: 0.6645 - val_loss: 0.8931\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.8829 - val_accuracy: 0.7555 - val_loss: 0.6791\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.7132 - val_accuracy: 0.7572 - val_loss: 0.6391\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.6544 - val_accuracy: 0.7705 - val_loss: 0.6085\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.5973 - val_accuracy: 0.7905 - val_loss: 0.5532\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.5496 - val_accuracy: 0.8120 - val_loss: 0.5163\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.5073 - val_accuracy: 0.8187 - val_loss: 0.5004\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.4886 - val_accuracy: 0.8135 - val_loss: 0.5025\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.4675 - val_accuracy: 0.8378 - val_loss: 0.4611\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 0.4441 - val_accuracy: 0.8407 - val_loss: 0.4346\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8405 - loss: 0.4554\n",
      "\n",
      "Test accuracy: 0.840499997138977\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2582 - loss: 2.1055 - val_accuracy: 0.6295 - val_loss: 0.9496\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6372 - loss: 0.9641 - val_accuracy: 0.7012 - val_loss: 0.7728\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6835 - loss: 0.8188 - val_accuracy: 0.7225 - val_loss: 0.7048\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.7376 - val_accuracy: 0.7538 - val_loss: 0.6687\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 0.6988 - val_accuracy: 0.7753 - val_loss: 0.6161\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.6564 - val_accuracy: 0.7712 - val_loss: 0.5929\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7689 - loss: 0.6213 - val_accuracy: 0.7903 - val_loss: 0.5662\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7782 - loss: 0.5965 - val_accuracy: 0.8047 - val_loss: 0.5363\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.5753 - val_accuracy: 0.8110 - val_loss: 0.5174\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.5481 - val_accuracy: 0.8172 - val_loss: 0.4999\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8096 - loss: 0.5271\n",
      "\n",
      "Test accuracy: 0.8095999956130981\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1857 - loss: 3.6915 - val_accuracy: 0.5972 - val_loss: 2.4373\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6066 - loss: 2.3187 - val_accuracy: 0.7238 - val_loss: 1.9161\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 1.8761 - val_accuracy: 0.7498 - val_loss: 1.6574\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 1.6326 - val_accuracy: 0.7657 - val_loss: 1.4653\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 1.4560 - val_accuracy: 0.7803 - val_loss: 1.3181\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7747 - loss: 1.3127 - val_accuracy: 0.7540 - val_loss: 1.2536\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 1.1928 - val_accuracy: 0.8068 - val_loss: 1.0902\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 1.0913 - val_accuracy: 0.8057 - val_loss: 1.0045\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 1.0098 - val_accuracy: 0.7962 - val_loss: 0.9661\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.9299 - val_accuracy: 0.8163 - val_loss: 0.8779\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8072 - loss: 0.9088\n",
      "\n",
      "Test accuracy: 0.807200014591217\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2024 - loss: 3.5873 - val_accuracy: 0.5523 - val_loss: 2.4144\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6263 - loss: 2.2380 - val_accuracy: 0.7150 - val_loss: 1.8998\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 1.8965 - val_accuracy: 0.7290 - val_loss: 1.6721\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7145 - loss: 1.6734 - val_accuracy: 0.7463 - val_loss: 1.4997\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 1.4975 - val_accuracy: 0.7593 - val_loss: 1.3429\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7472 - loss: 1.3540 - val_accuracy: 0.7682 - val_loss: 1.2305\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 1.2571 - val_accuracy: 0.7853 - val_loss: 1.1126\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7647 - loss: 1.1405 - val_accuracy: 0.7723 - val_loss: 1.0416\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 1.0519 - val_accuracy: 0.7932 - val_loss: 0.9676\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7815 - loss: 0.9763 - val_accuracy: 0.7943 - val_loss: 0.8967\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7893 - loss: 0.9231\n",
      "\n",
      "Test accuracy: 0.7893000245094299\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2548 - loss: 27.7073 - val_accuracy: 0.1723 - val_loss: 6.5115\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1157 - loss: 4.2660 - val_accuracy: 0.0925 - val_loss: 2.3629\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3606 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3585 - val_accuracy: 0.0973 - val_loss: 2.3587\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3586 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3585 - val_accuracy: 0.1027 - val_loss: 2.3585\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3586 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3586 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.1000 - loss: 2.3585\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1199 - loss: 27.8924 - val_accuracy: 0.1558 - val_loss: 6.4737\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1200 - loss: 4.2224 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3585 - val_accuracy: 0.0985 - val_loss: 2.3587\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3585 - val_accuracy: 0.0985 - val_loss: 2.3588\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3585 - val_accuracy: 0.0985 - val_loss: 2.3588\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1007 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3589\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.1000 - loss: 2.3586\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7078 - loss: 0.8211 - val_accuracy: 0.8618 - val_loss: 0.3591\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.3387 - val_accuracy: 0.8863 - val_loss: 0.3038\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.2865 - val_accuracy: 0.8895 - val_loss: 0.2984\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2574 - val_accuracy: 0.9093 - val_loss: 0.2552\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.2328 - val_accuracy: 0.9078 - val_loss: 0.2519\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2144 - val_accuracy: 0.9067 - val_loss: 0.2510\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.1968 - val_accuracy: 0.9032 - val_loss: 0.2658\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1861 - val_accuracy: 0.9112 - val_loss: 0.2390\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9387 - loss: 0.1674 - val_accuracy: 0.9112 - val_loss: 0.2409\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1587 - val_accuracy: 0.9160 - val_loss: 0.2311\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9129 - loss: 0.2504\n",
      "\n",
      "Test accuracy: 0.9128999710083008\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7079 - loss: 0.8264 - val_accuracy: 0.8667 - val_loss: 0.3702\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8628 - loss: 0.3792 - val_accuracy: 0.8825 - val_loss: 0.3246\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8845 - loss: 0.3143 - val_accuracy: 0.8918 - val_loss: 0.2940\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.2830 - val_accuracy: 0.8973 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9044 - loss: 0.2622 - val_accuracy: 0.9038 - val_loss: 0.2623\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.2501 - val_accuracy: 0.9082 - val_loss: 0.2456\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9159 - loss: 0.2342 - val_accuracy: 0.9132 - val_loss: 0.2430\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2267 - val_accuracy: 0.9138 - val_loss: 0.2350\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2164 - val_accuracy: 0.9150 - val_loss: 0.2378\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2046 - val_accuracy: 0.9152 - val_loss: 0.2370\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9076 - loss: 0.2604\n",
      "\n",
      "Test accuracy: 0.9075999855995178\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.6766 - loss: 1.4564 - val_accuracy: 0.8273 - val_loss: 0.6202\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.5919 - val_accuracy: 0.8368 - val_loss: 0.5622\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.5397 - val_accuracy: 0.8453 - val_loss: 0.5222\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.5149 - val_accuracy: 0.8513 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.5038 - val_accuracy: 0.8615 - val_loss: 0.4784\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.4832 - val_accuracy: 0.8687 - val_loss: 0.4632\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.4623 - val_accuracy: 0.8687 - val_loss: 0.4648\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.4578 - val_accuracy: 0.8715 - val_loss: 0.4457\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8749 - loss: 0.4467 - val_accuracy: 0.8715 - val_loss: 0.4605\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.4423 - val_accuracy: 0.8747 - val_loss: 0.4337\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8695 - loss: 0.4561\n",
      "\n",
      "Test accuracy: 0.8694999814033508\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6731 - loss: 1.4752 - val_accuracy: 0.8200 - val_loss: 0.6184\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.6240 - val_accuracy: 0.8147 - val_loss: 0.6156\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.5608 - val_accuracy: 0.8483 - val_loss: 0.5359\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.5373 - val_accuracy: 0.8480 - val_loss: 0.5304\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8539 - loss: 0.5161 - val_accuracy: 0.8582 - val_loss: 0.5067\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.5118 - val_accuracy: 0.8608 - val_loss: 0.4906\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.4949 - val_accuracy: 0.8555 - val_loss: 0.4952\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.4896 - val_accuracy: 0.8612 - val_loss: 0.4888\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.4783 - val_accuracy: 0.8642 - val_loss: 0.4709\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.4647 - val_accuracy: 0.8655 - val_loss: 0.4630\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8642 - loss: 0.4743\n",
      "\n",
      "Test accuracy: 0.8641999959945679\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4999 - loss: 8.7868 - val_accuracy: 0.7580 - val_loss: 1.0548\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 1.0315 - val_accuracy: 0.7833 - val_loss: 0.9141\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.9128 - val_accuracy: 0.8008 - val_loss: 0.8520\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8010 - loss: 0.8530 - val_accuracy: 0.8100 - val_loss: 0.8179\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.8266 - val_accuracy: 0.8072 - val_loss: 0.8038\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.8082 - val_accuracy: 0.8182 - val_loss: 0.7793\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.7878 - val_accuracy: 0.8235 - val_loss: 0.7701\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.7708 - val_accuracy: 0.8235 - val_loss: 0.7543\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.7513 - val_accuracy: 0.8285 - val_loss: 0.7425\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.7405 - val_accuracy: 0.8277 - val_loss: 0.7284\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8263 - loss: 0.7514\n",
      "\n",
      "Test accuracy: 0.8263000249862671\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5094 - loss: 8.8322 - val_accuracy: 0.7342 - val_loss: 1.0772\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 1.0847 - val_accuracy: 0.7598 - val_loss: 0.9587\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7511 - loss: 0.9839 - val_accuracy: 0.7737 - val_loss: 0.9155\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7568 - loss: 0.9544 - val_accuracy: 0.7642 - val_loss: 0.8997\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7628 - loss: 0.9314 - val_accuracy: 0.7750 - val_loss: 0.8854\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.9135 - val_accuracy: 0.7808 - val_loss: 0.8689\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.8954 - val_accuracy: 0.7808 - val_loss: 0.8603\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.8916 - val_accuracy: 0.7888 - val_loss: 0.8403\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.8756 - val_accuracy: 0.7888 - val_loss: 0.8486\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.8699 - val_accuracy: 0.7898 - val_loss: 0.8248\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7776 - loss: 0.8614\n",
      "\n",
      "Test accuracy: 0.7775999903678894\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3543 - loss: 1.9685 - val_accuracy: 0.7000 - val_loss: 0.8931\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.8271 - val_accuracy: 0.7627 - val_loss: 0.6736\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6672 - val_accuracy: 0.7778 - val_loss: 0.5984\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.5939 - val_accuracy: 0.7978 - val_loss: 0.5453\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.5461 - val_accuracy: 0.8100 - val_loss: 0.5103\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.5134 - val_accuracy: 0.8215 - val_loss: 0.4810\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.4829 - val_accuracy: 0.8317 - val_loss: 0.4607\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.4561 - val_accuracy: 0.8373 - val_loss: 0.4420\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.4440 - val_accuracy: 0.8410 - val_loss: 0.4293\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.4225 - val_accuracy: 0.8482 - val_loss: 0.4129\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8468 - loss: 0.4329\n",
      "\n",
      "Test accuracy: 0.8468000292778015\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3380 - loss: 1.9437 - val_accuracy: 0.6972 - val_loss: 0.8544\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 0.8338 - val_accuracy: 0.7482 - val_loss: 0.6816\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.7027 - val_accuracy: 0.7722 - val_loss: 0.6070\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7638 - loss: 0.6363 - val_accuracy: 0.7853 - val_loss: 0.5656\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7832 - loss: 0.5885 - val_accuracy: 0.7942 - val_loss: 0.5373\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.5626 - val_accuracy: 0.8057 - val_loss: 0.5137\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.5388 - val_accuracy: 0.8190 - val_loss: 0.4816\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.5167 - val_accuracy: 0.8228 - val_loss: 0.4659\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.4825 - val_accuracy: 0.8265 - val_loss: 0.4566\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.4673 - val_accuracy: 0.8335 - val_loss: 0.4361\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8277 - loss: 0.4616\n",
      "\n",
      "Test accuracy: 0.8277000188827515\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3944 - loss: 3.3767 - val_accuracy: 0.7085 - val_loss: 2.2112\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7133 - loss: 2.1127 - val_accuracy: 0.7552 - val_loss: 1.8342\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 1.7870 - val_accuracy: 0.7710 - val_loss: 1.5993\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 1.5702 - val_accuracy: 0.7842 - val_loss: 1.4238\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 1.4003 - val_accuracy: 0.7962 - val_loss: 1.2802\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 1.2689 - val_accuracy: 0.7970 - val_loss: 1.1665\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8026 - loss: 1.1538 - val_accuracy: 0.8095 - val_loss: 1.0665\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8126 - loss: 1.0538 - val_accuracy: 0.8138 - val_loss: 0.9860\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.9780 - val_accuracy: 0.8148 - val_loss: 0.9174\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.9020 - val_accuracy: 0.8228 - val_loss: 0.8528\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8180 - loss: 0.8797\n",
      "\n",
      "Test accuracy: 0.8180000185966492\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2266 - loss: 3.5142 - val_accuracy: 0.6863 - val_loss: 2.2464\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6982 - loss: 2.1445 - val_accuracy: 0.7482 - val_loss: 1.8426\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7409 - loss: 1.8145 - val_accuracy: 0.7627 - val_loss: 1.6084\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7646 - loss: 1.5927 - val_accuracy: 0.7802 - val_loss: 1.4241\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 1.4140 - val_accuracy: 0.7955 - val_loss: 1.2837\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 1.2716 - val_accuracy: 0.8005 - val_loss: 1.1617\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 1.1594 - val_accuracy: 0.8087 - val_loss: 1.0615\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 1.0653 - val_accuracy: 0.8155 - val_loss: 0.9762\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.9770 - val_accuracy: 0.8228 - val_loss: 0.9074\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.9100 - val_accuracy: 0.8235 - val_loss: 0.8459\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8178 - loss: 0.8687\n",
      "\n",
      "Test accuracy: 0.817799985408783\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2894 - loss: 27.8349 - val_accuracy: 0.5837 - val_loss: 6.4470\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 4.2338 - val_accuracy: 0.6192 - val_loss: 1.7953\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6194 - loss: 1.6881 - val_accuracy: 0.6520 - val_loss: 1.4542\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6502 - loss: 1.4274 - val_accuracy: 0.6858 - val_loss: 1.3068\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6775 - loss: 1.3018 - val_accuracy: 0.6972 - val_loss: 1.2102\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6937 - loss: 1.2121 - val_accuracy: 0.7115 - val_loss: 1.1397\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7081 - loss: 1.1437 - val_accuracy: 0.7198 - val_loss: 1.0882\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7210 - loss: 1.0958 - val_accuracy: 0.7372 - val_loss: 1.0450\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7266 - loss: 1.0569 - val_accuracy: 0.7385 - val_loss: 1.0107\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 1.0312 - val_accuracy: 0.7430 - val_loss: 0.9852\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7301 - loss: 1.0259\n",
      "\n",
      "Test accuracy: 0.7300999760627747\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2473 - loss: 27.5845 - val_accuracy: 0.4555 - val_loss: 6.4370\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4798 - loss: 4.2640 - val_accuracy: 0.6113 - val_loss: 1.8424\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5983 - loss: 1.7359 - val_accuracy: 0.6433 - val_loss: 1.4607\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6321 - loss: 1.4405 - val_accuracy: 0.6723 - val_loss: 1.2980\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 1.3048 - val_accuracy: 0.6813 - val_loss: 1.2064\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6666 - loss: 1.2232 - val_accuracy: 0.6890 - val_loss: 1.1426\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6744 - loss: 1.1732 - val_accuracy: 0.6948 - val_loss: 1.1000\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6846 - loss: 1.1322 - val_accuracy: 0.7107 - val_loss: 1.0663\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6900 - loss: 1.0989 - val_accuracy: 0.7162 - val_loss: 1.0371\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6901 - loss: 1.0843 - val_accuracy: 0.7163 - val_loss: 1.0177\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.6987 - loss: 1.0556\n",
      "\n",
      "Test accuracy: 0.6987000107765198\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6706 - loss: 0.9156 - val_accuracy: 0.8395 - val_loss: 0.4344\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.3664 - val_accuracy: 0.8760 - val_loss: 0.3393\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8875 - loss: 0.3154 - val_accuracy: 0.8910 - val_loss: 0.3001\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.2764 - val_accuracy: 0.8993 - val_loss: 0.2743\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9098 - loss: 0.2507 - val_accuracy: 0.9023 - val_loss: 0.2719\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.2291 - val_accuracy: 0.9117 - val_loss: 0.2484\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2070 - val_accuracy: 0.8923 - val_loss: 0.2908\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2000 - val_accuracy: 0.9045 - val_loss: 0.2822\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.1807 - val_accuracy: 0.9115 - val_loss: 0.2512\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9409 - loss: 0.1675 - val_accuracy: 0.9142 - val_loss: 0.2420\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9102 - loss: 0.2486\n",
      "\n",
      "Test accuracy: 0.9101999998092651\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6534 - loss: 0.9398 - val_accuracy: 0.8417 - val_loss: 0.4323\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 0.4051 - val_accuracy: 0.8708 - val_loss: 0.3362\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8822 - loss: 0.3341 - val_accuracy: 0.8928 - val_loss: 0.2888\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.3006 - val_accuracy: 0.8988 - val_loss: 0.2739\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.2763 - val_accuracy: 0.9037 - val_loss: 0.2597\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.2594 - val_accuracy: 0.9047 - val_loss: 0.2517\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2451 - val_accuracy: 0.9108 - val_loss: 0.2417\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2342 - val_accuracy: 0.9142 - val_loss: 0.2315\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2141 - val_accuracy: 0.9080 - val_loss: 0.2548\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2077 - val_accuracy: 0.9120 - val_loss: 0.2366\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9091 - loss: 0.2594\n",
      "\n",
      "Test accuracy: 0.9090999960899353\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6514 - loss: 1.4893 - val_accuracy: 0.7962 - val_loss: 0.7254\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.6789 - val_accuracy: 0.8375 - val_loss: 0.6021\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.5781 - val_accuracy: 0.8370 - val_loss: 0.5662\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.5532 - val_accuracy: 0.8518 - val_loss: 0.5283\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.5253 - val_accuracy: 0.8540 - val_loss: 0.5267\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.5084 - val_accuracy: 0.8562 - val_loss: 0.4996\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.4904 - val_accuracy: 0.8487 - val_loss: 0.5132\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.4785 - val_accuracy: 0.8647 - val_loss: 0.4792\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.4615 - val_accuracy: 0.8672 - val_loss: 0.4684\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.4563 - val_accuracy: 0.8667 - val_loss: 0.4523\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8610 - loss: 0.4733\n",
      "\n",
      "Test accuracy: 0.8610000014305115\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6049 - loss: 1.5966 - val_accuracy: 0.7995 - val_loss: 0.7310\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.7319 - val_accuracy: 0.8282 - val_loss: 0.6416\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.6564 - val_accuracy: 0.8330 - val_loss: 0.6061\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.6264 - val_accuracy: 0.8253 - val_loss: 0.6138\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.6023 - val_accuracy: 0.8460 - val_loss: 0.5623\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.5877 - val_accuracy: 0.8405 - val_loss: 0.5789\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.5769 - val_accuracy: 0.8537 - val_loss: 0.5332\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8457 - loss: 0.5589 - val_accuracy: 0.8528 - val_loss: 0.5302\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.5455 - val_accuracy: 0.8493 - val_loss: 0.5353\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.5352 - val_accuracy: 0.8475 - val_loss: 0.5256\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8484 - loss: 0.5424\n",
      "\n",
      "Test accuracy: 0.8483999967575073\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1314 - loss: 9.3818 - val_accuracy: 0.1008 - val_loss: 2.4381\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.4379 - val_accuracy: 0.0985 - val_loss: 2.4381\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1018 - loss: 2.4376 - val_accuracy: 0.0942 - val_loss: 2.4380\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 2.4376 - val_accuracy: 0.0973 - val_loss: 2.4381\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0991 - loss: 2.4376 - val_accuracy: 0.0942 - val_loss: 2.4383\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1018 - loss: 2.4375 - val_accuracy: 0.1003 - val_loss: 2.4381\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0953 - loss: 2.4376 - val_accuracy: 0.0925 - val_loss: 2.4382\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.4376 - val_accuracy: 0.1003 - val_loss: 2.4381\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0987 - loss: 2.4376 - val_accuracy: 0.0925 - val_loss: 2.4378\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1010 - loss: 2.4375 - val_accuracy: 0.0925 - val_loss: 2.4371\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.1000 - loss: 2.4369\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3932 - loss: 8.8842 - val_accuracy: 0.7050 - val_loss: 1.1939\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6861 - loss: 1.1746 - val_accuracy: 0.7012 - val_loss: 1.1179\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7017 - loss: 1.0973 - val_accuracy: 0.7358 - val_loss: 1.0594\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7137 - loss: 1.0519 - val_accuracy: 0.6937 - val_loss: 1.0718\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 1.0240 - val_accuracy: 0.7322 - val_loss: 1.0258\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 1.0120 - val_accuracy: 0.7282 - val_loss: 1.0311\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.9899 - val_accuracy: 0.7520 - val_loss: 0.9680\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.9814 - val_accuracy: 0.7495 - val_loss: 0.9707\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.9780 - val_accuracy: 0.7617 - val_loss: 0.9520\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.9587 - val_accuracy: 0.7480 - val_loss: 0.9778\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7317 - loss: 1.0011\n",
      "\n",
      "Test accuracy: 0.7317000031471252\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2577 - loss: 2.1189 - val_accuracy: 0.6120 - val_loss: 0.9823\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6406 - loss: 0.9300 - val_accuracy: 0.7443 - val_loss: 0.7537\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7291 - loss: 0.7402 - val_accuracy: 0.7652 - val_loss: 0.6266\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.6446 - val_accuracy: 0.7917 - val_loss: 0.5900\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.6003 - val_accuracy: 0.8023 - val_loss: 0.5529\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.5622 - val_accuracy: 0.8147 - val_loss: 0.5199\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.5305 - val_accuracy: 0.7977 - val_loss: 0.5455\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.5131 - val_accuracy: 0.8188 - val_loss: 0.4952\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4764 - val_accuracy: 0.8277 - val_loss: 0.4792\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.4653 - val_accuracy: 0.8327 - val_loss: 0.4707\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8209 - loss: 0.4970\n",
      "\n",
      "Test accuracy: 0.820900022983551\n",
      "Training model with activation=relu, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2704 - loss: 2.1637 - val_accuracy: 0.6108 - val_loss: 1.0260\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6112 - loss: 1.0225 - val_accuracy: 0.7150 - val_loss: 0.7961\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.8415 - val_accuracy: 0.7488 - val_loss: 0.7010\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.7601 - val_accuracy: 0.7517 - val_loss: 0.6662\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.7041 - val_accuracy: 0.7693 - val_loss: 0.6248\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 0.6613 - val_accuracy: 0.7745 - val_loss: 0.6174\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7696 - loss: 0.6217 - val_accuracy: 0.7783 - val_loss: 0.5765\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.5954 - val_accuracy: 0.7845 - val_loss: 0.5497\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.5792 - val_accuracy: 0.8045 - val_loss: 0.5228\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.5510 - val_accuracy: 0.8105 - val_loss: 0.5108\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8059 - loss: 0.5339\n",
      "\n",
      "Test accuracy: 0.805899977684021\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2531 - loss: 3.6877 - val_accuracy: 0.5985 - val_loss: 2.4337\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6445 - loss: 2.2394 - val_accuracy: 0.7205 - val_loss: 1.8831\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7180 - loss: 1.8488 - val_accuracy: 0.7453 - val_loss: 1.6361\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 1.6245 - val_accuracy: 0.7590 - val_loss: 1.4960\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 1.4488 - val_accuracy: 0.7608 - val_loss: 1.3515\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 1.3092 - val_accuracy: 0.7608 - val_loss: 1.2337\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 1.1886 - val_accuracy: 0.7992 - val_loss: 1.0956\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 1.0843 - val_accuracy: 0.7968 - val_loss: 1.0267\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.9997 - val_accuracy: 0.8177 - val_loss: 0.9343\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.9268 - val_accuracy: 0.8177 - val_loss: 0.8730\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8128 - loss: 0.8988\n",
      "\n",
      "Test accuracy: 0.8127999901771545\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2197 - loss: 3.5915 - val_accuracy: 0.6332 - val_loss: 2.2661\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 2.2278 - val_accuracy: 0.7055 - val_loss: 1.9073\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6862 - loss: 1.9085 - val_accuracy: 0.7173 - val_loss: 1.7034\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 1.6786 - val_accuracy: 0.7515 - val_loss: 1.4955\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 1.5042 - val_accuracy: 0.7325 - val_loss: 1.3780\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7377 - loss: 1.3734 - val_accuracy: 0.7602 - val_loss: 1.2409\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7522 - loss: 1.2492 - val_accuracy: 0.7548 - val_loss: 1.1466\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7608 - loss: 1.1471 - val_accuracy: 0.7830 - val_loss: 1.0356\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7693 - loss: 1.0619 - val_accuracy: 0.7915 - val_loss: 0.9616\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.9788 - val_accuracy: 0.7995 - val_loss: 0.8998\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7867 - loss: 0.9337\n",
      "\n",
      "Test accuracy: 0.7867000102996826\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1679 - loss: 27.7689 - val_accuracy: 0.2188 - val_loss: 6.4905\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1582 - loss: 4.2432 - val_accuracy: 0.0942 - val_loss: 2.3593\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.3587 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0982 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1026 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3588\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1014 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.1000 - loss: 2.3586\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2012 - loss: 27.6413 - val_accuracy: 0.1730 - val_loss: 6.4903\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1109 - loss: 4.2493 - val_accuracy: 0.0925 - val_loss: 2.3601\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1013 - loss: 2.3590 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 2.3585 - val_accuracy: 0.0973 - val_loss: 2.3587\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0979 - loss: 2.3585 - val_accuracy: 0.0942 - val_loss: 2.3587\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3588\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 2.3585 - val_accuracy: 0.0925 - val_loss: 2.3589\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1014 - loss: 2.3584 - val_accuracy: 0.0925 - val_loss: 2.3587\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.1000 - loss: 2.3586\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6838 - loss: 0.8709 - val_accuracy: 0.8613 - val_loss: 0.3695\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3514 - val_accuracy: 0.8798 - val_loss: 0.3194\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8894 - loss: 0.3003 - val_accuracy: 0.8918 - val_loss: 0.2905\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2691 - val_accuracy: 0.8955 - val_loss: 0.2861\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2466 - val_accuracy: 0.9030 - val_loss: 0.2652\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.2387 - val_accuracy: 0.9045 - val_loss: 0.2556\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 0.2148 - val_accuracy: 0.9052 - val_loss: 0.2636\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2016 - val_accuracy: 0.9108 - val_loss: 0.2427\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.1915 - val_accuracy: 0.9105 - val_loss: 0.2432\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9369 - loss: 0.1721 - val_accuracy: 0.9110 - val_loss: 0.2423\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9058 - loss: 0.2666\n",
      "\n",
      "Test accuracy: 0.9057999849319458\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.8554 - val_accuracy: 0.8542 - val_loss: 0.3954\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.3747 - val_accuracy: 0.8792 - val_loss: 0.3257\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3217 - val_accuracy: 0.8748 - val_loss: 0.3326\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8893 - loss: 0.2987 - val_accuracy: 0.8995 - val_loss: 0.2765\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.2710 - val_accuracy: 0.8960 - val_loss: 0.2795\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.2610 - val_accuracy: 0.9068 - val_loss: 0.2632\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2473 - val_accuracy: 0.9080 - val_loss: 0.2494\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.2351 - val_accuracy: 0.9003 - val_loss: 0.2819\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.2299 - val_accuracy: 0.9117 - val_loss: 0.2515\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2123 - val_accuracy: 0.9128 - val_loss: 0.2368\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9065 - loss: 0.2585\n",
      "\n",
      "Test accuracy: 0.906499981880188\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6641 - loss: 1.4504 - val_accuracy: 0.8252 - val_loss: 0.6138\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.5981 - val_accuracy: 0.8432 - val_loss: 0.5423\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8480 - loss: 0.5352 - val_accuracy: 0.8470 - val_loss: 0.5157\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.5146 - val_accuracy: 0.8533 - val_loss: 0.4955\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.4929 - val_accuracy: 0.8600 - val_loss: 0.4758\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 0.4835 - val_accuracy: 0.8640 - val_loss: 0.4633\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.4606 - val_accuracy: 0.8602 - val_loss: 0.4673\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8697 - loss: 0.4517 - val_accuracy: 0.8553 - val_loss: 0.4657\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.4389 - val_accuracy: 0.8625 - val_loss: 0.4637\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.4384 - val_accuracy: 0.8745 - val_loss: 0.4251\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8734 - loss: 0.4438\n",
      "\n",
      "Test accuracy: 0.8733999729156494\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6836 - loss: 1.4369 - val_accuracy: 0.7958 - val_loss: 0.6594\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.6110 - val_accuracy: 0.8410 - val_loss: 0.5711\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.5506 - val_accuracy: 0.8485 - val_loss: 0.5320\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.5293 - val_accuracy: 0.8535 - val_loss: 0.5121\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.5101 - val_accuracy: 0.8505 - val_loss: 0.5018\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.5007 - val_accuracy: 0.8633 - val_loss: 0.4928\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.4859 - val_accuracy: 0.8647 - val_loss: 0.4734\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.4756 - val_accuracy: 0.8687 - val_loss: 0.4709\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.4729 - val_accuracy: 0.8683 - val_loss: 0.4588\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.4603 - val_accuracy: 0.8682 - val_loss: 0.4477\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8719 - loss: 0.4601\n",
      "\n",
      "Test accuracy: 0.8719000220298767\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5481 - loss: 8.7923 - val_accuracy: 0.7528 - val_loss: 1.0324\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 1.0119 - val_accuracy: 0.7812 - val_loss: 0.9023\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.9056 - val_accuracy: 0.7963 - val_loss: 0.8339\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.8371 - val_accuracy: 0.8130 - val_loss: 0.8051\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.8092 - val_accuracy: 0.8223 - val_loss: 0.7811\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.7779 - val_accuracy: 0.8235 - val_loss: 0.7759\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.7653 - val_accuracy: 0.8278 - val_loss: 0.7669\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.7445 - val_accuracy: 0.8320 - val_loss: 0.7461\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.7317 - val_accuracy: 0.8380 - val_loss: 0.7217\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.7251 - val_accuracy: 0.8413 - val_loss: 0.7164\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8322 - loss: 0.7356\n",
      "\n",
      "Test accuracy: 0.8321999907493591\n",
      "Training model with activation=tanh, optimizer=adam, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4191 - loss: 8.8701 - val_accuracy: 0.7253 - val_loss: 1.0716\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6985 - loss: 1.1165 - val_accuracy: 0.7147 - val_loss: 0.9900\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 1.0183 - val_accuracy: 0.7035 - val_loss: 1.0060\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7289 - loss: 0.9767 - val_accuracy: 0.7138 - val_loss: 0.9762\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7391 - loss: 0.9509 - val_accuracy: 0.7208 - val_loss: 0.9383\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.9399 - val_accuracy: 0.7155 - val_loss: 0.9576\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.9253 - val_accuracy: 0.7358 - val_loss: 0.9195\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7504 - loss: 0.9086 - val_accuracy: 0.7143 - val_loss: 0.9541\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7503 - loss: 0.8983 - val_accuracy: 0.7290 - val_loss: 0.9300\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.8962 - val_accuracy: 0.7097 - val_loss: 0.9631\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7048 - loss: 0.9942\n",
      "\n",
      "Test accuracy: 0.704800009727478\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3780 - loss: 1.8549 - val_accuracy: 0.7265 - val_loss: 0.8040\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.7690 - val_accuracy: 0.7735 - val_loss: 0.6380\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.6375 - val_accuracy: 0.7880 - val_loss: 0.5818\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7923 - loss: 0.5813 - val_accuracy: 0.8030 - val_loss: 0.5310\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.5332 - val_accuracy: 0.8115 - val_loss: 0.5060\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.5022 - val_accuracy: 0.8255 - val_loss: 0.4720\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.4806 - val_accuracy: 0.8360 - val_loss: 0.4508\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.4493 - val_accuracy: 0.8412 - val_loss: 0.4338\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.4255 - val_accuracy: 0.8467 - val_loss: 0.4245\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.4176 - val_accuracy: 0.8538 - val_loss: 0.4046\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8460 - loss: 0.4290\n",
      "\n",
      "Test accuracy: 0.8460000157356262\n",
      "Training model with activation=tanh, optimizer=sgd, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2720 - loss: 2.0341 - val_accuracy: 0.6818 - val_loss: 0.9054\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6828 - loss: 0.8778 - val_accuracy: 0.7385 - val_loss: 0.7046\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.7120 - val_accuracy: 0.7683 - val_loss: 0.6126\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7630 - loss: 0.6364 - val_accuracy: 0.7835 - val_loss: 0.5639\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.5869 - val_accuracy: 0.7973 - val_loss: 0.5296\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.5515 - val_accuracy: 0.8045 - val_loss: 0.5175\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.5290 - val_accuracy: 0.8135 - val_loss: 0.4915\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.5144 - val_accuracy: 0.8177 - val_loss: 0.4873\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.4858 - val_accuracy: 0.8352 - val_loss: 0.4485\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4733 - val_accuracy: 0.8393 - val_loss: 0.4393\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8300 - loss: 0.4675\n",
      "\n",
      "Test accuracy: 0.8299999833106995\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4291 - loss: 3.3875 - val_accuracy: 0.7085 - val_loss: 2.2318\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7074 - loss: 2.1307 - val_accuracy: 0.7513 - val_loss: 1.8395\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 1.7957 - val_accuracy: 0.7747 - val_loss: 1.6044\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 1.5635 - val_accuracy: 0.7892 - val_loss: 1.4247\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 1.3977 - val_accuracy: 0.7933 - val_loss: 1.2845\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 1.2620 - val_accuracy: 0.8050 - val_loss: 1.1605\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 1.1443 - val_accuracy: 0.8132 - val_loss: 1.0616\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 1.0520 - val_accuracy: 0.8233 - val_loss: 0.9768\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.9615 - val_accuracy: 0.8258 - val_loss: 0.9080\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.8925 - val_accuracy: 0.8263 - val_loss: 0.8496\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.8256 - loss: 0.8720\n",
      "\n",
      "Test accuracy: 0.8256000280380249\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L2 object at 0x7f839881b1d0>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3048 - loss: 3.4339 - val_accuracy: 0.6690 - val_loss: 2.2616\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6716 - loss: 2.1807 - val_accuracy: 0.7263 - val_loss: 1.8808\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7298 - loss: 1.8473 - val_accuracy: 0.7632 - val_loss: 1.6351\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 1.6189 - val_accuracy: 0.7762 - val_loss: 1.4434\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7721 - loss: 1.4367 - val_accuracy: 0.7883 - val_loss: 1.2991\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 1.2973 - val_accuracy: 0.7948 - val_loss: 1.1767\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 1.1772 - val_accuracy: 0.8058 - val_loss: 1.0731\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 1.0778 - val_accuracy: 0.8082 - val_loss: 0.9915\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.9926 - val_accuracy: 0.8185 - val_loss: 0.9183\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.9171 - val_accuracy: 0.8212 - val_loss: 0.8555\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.8117 - loss: 0.8858\n",
      "\n",
      "Test accuracy: 0.8116999864578247\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.2371 - loss: 27.7118 - val_accuracy: 0.5493 - val_loss: 6.5044\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5549 - loss: 4.2748 - val_accuracy: 0.6355 - val_loss: 1.8175\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6451 - loss: 1.6927 - val_accuracy: 0.6857 - val_loss: 1.4525\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6859 - loss: 1.4184 - val_accuracy: 0.7095 - val_loss: 1.2961\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7066 - loss: 1.2829 - val_accuracy: 0.7277 - val_loss: 1.1902\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7216 - loss: 1.1860 - val_accuracy: 0.7348 - val_loss: 1.1177\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 1.1200 - val_accuracy: 0.7402 - val_loss: 1.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 1.0637 - val_accuracy: 0.7452 - val_loss: 1.0194\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 1.0269 - val_accuracy: 0.7488 - val_loss: 0.9885\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7407 - loss: 1.0063 - val_accuracy: 0.7507 - val_loss: 0.9628\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.7330 - loss: 0.9987\n",
      "\n",
      "Test accuracy: 0.7329999804496765\n",
      "Training model with activation=tanh, optimizer=sgd, reg=<keras.src.regularizers.regularizers.L1 object at 0x7f83988c3750>, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.2032 - loss: 27.6791 - val_accuracy: 0.5437 - val_loss: 6.3708\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5562 - loss: 4.1879 - val_accuracy: 0.6095 - val_loss: 1.8068\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 1.7011 - val_accuracy: 0.6417 - val_loss: 1.4599\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6443 - loss: 1.4316 - val_accuracy: 0.6703 - val_loss: 1.3087\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6634 - loss: 1.3106 - val_accuracy: 0.6747 - val_loss: 1.2264\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6774 - loss: 1.2275 - val_accuracy: 0.6955 - val_loss: 1.1615\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6891 - loss: 1.1726 - val_accuracy: 0.7113 - val_loss: 1.1119\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 1.1220 - val_accuracy: 0.7132 - val_loss: 1.0770\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7006 - loss: 1.1043 - val_accuracy: 0.7237 - val_loss: 1.0479\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 1.0785 - val_accuracy: 0.7292 - val_loss: 1.0268\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7135 - loss: 1.0632\n",
      "\n",
      "Test accuracy: 0.7135000228881836\n"
     ]
    }
   ],
   "source": [
    "combinations_big = {}\n",
    "architectures = [[128,64,32], [256,128,64], [512,256,128]]\n",
    "for architecture in architectures:\n",
    "    for activation in activations:\n",
    "        for opt in optimizers:\n",
    "            for reg in regularizations:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    print(f\"Training model with activation={activation}, optimizer={opt}, \"\n",
    "                            f\"reg={reg}, dropout_rate={dropout_rate}\")\n",
    "                    model = create_model_big(shape=X_train[0].shape, activation=activation, optimizer=opt, \n",
    "                                            regularization=reg, dropout_rate=dropout_rate)\n",
    "                    history = model.fit(\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                        )\n",
    "                    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\t\n",
    "                    print(\"\\nTest accuracy:\", test_acc)\n",
    "                    combinations_big[(*architecture, activation, opt, reg, dropout_rate)] = {'test_acc': test_acc, 'history': history}\n",
    "with open(f'combinations_big_{epochs}_epochs.pkl', 'wb') as f:\n",
    "    pickle.dump(combinations_big, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(256, 128, 64, 'relu', 'adam', None, 0.25): {'test_acc': 0.9139999747276306,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f81a86dfdd0>},\n",
       " (128, 64, 32, 'relu', 'adam', None, 0.0): {'test_acc': 0.913100004196167,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f82cc7d8750>},\n",
       " (256, 128, 64, 'relu', 'adam', None, 0.0): {'test_acc': 0.913100004196167,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f81b006e3d0>},\n",
       " (256, 128, 64, 'tanh', 'adam', None, 0.0): {'test_acc': 0.9128999710083008,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f810054dfd0>},\n",
       " (128, 64, 32, 'relu', 'adam', None, 0.25): {'test_acc': 0.9110999703407288,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f82cc33b510>}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top K highest accuracy\n",
    "combinations_big = {k: v for k, v in sorted(combinations_big.items(), key=lambda item: item[1]['test_acc'], reverse=True)}\n",
    "top_k = 5\n",
    "top_k_combinations_big = dict(list(combinations_big.items())[:top_k])\n",
    "top_k_combinations_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3003 - loss: 47.9614\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5168 - loss: 1.3678\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5822 - loss: 1.1863\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 1.0756\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6534 - loss: 0.9866\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 0.8677\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7204 - loss: 0.7945\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7365 - loss: 0.7498\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7680 - loss: 0.6668\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7779 - loss: 0.6362\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.5658 - loss: 1.5202\n",
      "\n",
      "Test accuracy: 0.5658000111579895\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.2748 - loss: 38.9456\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5304 - loss: 1.3379\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6048 - loss: 1.1366\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.9795\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.8246\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.6979\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.6006\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5488\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.4361\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3893\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.5464 - loss: 2.1815\n",
      "\n",
      "Test accuracy: 0.5464000105857849\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3259 - loss: 68.3636\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5816 - loss: 1.1946\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6505 - loss: 0.9934\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7090 - loss: 0.8286\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7701 - loss: 0.6604\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8098 - loss: 0.5489\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8429 - loss: 0.4479\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8742 - loss: 0.3713\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8953 - loss: 0.3057\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.2675\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.5519 - loss: 2.4755\n",
      "\n",
      "Test accuracy: 0.5519000291824341\n",
      "Training model with activation=tanh, optimizer=adam, reg=None, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0980 - loss: 3.2323\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.3093\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.1016 - loss: 2.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.1003 - loss: 2.3090\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.1034 - loss: 2.3091\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.1033 - loss: 2.3099\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0981 - loss: 2.3091\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1012 - loss: 2.3109\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1003 - loss: 2.3099\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0988 - loss: 2.3097\n",
      "313/313 - 1s - 5ms/step - accuracy: 0.1000 - loss: 2.3124\n",
      "\n",
      "Test accuracy: 0.10000000149011612\n",
      "Training model with activation=relu, optimizer=adam, reg=None, dropout_rate=0.25\n",
      "Epoch 1/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1387 - loss: 39.3808\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1881 - loss: 2.0842\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2534 - loss: 1.8985\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2917 - loss: 1.7679\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3109 - loss: 1.7075\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3156 - loss: 1.6757\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3245 - loss: 1.6561\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3338 - loss: 1.6276\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3452 - loss: 1.6039\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3448 - loss: 1.5975\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.3464 - loss: 1.6371\n",
      "\n",
      "Test accuracy: 0.3463999927043915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(256, 128, 64, 'relu', 'adam', None, 0.25): {'test_acc': 0.5658000111579895,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f801c5b1490>},\n",
       " (128, 64, 32, 'relu', 'adam', None, 0.0): {'test_acc': 0.5464000105857849,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f80242e18d0>},\n",
       " (256, 128, 64, 'relu', 'adam', None, 0.0): {'test_acc': 0.5519000291824341,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f800c77b290>},\n",
       " (256, 128, 64, 'tanh', 'adam', None, 0.0): {'test_acc': 0.10000000149011612,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f800c5e8a10>},\n",
       " (128, 64, 32, 'relu', 'adam', None, 0.25): {'test_acc': 0.3463999927043915,\n",
       "  'history': <keras.src.callbacks.history.History at 0x7f800c239c50>}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, num_classes = load_cifar10_data()\n",
    "shape = X_train[1:].shape\n",
    "# train models with the top k combinations\n",
    "cifar10_top_k_results_big = {}\n",
    "for (layer1,layer2,layers3,activation, opt, reg, dropout_rate) in top_k_combinations_big.keys():\n",
    "    print(f\"Training model with activation={activation}, optimizer={opt}, \"\n",
    "            f\"reg={reg}, dropout_rate={dropout_rate}\")\n",
    "    architectures = [layer1,layer2,layers3]\n",
    "    model = create_model_small(shape=X_train[0].shape,activation=activation, optimizer=opt, \n",
    "                            regularization=reg, dropout_rate=dropout_rate, architectures=architectures)\n",
    "    history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=10,\n",
    "            verbose=1,\n",
    "            # validation_data=(X_test, y_test),\n",
    "        )\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\t\n",
    "    print(\"\\nTest accuracy:\", test_acc)\n",
    "    cifar10_top_k_results_big[(*architectures,activation, opt, reg, dropout_rate)] = {'test_acc': test_acc, 'history': history}\n",
    "with open(f'cifar10_top_k_big_results_{epochs}_epochs.pkl', 'wb') as f:\n",
    "    pickle.dump(cifar10_top_k_results_big, f)\n",
    "cifar10_top_k_results_big"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
